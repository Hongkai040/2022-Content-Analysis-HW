{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Week 3 - Discovering higher-level Patterns (Topic Modeling & Clustering)\n",
    "\n",
    "The first 2 weeks have primarily used the word count of documents as their measure, such as counting the number of \"positive\" and \"negative\" words to determine sentiment.\n",
    "\n",
    "This week, we learn a second kind of document representation in clusters or topics. First, we take a text corpus that we have developed and discovery emergent clusters through a process known as clustering or partitioning. We pilot this here both with a well-known *flat* clustering method, `kmeans`, and also a *hierarchical* approach, `Ward's (minimum variance) method`. We will demonstrate a simple (graphical) approach to identifying optimal cluster number, the sillhouette method, and evaluate the quality of unsupervised clusters on labeled data. Next, we will explore a method of two dimensional content clustering called topic modeling (e.g., words cluster in topics; topics cluster in documents). This statistical technique models and computationally induces *topics* from data, which are sparse distributions over (nonexclusive clusters of) words, from which documents can formally be described as sparse mixtures. We will explore these topics and consider their utility for understanding trends within a corpus. We will consider how to construct models that take document cluster and topic loadings as predictive features, the basis of influence metrics and dynamically over time.\n",
    "\n",
    "For this notebook we will be using the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Special module written for this class\n",
    "#This provides access to data and to helper functions from previous weeks\n",
    "#Make sure you update it before starting this notebook\n",
    "import lucem_illud #pip install -U git+git://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git\n",
    "\n",
    "\n",
    "#All these packages need to be installed from pip\n",
    "#These are all for the cluster detection\n",
    "import sklearn\n",
    "import sklearn.feature_extraction.text\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "import sklearn.datasets\n",
    "import sklearn.cluster\n",
    "import sklearn.decomposition\n",
    "import sklearn.metrics\n",
    "\n",
    "import scipy #For hierarchical clustering and some visuals\n",
    "#import scipy.cluster.hierarchy\n",
    "import gensim#For topic modeling\n",
    "import requests #For downloading our datasets\n",
    "import numpy as np #for arrays\n",
    "import pandas #gives us DataFrames\n",
    "import matplotlib.pyplot as plt #For graphics\n",
    "import matplotlib.cm #Still for graphics\n",
    "import seaborn as sns #Makes the graphics look nicer\n",
    "\n",
    "#This 'magic' command makes the plots work better\n",
    "#in the notebook, don't use it outside of a notebook.\n",
    "#Also you can ignore the warning, it\n",
    "%matplotlib inline\n",
    "\n",
    "import itertools\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting our corpora\n",
    "\n",
    "To begin, we will use a well known corpus of testing documents from the *20 Newsgroups corpus*, a dataset commonly used to illustrate text applications of text clustering and classification. This comes packaged with sklearn and comprises approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 newsgroups. It was originally collected by Ken Lang, probably for his 1995 *Newsweeder: Learning to filter netnews* paper. The data is organized into 20 distinct newsgroups, each corresponding to a different topic. Some of the newsgroups are very closely related (e.g. comp.sys.ibm.pc.hardware / comp.sys.mac.hardware), while others are unrelated (e.g misc.forsale / soc.religion.christian). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = sklearn.datasets.fetch_20newsgroups(subset='train', data_home = '../data/scikit_learn_data')\n",
    "print(dir(newsgroups))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can ascertain the categories with `target_names` or the actual files with `filenames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(newsgroups.target_names)\n",
    "print(len(newsgroups.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by converting the provided data into pandas DataFrames.\n",
    "\n",
    "First we reduce our dataset for this analysis by dropping some extraneous information and converting it into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroupsCategories = ['comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos']\n",
    "\n",
    "newsgroupsDF = pandas.DataFrame(columns = ['text', 'category', 'source_file'])\n",
    "\n",
    "for category in newsgroupsCategories:\n",
    "    print(\"Fetching data for: {}\".format(category))\n",
    "    ng = sklearn.datasets.fetch_20newsgroups(subset='train', categories = [category], remove=['headers', 'footers', 'quotes'], data_home = '../data/scikit_learn_data/')\n",
    "    newsgroupsDF = newsgroupsDF.append(pandas.DataFrame({'text' : ng.data, 'category' : [category] * len(ng.data), 'source_file' : ng.filenames}), ignore_index=True)\n",
    "\n",
    "#Creating an explicit index column for later\n",
    "\n",
    "#newsgroupsDF['index'] = range(len(newsgroupsDF))\n",
    "#newsgroupsDF.set_index('index', inplace = True)\n",
    "print(len(newsgroupsDF))\n",
    "newsgroupsDF[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can convert the documents into word count vectors (e.g., *soc.religion.christian message a* might contain 3 mentions of \"church\", 2 of \"jesus\", 1 of \"religion\", etc., yielding a CountVector=[3,2,1,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First it needs to be initialized\n",
    "ngCountVectorizer = sklearn.feature_extraction.text.CountVectorizer()\n",
    "#Then trained\n",
    "newsgroupsVects = ngCountVectorizer.fit_transform(newsgroupsDF['text'])\n",
    "print(newsgroupsVects.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm pretty sure that you're very familiar with the cell above now, but let's go through the concepts again. \n",
    "\n",
    "What do we want to do here? We want to do vectorization, i.e., converting texts into numerical features (vectors) as required by machine learning algorithms. And this is what feature_extraction module does: to extract features from texts in a format as required by ML algorithms. **feature_extraction module has four classes: CountVectorizer, DictVectorizer, TfidfVectorizer, and FeatureHasher**. Here, we use CountVectorizer, but we'll also use TfidfVectorizer as well below.\n",
    "\n",
    "There are various strategies by which we extract features. Here, we use CountVectorizer, and, in particular, we use 'Bag of Words' representation. In other words, the features we hope to extract from the texts are each individual token occurrence frequency. We simply count the the occurrence of each token in each document. So, here, we get a document-term-matrix, in which documents are characterized by the occurrences of tokens. Other forms of features, such as the relative position information of words, are ignored. We'll see other types of representations and strategies as well soon, such as N-gram (by the way, we can do n-gram with CountVectorizer. CountVectorizer class takes a set of parameters, such as analyzer, which you can specify the n-gram). \n",
    "\n",
    "the first line of the cell above instantiate a class, CountVectorizer(). In other words, you created an instance, or realization of a class. What is a class and what does instantiation mean? That's a long story, maybe for next time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a matrix with row a document and each column a word. The matrix is mostly zeros, so we store it as a sparse matrix, a data structure that contains and indexes only the nonzero entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroupsVects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the normal operations on this sparse matrix or convert it to normal matrix (not recommended for large sparse matrices :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroupsVects[:10,:20].toarray()\n",
    "# newsgroupsVects[:10,:20].todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the toarray() function here? It's similar to todense()--todense() and toarray() both returns a dense representation of a matrix; however, todense() returns a matrix representation while toarray() returns a ndarray representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also lookup the indices of different words using the Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ngCountVectorizer.vocabulary_.get('mac')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some more interesting things to do...\n",
    "\n",
    "Lets start with [term frequency–inverse document frequency](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html)(tf-idf), a method for weighting document-distinguishing words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize\n",
    "newsgroupsTFTransformer = sklearn.feature_extraction.text.TfidfTransformer().fit(newsgroupsVects)\n",
    "#train\n",
    "newsgroupsTF = newsgroupsTFTransformer.transform(newsgroupsVects)\n",
    "print(newsgroupsTF.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us the tf-idf for each word in each text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(zip(ngCountVectorizer.vocabulary_.keys(), newsgroupsTF.data))[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we're doing here. First, you need to know what vocabulary\\_ does. vocabulary\\_ is an attribute of the CountVectorizer, which gives you a mapping of terms to feature indices. It gives you all the terms and their feature indices, so it's a dictionary. So, by doing \"ngCountVectorizer.vocabulary\\_.keys()\", we get the keys of the dictionary, which are the terms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, there appears to be a lot of garbage littering this unordered list with unique words and stopwords. Note, however, that words like *apple*, *rgb*, and *voltage* distinguish this newsgroup document, while stopwords post a much lower weight. Note that we could filter out stop words, stem and lem our data before vectorizering, or we can instead use tf-idf to filter our data (or **both**). For exact explanation of all options look [here](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). To prune this matrix of features, we now limit our word vector to 1000 words with at least 3 occurrences, which do not occur in more than half of the documents. There is an extensive science and art to feature engineering for machine learning applications like clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize\n",
    "ngTFVectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_df=0.5, max_features=1000, min_df=3, stop_words='english', norm='l2')\n",
    "#train\n",
    "newsgroupsTFVects = ngTFVectorizer.fit_transform(newsgroupsDF['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroupsDF['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix is much smaller now, only 1000 words, but the same number of documents\n",
    "\n",
    "We can still look at the words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(ngTFVectorizer.vocabulary_['vector'])\n",
    "except KeyError:\n",
    "    print('vector is missing')\n",
    "    print('The available words are: {} ...'.format(list(ngTFVectorizer.vocabulary_.keys())[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a reasonable matrix of features with which to begin identifying clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flat Clustering with $K$-means\n",
    "\n",
    "Lets start with $k$-means, an approach that begins with random clusters of predefined number, then iterates cluster reassignment and evaluates the new clusters relative to an objective function, recursively.\n",
    "\n",
    "To do this we will need to know how many clusters we are looking for. Here the *true number* of clusters is 4. Of course, in most cases you would not know the number in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numClusters = len(set(newsgroupsDF['category']))\n",
    "numClusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can initialize our cluster finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-means++ is a better way of finding the starting points\n",
    "#We could also try providing our own\n",
    "km = sklearn.cluster.KMeans(n_clusters=numClusters, init='k-means++')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can calculate the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km.fit(newsgroupsTFVects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the clusters, we can evaluate them with a variety of metrics that sklearn provides. We will look at a few, including *Homogeneity*, *Completeness*, *V-measure* and *Adjusted Rand Score*. \n",
    "\n",
    "*Homogeneity* is a measure that grows (from 0 to 1) to the degree that all of its clusters contain only data points which are members of a single class (e.g., newsgroup). \n",
    "\n",
    "*Completeness* is *Homogeneity's* converse: a measure that grows (0 to 1) to the degree that all data points of a given class are also elements of the same cluster.\n",
    "\n",
    "The *V-measure* is the harmonic mean of *Homogeniety* and *Completeness* ($v = 2 * (homogeneity * completeness) / (homogeneity + completeness$).\n",
    "\n",
    "the *Adjusted Rand Score* is built atop the *Rand Index (RI)*, which computes the similarity between two clusterings by considering all pairs of samples and counting pairs assigned in the same or different clusters in the predicted and true clusterings (e.g., actual newsgroups). The *RI* is then adjusted for chance as follows:\n",
    "$ARI = (RI - RI_{expected}) / (max(RI) - RI_{expected})$.\n",
    "The Adjusted Rand Index is thus ensured to have a value close to 0.0 for random labeling independent of the number of clusters and samples, 1.0 when the clusterings are identical, and -1.0 when they are as bad (i.e., cross-cutting) as they can be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The available metrics are: {}\".format([s for s in dir(sklearn.metrics) if s[0] != '_']))\n",
    "print(\"For our clusters:\")\n",
    "# here the category represents true label\n",
    "print(\"Homogeneity: {:0.3f}\".format(sklearn.metrics.homogeneity_score(newsgroupsDF['category'], km.labels_)))\n",
    "print(\"Completeness: {:0.3f}\".format(sklearn.metrics.completeness_score(newsgroupsDF['category'], km.labels_)))\n",
    "print(\"V-measure: {:0.3f}\".format(sklearn.metrics.v_measure_score(newsgroupsDF['category'], km.labels_)))\n",
    "print(\"Adjusted Rand Score: {:0.3f}\".format(sklearn.metrics.adjusted_rand_score(newsgroupsDF['category'], km.labels_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can evaluate these for different clustering solutions ($1-N$ clusters). You can also interrogate the alignment between specific documents and their cluster assignments by adding the cluster labels to the pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroupsDF['kmeans_predictions'] = km.labels_\n",
    "newsgroupsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the distinguishing features in each cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = ngTFVectorizer.get_feature_names()\n",
    "print(terms[100:110])\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1] # copy inverse\n",
    "for i in range(numClusters):\n",
    "    print(\"Cluster %d:\" % i)\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(ind)\n",
    "        print(' %s' % terms[ind]) # formatting the word \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct a visualization of the clusters. First, we will first reduce the\n",
    "dimensionality of the data using principal components analysis (PCA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA = sklearn.decomposition.PCA\n",
    "pca = PCA(n_components = 2).fit(newsgroupsTFVects.toarray())\n",
    "reduced_data = pca.transform(newsgroupsTFVects.toarray()) \n",
    "# is equal to fit_transform. but fit and transform have different functionalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The cell below is optional. It allows you to do a biplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = pca.components_\n",
    "print(type(components))\n",
    "print(components)\n",
    "keyword_ids = list(set(order_centroids[:,:10].flatten())) #Get the ids of the most distinguishing words(features) from your kmeans model.\n",
    "# .flatten() reduces to one dimension\n",
    "words = [terms[i] for i in keyword_ids]#Turn the ids into words.\n",
    "x = components[:,keyword_ids][0,:] #Find the coordinates of those words in your biplot.\n",
    "y = components[:,keyword_ids][1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's build a color map for the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colordict = {\n",
    "'comp.sys.mac.hardware': 'red',\n",
    "'comp.windows.x': 'orange',\n",
    "'misc.forsale': 'green',\n",
    "'rec.autos': 'blue',\n",
    "    }\n",
    "colors = [colordict[c] for c in newsgroupsDF['category']]\n",
    "print(\"The categories' colors are:\\n{}\".format(colordict.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the data using the true labels as the colors of our data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_frame_on(False)\n",
    "ax.scatter(reduced_data[:, 0], reduced_data[:, 1], color = colors, alpha = 0.5, label = colors)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title('True Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One nice thing about PCA is that we can also do a biplot and map our feature\n",
    "vectors to the same space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (16,9))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_frame_on(False)\n",
    "ax.scatter(reduced_data[:, 0], reduced_data[:, 1], color = colors, alpha = 0.3, label = colors)\n",
    "for i, word in enumerate(words):\n",
    "    ax.annotate(word, (x[i],y[i]))\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title('True Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do it again with predicted clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_p = [colordict[newsgroupsCategories[l]] for l in km.labels_]\n",
    "# see the beginning of this section for colordict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_frame_on(False)\n",
    "plt.scatter(reduced_data[:, 0], reduced_data[:, 1], color = colors_p, alpha = 0.5)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title('Predicted Clusters\\n k = 4')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with 3 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km3 = sklearn.cluster.KMeans(n_clusters= 3, init='k-means++')\n",
    "km3.fit(newsgroupsTFVects.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Cluster Number\n",
    "\n",
    "We can select an optimal cluster number by identifying the lowest of the metrics listed above (e.g., V-measure), but often you don't have \"ground truth\" or labeled data. For identifying the \"best\" number of clusters in an unsupervised way, we demonstrate the Silhouette method. Many other methods also exist (e.g., Bayesian Information Criteria or BIC, the visual \"elbow criteria\", etc.)\n",
    "\n",
    "First we will define a helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSilhouette(n_clusters, X):\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize = (15,5))\n",
    "    \n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "    clusterer = sklearn.cluster.KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "    \n",
    "    silhouette_avg = sklearn.metrics.silhouette_score(X, cluster_labels)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = sklearn.metrics.silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "        cmap = matplotlib.cm.get_cmap(\"nipy_spectral\")\n",
    "        color = cmap(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        y_lower = y_upper + 10\n",
    "    \n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    cmap = matplotlib.cm.get_cmap(\"nipy_spectral\")\n",
    "#     colors = cmap(float(i) / n_clusters)\n",
    "    colors = np.array(cmap(float(i) / n_clusters)).reshape(1,-1)\n",
    "    ax2.scatter(reduced_data[:, 0], reduced_data[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
    "                c=colors)\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = clusterer.cluster_centers_\n",
    "    projected_centers = pca.transform(centers)\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(projected_centers[:, 0], projected_centers[:, 1],\n",
    "                marker='o', c=\"white\", alpha=1, s=200)\n",
    "\n",
    "    for i, c in enumerate(projected_centers):\n",
    "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1, s=50)\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"PC 1\")\n",
    "    ax2.set_ylabel(\"PC 2\")\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    plt.show()\n",
    "    print(\"For n_clusters = {}, The average silhouette_score is : {:.3f}\".format(n_clusters, silhouette_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can examine a few different numbers of clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = newsgroupsTFVects.toarray()\n",
    "plotSilhouette(3, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = newsgroupsTFVects.toarray()\n",
    "plotSilhouette(4, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = newsgroupsTFVects.toarray()\n",
    "plotSilhouette(5, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = newsgroupsTFVects.toarray()\n",
    "plotSilhouette(6, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the silhouette scores above suggests that 3 is a better number of clusters than 4, which would be accurate if we (reasonsably) grouped the two computer-themed groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting new text data\n",
    "\n",
    "Lets start by using the same function as last lesson and loading a few press releases from 10 different senators into a DataFrame. The code to do this is below, but commented out as we've already downloaded the data to the data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetSenator = 'Kennedy'# = ['Voinovich', 'Obama', 'Whitehouse', 'Snowe', 'Rockefeller', 'Murkowski', 'McCain', 'Kyl', 'Baucus', 'Frist']\n",
    "\"\"\"\n",
    "#Uncomment this to download your own data\n",
    "senReleasesTraining = pandas.DataFrame()\n",
    "\n",
    "print(\"Fetching {}'s data\".format(targetSenator))\n",
    "targetDF = lucem_illud.getGithubFiles('https://api.github.com/repos/lintool/GrimmerSenatePressReleases/contents/raw/{}'.format(targetSenator), maxFiles = 2000)\n",
    "targetDF['targetSenator'] = targetSenator\n",
    "senReleasesTraining = senReleasesTraining.append(targetDF, ignore_index = True)\n",
    "\n",
    "#Watch out for weird lines when converting to csv\n",
    "#one of them had to be removed from the Kennedy data so it could be re-read\n",
    "senReleasesTraining.to_csv(\"data/senReleasesTraining.csv\")\n",
    "\"\"\"\n",
    "\n",
    "senReleasesTraining = pandas.read_csv(\"../data/senReleasesTraining.csv\")\n",
    "\n",
    "senReleasesTraining[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the files we can tokenize and normalize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normalized text is good, but we know that the texts will have a large amount of overlap so we can use tf-idf to remove some of the most frequent words. Before doing that, there is one empty cell, let's remove that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senReleasesTraining = senReleasesTraining.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similar parameters to before, but stricter max df and no max num occurrences\n",
    "senTFVectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_df=100, min_df=2, stop_words='english', norm='l2')\n",
    "senTFVects = senTFVectorizer.fit_transform(senReleasesTraining['text'])\n",
    "senTFVectorizer.vocabulary_.get('senat', 'Missing \"Senate\"')\n",
    "# if not find senat, return missing senate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering with our new data\n",
    "\n",
    "One nice thing about using DataFrames for everything is that we can quickly convert code from one input to another. Below we are redoing the cluster detection with our senate data. If you setup your DataFrame the same way it should be able to run on this code, without much work.\n",
    "\n",
    "First we will define what we will be working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetDF = senReleasesTraining\n",
    "textColumn = 'text'\n",
    "numCategories = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tf-IDf vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exampleTFVectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_df=0.5, max_features=1000, min_df=3, stop_words='english', norm='l2')\n",
    "#train\n",
    "exampleTFVects = ngTFVectorizer.fit_transform(targetDF[textColumn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running k means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exampleKM = sklearn.cluster.KMeans(n_clusters = numCategories, init='k-means++')\n",
    "exampleKM.fit(exampleTFVects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examplePCA = sklearn.decomposition.PCA(n_components = 2).fit(exampleTFVects.toarray())\n",
    "reducedPCA_data = examplePCA.transform(exampleTFVects.toarray())\n",
    "\n",
    "colors = list(plt.cm.rainbow(np.linspace(0,1, numCategories)))\n",
    "colors_p = [colors[l] for l in exampleKM.labels_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_frame_on(False)\n",
    "plt.scatter(reducedPCA_data[:, 0], reducedPCA_data[:, 1], color = colors_p, alpha = 0.5)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title('Predicted Clusters\\n k = {}'.format(numCategories))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, there may be two clusters that could be identified with Silhouette analysis or some of the metrics described above; although not having true classes makes that tricky. Below, we add these cluster assignments to the dataframe for individual perusal and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetDF['kmeans_predictions'] = exampleKM.labels_\n",
    "targetDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">*Exercise 1*</font>\n",
    "\n",
    "<font color=\"red\">Construct cells immediately below this that construct features and cluster your documents using K-means and a variety of cluster numbers. Interrogate the cluster contents in terms of both documents and features. Identify the \"optimal\" cluster number with Silhouette analysis. Plot clusters and features after reducing with PCA. What does this cluster structure reveal about the organization of documents in your corpora? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some sample movie reviews from douban.com\n",
    "import re\n",
    "import jieba \n",
    "# a package for cutting Chinese text into words. i.e. tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_time</th>\n",
       "      <th>content</th>\n",
       "      <th>douban_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-05 19:42:07</td>\n",
       "      <td>480p画质不高黑白y</td>\n",
       "      <td>5113101</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-09 14:52:07</td>\n",
       "      <td>毫无看点黑白画质一个男人孤独的心理情景历程疯疯癫癫没有任何恐怖的成分这应该是剧情片吧</td>\n",
       "      <td>5113101</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-11-05 22:15:44</td>\n",
       "      <td>上吊那裡超好笑可惜最後報告近況的旁白大扣分</td>\n",
       "      <td>3718526</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-06-20 02:12:50</td>\n",
       "      <td>上海国际电影节观摩片</td>\n",
       "      <td>3718526</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-04-09 22:10:13</td>\n",
       "      <td></td>\n",
       "      <td>3718526</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>2010-09-11 13:46:02</td>\n",
       "      <td>搞笑的励志电影</td>\n",
       "      <td>1309050</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>2010-10-23 13:19:17</td>\n",
       "      <td>美国所谓的人权</td>\n",
       "      <td>1309050</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2009-01-22 18:36:13</td>\n",
       "      <td>2009121在书房跟老公一起看的没看完但看过的部分很精彩期待</td>\n",
       "      <td>1309050</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2011-10-19 12:00:27</td>\n",
       "      <td>我喜欢亚当桑德勒说橄榄球跟乒乓球差不多就是是蛋形的跟我的头一样lol另外我的Alexmaho...</td>\n",
       "      <td>1309050</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2009-05-23 19:02:22</td>\n",
       "      <td>好久没看这么搞笑的片了哈哈</td>\n",
       "      <td>1309050</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             comment_time                                            content  \\\n",
       "0     2018-09-05 19:42:07                                        480p画质不高黑白y   \n",
       "1     2019-07-09 14:52:07         毫无看点黑白画质一个男人孤独的心理情景历程疯疯癫癫没有任何恐怖的成分这应该是剧情片吧   \n",
       "2     2010-11-05 22:15:44                              上吊那裡超好笑可惜最後報告近況的旁白大扣分   \n",
       "3     2010-06-20 02:12:50                                         上海国际电影节观摩片   \n",
       "4     2011-04-09 22:10:13                                                      \n",
       "...                   ...                                                ...   \n",
       "4995  2010-09-11 13:46:02                                            搞笑的励志电影   \n",
       "4996  2010-10-23 13:19:17                                            美国所谓的人权   \n",
       "4997  2009-01-22 18:36:13                    2009121在书房跟老公一起看的没看完但看过的部分很精彩期待   \n",
       "4998  2011-10-19 12:00:27  我喜欢亚当桑德勒说橄榄球跟乒乓球差不多就是是蛋形的跟我的头一样lol另外我的Alexmaho...   \n",
       "4999  2009-05-23 19:02:22                                      好久没看这么搞笑的片了哈哈   \n",
       "\n",
       "      douban_id  rating  \n",
       "0       5113101     2.0  \n",
       "1       5113101     1.0  \n",
       "2       3718526     3.0  \n",
       "3       3718526     NaN  \n",
       "4       3718526     NaN  \n",
       "...         ...     ...  \n",
       "4995    1309050     5.0  \n",
       "4996    1309050     3.0  \n",
       "4997    1309050     3.0  \n",
       "4998    1309050     3.0  \n",
       "4999    1309050     4.0  \n",
       "\n",
       "[5000 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pandas.read_csv('/Users/mao_shiba/Downloads/moviedata_small/comments.csv')\n",
    "reviews = reviews.loc[:, ['comment_time','content', 'douban_id', 'rating']]\n",
    "reviews['content'].replace('[^\\u4e00-\\u9fa5A-Za-z0-9]+', ' ', regex = True, inplace=True)\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_time</th>\n",
       "      <th>content</th>\n",
       "      <th>douban_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>cut_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-05 19:42:07</td>\n",
       "      <td>480p画质不高黑白y</td>\n",
       "      <td>5113101</td>\n",
       "      <td>2.0</td>\n",
       "      <td>480p 画质 不高 黑白 y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-09 14:52:07</td>\n",
       "      <td>毫无看点黑白画质一个男人孤独的心理情景历程疯疯癫癫没有任何恐怖的成分这应该是剧情片吧</td>\n",
       "      <td>5113101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>毫无 看点 黑白 画质 一个 男人 孤独 的 心理 情景 历程 疯疯癫癫 没有 任何 恐怖 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-11-05 22:15:44</td>\n",
       "      <td>上吊那裡超好笑可惜最後報告近況的旁白大扣分</td>\n",
       "      <td>3718526</td>\n",
       "      <td>3.0</td>\n",
       "      <td>上吊 那裡 超 好笑 可惜 最後報 告近況 的 旁白 大 扣分</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-06-20 02:12:50</td>\n",
       "      <td>上海国际电影节观摩片</td>\n",
       "      <td>3718526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>上海 国际 电影节 观摩 片</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-04-09 22:10:13</td>\n",
       "      <td></td>\n",
       "      <td>3718526</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>2010-09-11 13:46:02</td>\n",
       "      <td>搞笑的励志电影</td>\n",
       "      <td>1309050</td>\n",
       "      <td>5.0</td>\n",
       "      <td>搞笑 的 励志 电影</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>2010-10-23 13:19:17</td>\n",
       "      <td>美国所谓的人权</td>\n",
       "      <td>1309050</td>\n",
       "      <td>3.0</td>\n",
       "      <td>美国 所谓 的 人权</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2009-01-22 18:36:13</td>\n",
       "      <td>2009121在书房跟老公一起看的没看完但看过的部分很精彩期待</td>\n",
       "      <td>1309050</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2009121 在 书房 跟 老公 一起 看 的 没 看 完 但 看过 的 部分 很 精彩 期待</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2011-10-19 12:00:27</td>\n",
       "      <td>我喜欢亚当桑德勒说橄榄球跟乒乓球差不多就是是蛋形的跟我的头一样lol另外我的Alexmaho...</td>\n",
       "      <td>1309050</td>\n",
       "      <td>3.0</td>\n",
       "      <td>我 喜欢 亚当 桑德勒 说 橄榄球 跟 乒乓球 差不多 就是 是 蛋形 的 跟 我 的 头 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2009-05-23 19:02:22</td>\n",
       "      <td>好久没看这么搞笑的片了哈哈</td>\n",
       "      <td>1309050</td>\n",
       "      <td>4.0</td>\n",
       "      <td>好久没 看 这么 搞笑 的 片 了 哈哈</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             comment_time                                            content  \\\n",
       "0     2018-09-05 19:42:07                                        480p画质不高黑白y   \n",
       "1     2019-07-09 14:52:07         毫无看点黑白画质一个男人孤独的心理情景历程疯疯癫癫没有任何恐怖的成分这应该是剧情片吧   \n",
       "2     2010-11-05 22:15:44                              上吊那裡超好笑可惜最後報告近況的旁白大扣分   \n",
       "3     2010-06-20 02:12:50                                         上海国际电影节观摩片   \n",
       "4     2011-04-09 22:10:13                                                      \n",
       "...                   ...                                                ...   \n",
       "4995  2010-09-11 13:46:02                                            搞笑的励志电影   \n",
       "4996  2010-10-23 13:19:17                                            美国所谓的人权   \n",
       "4997  2009-01-22 18:36:13                    2009121在书房跟老公一起看的没看完但看过的部分很精彩期待   \n",
       "4998  2011-10-19 12:00:27  我喜欢亚当桑德勒说橄榄球跟乒乓球差不多就是是蛋形的跟我的头一样lol另外我的Alexmaho...   \n",
       "4999  2009-05-23 19:02:22                                      好久没看这么搞笑的片了哈哈   \n",
       "\n",
       "      douban_id  rating                                          cut_words  \n",
       "0       5113101     2.0                                    480p 画质 不高 黑白 y  \n",
       "1       5113101     1.0  毫无 看点 黑白 画质 一个 男人 孤独 的 心理 情景 历程 疯疯癫癫 没有 任何 恐怖 ...  \n",
       "2       3718526     3.0                    上吊 那裡 超 好笑 可惜 最後報 告近況 的 旁白 大 扣分  \n",
       "3       3718526     NaN                                     上海 国际 电影节 观摩 片  \n",
       "4       3718526     NaN                                                     \n",
       "...         ...     ...                                                ...  \n",
       "4995    1309050     5.0                                         搞笑 的 励志 电影  \n",
       "4996    1309050     3.0                                         美国 所谓 的 人权  \n",
       "4997    1309050     3.0   2009121 在 书房 跟 老公 一起 看 的 没 看 完 但 看过 的 部分 很 精彩 期待  \n",
       "4998    1309050     3.0  我 喜欢 亚当 桑德勒 说 橄榄球 跟 乒乓球 差不多 就是 是 蛋形 的 跟 我 的 头 ...  \n",
       "4999    1309050     4.0                               好久没 看 这么 搞笑 的 片 了 哈哈  \n",
       "\n",
       "[5000 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_words = lambda x: ' '.join(jieba.cut(x))\n",
    "reviews['cut_words'] = reviews['content'].apply(cut_words)\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--',\n",
       " '?',\n",
       " '“',\n",
       " '”',\n",
       " '》',\n",
       " '－－',\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'across',\n",
       " 'actually',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " \"ain't\",\n",
       " 'all',\n",
       " 'allow',\n",
       " 'allows',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'appear',\n",
       " 'appreciate',\n",
       " 'appropriate',\n",
       " 'are',\n",
       " \"aren't\",\n",
       " 'around',\n",
       " 'as',\n",
       " \"a's\",\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asking',\n",
       " 'associated',\n",
       " 'at',\n",
       " 'available',\n",
       " 'away',\n",
       " 'awfully',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'both',\n",
       " 'brief',\n",
       " 'but',\n",
       " 'by',\n",
       " 'came',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'cant',\n",
       " \"can't\",\n",
       " 'cause',\n",
       " 'causes',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'changes',\n",
       " 'clearly',\n",
       " \"c'mon\",\n",
       " 'co',\n",
       " 'com',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'concerning',\n",
       " 'consequently',\n",
       " 'consider',\n",
       " 'considering',\n",
       " 'contain',\n",
       " 'containing',\n",
       " 'contains',\n",
       " 'corresponding',\n",
       " 'could',\n",
       " \"couldn't\",\n",
       " 'course',\n",
       " \"c's\",\n",
       " 'currently',\n",
       " 'definitely',\n",
       " 'described',\n",
       " 'despite',\n",
       " 'did',\n",
       " \"didn't\",\n",
       " 'different',\n",
       " 'do',\n",
       " 'does',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'done',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'downwards',\n",
       " 'during',\n",
       " 'each',\n",
       " 'edu',\n",
       " 'eg',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'enough',\n",
       " 'entirely',\n",
       " 'especially',\n",
       " 'et',\n",
       " 'etc',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'ex',\n",
       " 'exactly',\n",
       " 'example',\n",
       " 'except',\n",
       " 'far',\n",
       " 'few',\n",
       " 'fifth',\n",
       " 'first',\n",
       " 'five',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'follows',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forth',\n",
       " 'four',\n",
       " 'from',\n",
       " 'further',\n",
       " 'furthermore',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'go',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'gone',\n",
       " 'got',\n",
       " 'gotten',\n",
       " 'greetings',\n",
       " 'had',\n",
       " \"hadn't\",\n",
       " 'happens',\n",
       " 'hardly',\n",
       " 'has',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " \"here's\",\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'hi',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'hither',\n",
       " 'hopefully',\n",
       " 'how',\n",
       " 'howbeit',\n",
       " 'however',\n",
       " \"i'd\",\n",
       " 'ie',\n",
       " 'if',\n",
       " 'ignored',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'immediate',\n",
       " 'in',\n",
       " 'inasmuch',\n",
       " 'inc',\n",
       " 'indeed',\n",
       " 'indicate',\n",
       " 'indicated',\n",
       " 'indicates',\n",
       " 'inner',\n",
       " 'insofar',\n",
       " 'instead',\n",
       " 'into',\n",
       " 'inward',\n",
       " 'is',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " 'its',\n",
       " \"it's\",\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'keep',\n",
       " 'keeps',\n",
       " 'kept',\n",
       " 'know',\n",
       " 'known',\n",
       " 'knows',\n",
       " 'last',\n",
       " 'lately',\n",
       " 'later',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'lest',\n",
       " 'let',\n",
       " \"let's\",\n",
       " 'like',\n",
       " 'liked',\n",
       " 'likely',\n",
       " 'little',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'ltd',\n",
       " 'mainly',\n",
       " 'many',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'me',\n",
       " 'mean',\n",
       " 'meanwhile',\n",
       " 'merely',\n",
       " 'might',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'much',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'name',\n",
       " 'namely',\n",
       " 'nd',\n",
       " 'near',\n",
       " 'nearly',\n",
       " 'necessary',\n",
       " 'need',\n",
       " 'needs',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'new',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'non',\n",
       " 'none',\n",
       " 'noone',\n",
       " 'nor',\n",
       " 'normally',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'novel',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'obviously',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'old',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'ones',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'ought',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'outside',\n",
       " 'over',\n",
       " 'overall',\n",
       " 'own',\n",
       " 'particular',\n",
       " 'particularly',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'placed',\n",
       " 'please',\n",
       " 'plus',\n",
       " 'possible',\n",
       " 'presumably',\n",
       " 'probably',\n",
       " 'provides',\n",
       " 'que',\n",
       " 'quite',\n",
       " 'qv',\n",
       " 'rather',\n",
       " 'rd',\n",
       " 're',\n",
       " 'really',\n",
       " 'reasonably',\n",
       " 'regarding',\n",
       " 'regardless',\n",
       " 'regards',\n",
       " 'relatively',\n",
       " 'respectively',\n",
       " 'right',\n",
       " 'said',\n",
       " 'same',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'second',\n",
       " 'secondly',\n",
       " 'see',\n",
       " 'seeing',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'seen',\n",
       " 'self',\n",
       " 'selves',\n",
       " 'sensible',\n",
       " 'sent',\n",
       " 'serious',\n",
       " 'seriously',\n",
       " 'seven',\n",
       " 'several',\n",
       " 'shall',\n",
       " 'she',\n",
       " 'should',\n",
       " \"shouldn't\",\n",
       " 'since',\n",
       " 'six',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somebody',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhat',\n",
       " 'somewhere',\n",
       " 'soon',\n",
       " 'sorry',\n",
       " 'specified',\n",
       " 'specify',\n",
       " 'specifying',\n",
       " 'still',\n",
       " 'sub',\n",
       " 'such',\n",
       " 'sup',\n",
       " 'sure',\n",
       " 'take',\n",
       " 'taken',\n",
       " 'tell',\n",
       " 'tends',\n",
       " 'th',\n",
       " 'than',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'thanx',\n",
       " 'that',\n",
       " 'thats',\n",
       " \"that's\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'theres',\n",
       " \"there's\",\n",
       " 'thereupon',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'think',\n",
       " 'third',\n",
       " 'this',\n",
       " 'thorough',\n",
       " 'thoroughly',\n",
       " 'those',\n",
       " 'though',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'took',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'tried',\n",
       " 'tries',\n",
       " 'truly',\n",
       " 'try',\n",
       " 'trying',\n",
       " \"t's\",\n",
       " 'twice',\n",
       " 'two',\n",
       " 'un',\n",
       " 'under',\n",
       " 'unfortunately',\n",
       " 'unless',\n",
       " 'unlikely',\n",
       " 'until',\n",
       " 'unto',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'use',\n",
       " 'used',\n",
       " 'useful',\n",
       " 'uses',\n",
       " 'using',\n",
       " 'usually',\n",
       " 'value',\n",
       " 'various',\n",
       " 'very',\n",
       " 'via',\n",
       " 'viz',\n",
       " 'vs',\n",
       " 'want',\n",
       " 'wants',\n",
       " 'was',\n",
       " \"wasn't\",\n",
       " 'way',\n",
       " 'we',\n",
       " \"we'd\",\n",
       " 'welcome',\n",
       " 'well',\n",
       " \"we'll\",\n",
       " 'went',\n",
       " 'were',\n",
       " \"we're\",\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'whatever',\n",
       " \"what's\",\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " \"where's\",\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whither',\n",
       " 'who',\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'whom',\n",
       " \"who's\",\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'willing',\n",
       " 'wish',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " 'wonder',\n",
       " \"won't\",\n",
       " 'would',\n",
       " \"wouldn't\",\n",
       " 'yes',\n",
       " 'yet',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\",\n",
       " 'zero',\n",
       " 'zt',\n",
       " 'ZT',\n",
       " 'zz',\n",
       " 'ZZ',\n",
       " '一',\n",
       " '一下',\n",
       " '一些',\n",
       " '一切',\n",
       " '一则',\n",
       " '一天',\n",
       " '一定',\n",
       " '一方面',\n",
       " '一旦',\n",
       " '一时',\n",
       " '一来',\n",
       " '一样',\n",
       " '一次',\n",
       " '一片',\n",
       " '一直',\n",
       " '一致',\n",
       " '一般',\n",
       " '一起',\n",
       " '一边',\n",
       " '一面',\n",
       " '万一',\n",
       " '上下',\n",
       " '上升',\n",
       " '上去',\n",
       " '上来',\n",
       " '上述',\n",
       " '上面',\n",
       " '下列',\n",
       " '下去',\n",
       " '下来',\n",
       " '下面',\n",
       " '不一',\n",
       " '不久',\n",
       " '不仅',\n",
       " '不会',\n",
       " '不但',\n",
       " '不光',\n",
       " '不单',\n",
       " '不变',\n",
       " '不只',\n",
       " '不可',\n",
       " '不同',\n",
       " '不够',\n",
       " '不如',\n",
       " '不得',\n",
       " '不怕',\n",
       " '不惟',\n",
       " '不成',\n",
       " '不拘',\n",
       " '不敢',\n",
       " '不断',\n",
       " '不是',\n",
       " '不比',\n",
       " '不然',\n",
       " '不特',\n",
       " '不独',\n",
       " '不管',\n",
       " '不能',\n",
       " '不要',\n",
       " '不论',\n",
       " '不足',\n",
       " '不过',\n",
       " '不问',\n",
       " '与',\n",
       " '与其',\n",
       " '与否',\n",
       " '与此同时',\n",
       " '专门',\n",
       " '且',\n",
       " '两者',\n",
       " '严格',\n",
       " '严重',\n",
       " '个',\n",
       " '个人',\n",
       " '个别',\n",
       " '中小',\n",
       " '中间',\n",
       " '丰富',\n",
       " '临',\n",
       " '为',\n",
       " '为主',\n",
       " '为了',\n",
       " '为什么',\n",
       " '为什麽',\n",
       " '为何',\n",
       " '为着',\n",
       " '主张',\n",
       " '主要',\n",
       " '举行',\n",
       " '乃',\n",
       " '乃至',\n",
       " '么',\n",
       " '之',\n",
       " '之一',\n",
       " '之前',\n",
       " '之后',\n",
       " '之後',\n",
       " '之所以',\n",
       " '之类',\n",
       " '乌乎',\n",
       " '乎',\n",
       " '乘',\n",
       " '也',\n",
       " '也好',\n",
       " '也是',\n",
       " '也罢',\n",
       " '了',\n",
       " '了解',\n",
       " '争取',\n",
       " '于',\n",
       " '于是',\n",
       " '于是乎',\n",
       " '云云',\n",
       " '互相',\n",
       " '产生',\n",
       " '人们',\n",
       " '人家',\n",
       " '什么',\n",
       " '什么样',\n",
       " '什麽',\n",
       " '今后',\n",
       " '今天',\n",
       " '今年',\n",
       " '今後',\n",
       " '仍然',\n",
       " '从',\n",
       " '从事',\n",
       " '从而',\n",
       " '他',\n",
       " '他人',\n",
       " '他们',\n",
       " '他的',\n",
       " '代替',\n",
       " '以',\n",
       " '以上',\n",
       " '以下',\n",
       " '以为',\n",
       " '以便',\n",
       " '以免',\n",
       " '以前',\n",
       " '以及',\n",
       " '以后',\n",
       " '以外',\n",
       " '以後',\n",
       " '以来',\n",
       " '以至',\n",
       " '以至于',\n",
       " '以致',\n",
       " '们',\n",
       " '任',\n",
       " '任何',\n",
       " '任凭',\n",
       " '任务',\n",
       " '企图',\n",
       " '伟大',\n",
       " '似乎',\n",
       " '似的',\n",
       " '但',\n",
       " '但是',\n",
       " '何',\n",
       " '何况',\n",
       " '何处',\n",
       " '何时',\n",
       " '作为',\n",
       " '你',\n",
       " '你们',\n",
       " '你的',\n",
       " '使得',\n",
       " '使用',\n",
       " '例如',\n",
       " '依',\n",
       " '依照',\n",
       " '依靠',\n",
       " '促进',\n",
       " '保持',\n",
       " '俺',\n",
       " '俺们',\n",
       " '倘',\n",
       " '倘使',\n",
       " '倘或',\n",
       " '倘然',\n",
       " '倘若',\n",
       " '假使',\n",
       " '假如',\n",
       " '假若',\n",
       " '做到',\n",
       " '像',\n",
       " '允许',\n",
       " '充分',\n",
       " '先后',\n",
       " '先後',\n",
       " '先生',\n",
       " '全部',\n",
       " '全面',\n",
       " '兮',\n",
       " '共同',\n",
       " '关于',\n",
       " '其',\n",
       " '其一',\n",
       " '其中',\n",
       " '其二',\n",
       " '其他',\n",
       " '其余',\n",
       " '其它',\n",
       " '其实',\n",
       " '其次',\n",
       " '具体',\n",
       " '具体地说',\n",
       " '具体说来',\n",
       " '具有',\n",
       " '再者',\n",
       " '再说',\n",
       " '冒',\n",
       " '冲',\n",
       " '决定',\n",
       " '况且',\n",
       " '准备',\n",
       " '几',\n",
       " '几乎',\n",
       " '几时',\n",
       " '凭',\n",
       " '凭借',\n",
       " '出去',\n",
       " '出来',\n",
       " '出现',\n",
       " '分别',\n",
       " '则',\n",
       " '别',\n",
       " '别的',\n",
       " '别说',\n",
       " '到',\n",
       " '前后',\n",
       " '前者',\n",
       " '前进',\n",
       " '前面',\n",
       " '加之',\n",
       " '加以',\n",
       " '加入',\n",
       " '加强',\n",
       " '十分',\n",
       " '即',\n",
       " '即令',\n",
       " '即使',\n",
       " '即便',\n",
       " '即或',\n",
       " '即若',\n",
       " '却不',\n",
       " '原来',\n",
       " '又',\n",
       " '及',\n",
       " '及其',\n",
       " '及时',\n",
       " '及至',\n",
       " '双方',\n",
       " '反之',\n",
       " '反应',\n",
       " '反映',\n",
       " '反过来',\n",
       " '反过来说',\n",
       " '取得',\n",
       " '受到',\n",
       " '变成',\n",
       " '另',\n",
       " '另一方面',\n",
       " '另外',\n",
       " '只是',\n",
       " '只有',\n",
       " '只要',\n",
       " '只限',\n",
       " '叫',\n",
       " '叫做',\n",
       " '召开',\n",
       " '叮咚',\n",
       " '可',\n",
       " '可以',\n",
       " '可是',\n",
       " '可能',\n",
       " '可见',\n",
       " '各',\n",
       " '各个',\n",
       " '各人',\n",
       " '各位',\n",
       " '各地',\n",
       " '各种',\n",
       " '各级',\n",
       " '各自',\n",
       " '合理',\n",
       " '同',\n",
       " '同一',\n",
       " '同时',\n",
       " '同样',\n",
       " '后来',\n",
       " '后面',\n",
       " '向',\n",
       " '向着',\n",
       " '吓',\n",
       " '吗',\n",
       " '否则',\n",
       " '吧',\n",
       " '吧哒',\n",
       " '吱',\n",
       " '呀',\n",
       " '呃',\n",
       " '呕',\n",
       " '呗',\n",
       " '呜',\n",
       " '呜呼',\n",
       " '呢',\n",
       " '周围',\n",
       " '呵',\n",
       " '呸',\n",
       " '呼哧',\n",
       " '咋',\n",
       " '和',\n",
       " '咚',\n",
       " '咦',\n",
       " '咱',\n",
       " '咱们',\n",
       " '咳',\n",
       " '哇',\n",
       " '哈',\n",
       " '哈哈',\n",
       " '哉',\n",
       " '哎',\n",
       " '哎呀',\n",
       " '哎哟',\n",
       " '哗',\n",
       " '哟',\n",
       " '哦',\n",
       " '哩',\n",
       " '哪',\n",
       " '哪个',\n",
       " '哪些',\n",
       " '哪儿',\n",
       " '哪天',\n",
       " '哪年',\n",
       " '哪怕',\n",
       " '哪样',\n",
       " '哪边',\n",
       " '哪里',\n",
       " '哼',\n",
       " '哼唷',\n",
       " '唉',\n",
       " '啊',\n",
       " '啐',\n",
       " '啥',\n",
       " '啦',\n",
       " '啪达',\n",
       " '喂',\n",
       " '喏',\n",
       " '喔唷',\n",
       " '嗡嗡',\n",
       " '嗬',\n",
       " '嗯',\n",
       " '嗳',\n",
       " '嘎',\n",
       " '嘎登',\n",
       " '嘘',\n",
       " '嘛',\n",
       " '嘻',\n",
       " '嘿',\n",
       " '因',\n",
       " '因为',\n",
       " '因此',\n",
       " '因而',\n",
       " '固然',\n",
       " '在',\n",
       " '在下',\n",
       " '地',\n",
       " '坚决',\n",
       " '坚持',\n",
       " '基本',\n",
       " '处理',\n",
       " '复杂',\n",
       " '多',\n",
       " '多少',\n",
       " '多数',\n",
       " '多次',\n",
       " '大力',\n",
       " '大多数',\n",
       " '大大',\n",
       " '大家',\n",
       " '大批',\n",
       " '大约',\n",
       " '大量',\n",
       " '失去',\n",
       " '她',\n",
       " '她们',\n",
       " '她的',\n",
       " '好的',\n",
       " '好象',\n",
       " '如',\n",
       " '如上所述',\n",
       " '如下',\n",
       " '如何',\n",
       " '如其',\n",
       " '如果',\n",
       " '如此',\n",
       " '如若',\n",
       " '存在',\n",
       " '宁',\n",
       " '宁可',\n",
       " '宁愿',\n",
       " '宁肯',\n",
       " '它',\n",
       " '它们',\n",
       " '它们的',\n",
       " '它的',\n",
       " '安全',\n",
       " '完全',\n",
       " '完成',\n",
       " '实现',\n",
       " '实际',\n",
       " '宣布',\n",
       " '容易',\n",
       " '密切',\n",
       " '对',\n",
       " '对于',\n",
       " '对应',\n",
       " '将',\n",
       " '少数',\n",
       " '尔后',\n",
       " '尚且',\n",
       " '尤其',\n",
       " '就',\n",
       " '就是',\n",
       " '就是说',\n",
       " '尽',\n",
       " '尽管',\n",
       " '属于',\n",
       " '岂但',\n",
       " '左右',\n",
       " '巨大',\n",
       " '巩固',\n",
       " '己',\n",
       " '已经',\n",
       " '帮助',\n",
       " '常常',\n",
       " '并',\n",
       " '并不',\n",
       " '并不是',\n",
       " '并且',\n",
       " '并没有',\n",
       " '广大',\n",
       " '广泛',\n",
       " '应当',\n",
       " '应用',\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# source: https://github.com/goto456/stopwords/blob/master/baidu_stopwords.txt\n",
    "stop_words = open(\"/Users/mao_shiba/Downloads/stopwords-master/baidu_stopwords.txt\", 'r', encoding='utf-8').read()\n",
    "stop_words_lst = stop_words.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetDF = reviews\n",
    "textColumn = 'cut_words'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mao_shiba/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'aren', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "reviewTFVectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_df=0.5, max_features=1000, min_df=3, stop_words=stop_words_lst, norm='l2')\n",
    "#train\n",
    "reviewTFVects = reviewTFVectorizer.fit_transform(targetDF[textColumn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['毫无', '看点', '一个', '男人', '孤独', '心理', '恐怖', '好笑', '可惜', '旁白', '上海', '生活', '状态', '真实', '残酷', '描述', '片子', '这部', '手法', '好莱坞', '故事', '关键', '镜头', '类型', '震撼', '方式', '竟然', '香港', '小姐', '熊掉', '发现', '主妇', '哈哈哈哈', '哈哈哈', '师父', '系列', '不得不', '垃圾', '缺乏', '五星', '电影', '好玩', '喜感', '师傅', '初恋', '推荐', '此片', '烂片', '实在', '完整', '拍摄', '两位', '男主', '演员', '随便', '看过', '童年', '可爱', '几个', 'sp', '好看', '大哥', '小时候', '喜欢', '美女', '超级', '漫画', '稍微', '作品', '一颗', '徐海', '男女', '猪脚', '演技', '一点', '剧情', '效果', '第一个', '居然', '女孩', '这是', '难看', '清新', '台词', '受不了', '狗血', '时间', '无聊', 'ps', '感觉', '文艺', '女主', '特别', '气质', '前半段', '样子', '台湾', '题材', '过程', '不了', '老人', '经历', '四星', '一星', '中国', '岁月', '爱情', '第一次', '背景', '莫名', '两星', '青涩', '平淡', '惊喜', '真的', '女主角', '导演', '分钟', '文化', '编剧', '老套', '做作', '浮夸', '一部', '本片', '还行', '类似', '不错', '差不多', '海报', '确实', '那位', '形式', '传奇', '搞笑', '本身', '少女', '亮点', '片尾', '彩蛋', '字幕', '年代', '女人', '好像', '不好', '啊啊啊', '暴力', '长大', '感慨', '究竟', '记得', '主演', '没意思', '真心', '超越', '经典', '创意', '这片', '大学', '说话', '难道', '舒服', '眼睛', '也许', '是因为', '25', '爷爷', '出场', '老头', '肯定', '妹妹', '貌似', '配音', '吸引', '为啥', '东西', '才能', '明白', '吐槽', '声音', '恶心', '奇怪', '现实', '路上', '看着', '国产', '好听', '结局', '感人', '有点像', '回到', '地方', '主角', '自然', '很多', '对白', '不行', '一分', '简直', '摩托', '半小时', '看不下去', '好人', '矫情', '立意', '还好', '简单', '纯粹', '有没有', '过于', '几次', '令人', '剧本', '蹩脚', '有意思', '长得', '呵呵', '不想', '电视剧', '展现', '两个', '版本', '包法利', '美国', '舞会', '开头', '结尾', '改编', '讨厌', '夫人', '人物', '刻画', '配乐', '能力', '社会', '女性', '悲剧', '命运', '40', '福楼拜', '身份', '影片', '依旧', '黑色', '丈夫', '家庭', '成熟', '摄影', '相比', '小说', '情节', '像是', '高潮', '段落', '描写', '灵魂', '魅力', '显得', '法庭', '观众', '片儿', '原著', '呈现', '美好', '单纯', '依然', '美丽', '这句', '答案', '想要', '事物', '却是', '改变', '就算', '向往', '男性', '视角', '变得', '青年', '一生', '那段', '不到', '名著', '控制', '欲望', '女儿', '时代', '追求', '梦想', '生命', '法国人', '琼斯', '遗憾', '批判', '整体', '节奏', '细节', '自我', '拍出', '那种', '实际上', '时期', '主题', '可怜', '三星', '恋爱', '如同', '当年', '期待', '年轻', '有点儿', '一种', '理想', '没想到', '打动', '半个', '小时', '慢慢', '值得一看', '学习', '讲述', '爱情故事', '唯美', '表现', '不知', '饰演', '的确', '整部', '尴尬', '水准', '勉强', '文艺片', '适合', '善良', '男孩', '感动', '温情', '温馨', '时光', '享受', '鳗鱼', '儿子', '有个', '家人', '关系', '漂亮', '一把', '目的', '角色', '反而', '口味', '模式', '喜剧', '爸爸', '厉害', '之中', '兄弟', '风格', '忘记', '情况', '自恋', '信仰', '剪辑', '形象', '情感', '一场', '印象', '深刻', '场景', '表达', '出彩', '最佳', '一位', '浪漫', '女子', '平庸', '情人', '面对', '自杀', '早就', '加上', '十足', '画面', '精致', '那条', '环境', '片名', '意义', '不明', '服装', '精彩', '到位', '算是', '翻拍', '张士豪', '男生', '女生', '阳光', '勇气', '大人', '永远', '青春', '无敌', '天蝎座', '爱上', '多年', '一扇', '蓝色', '门前', '下午', '三点', '好不好', '三年', '五年', '更久', '体育老师', '我妈', '我闭', '看不见', '孟克柔', '告诉', '朋友', 'o型', '游泳队', '吉他社', '十七岁', '不再', '直线', '该是', '多么', '幸福', '小朋友', '夏天', '到底', '一段', '至少', '人生', '观看', '感情', '電影', '典型', '17', '幻想', '想象', '桂纶', '陈柏霖', '少年', '一脸', '表情', '之作', '很漂亮', '一個', '真人', '不少', '配角', '龙套', '3d', '动画', '没什么', '身上', '强奸', '男主角', '一群', '造型', '表演', '游戏', '不太', '埃及', '未来', '音乐', '四个', '相遇', '般的', '压抑', '色彩', '语言', '出色', '糟糕', '故事情节', '神奇', '科幻', '科幻片', '哲学', '别人', '看不懂', 'cg', '乏味', '混乱', '动画片', '三个', '外星人', '成功', '高中', '回来', '怀念', '没看', '只能', '十年', '一堆', '视觉', '干嘛', '看得', '等待', '成长', '日本', '电视', '小孩', '好多', '带来', '战争', '最终', '西班牙', '调度', '姐姐', '监狱', '母亲', '国家', '遭遇', '革命', '苦难', '情绪', '痛苦', '精神', '恐惧', '片中', '女演员', '时刻', '死亡', '太多', '不算', '宗教', '直白', '孩子', '角度', '全片', '气氛', '象征', '民族', '之间', '估计', '青春片', '反正', '温暖', '一句', '办法', '大门', '评价', '理解', '世界', '眼神', '欣赏', '一幕', '质感', '诠释', '细腻', '如今', '暧昧', '充满', '危险', '主人公', '那年', '回忆', '遇见', '体验', '设计', '懵懂', '动人', '元素', '完美', '发展', '那句', '纠结', '传统', '几处', '打开', '难以', '原版', '莫名其妙', '美的', '夸张', '太帅', '法国', '很棒', '一遍', '值得', '冒险', '老版', '符合', '黑暗', '无比', '失败', '明明', '无论是', '结束', '学生', '大概', '杀人', '复仇', '意外', '场面', '特效', '神话', '设定', '很大', '老师', '浪费', '女神', '身材', '诡异', '一半', '眼泪', '宿命', '人类', '视觉效果', '原作', '地球', '来说', '唯一', '豆瓣', '名字', '政治', '事件', '包括', '意识', '忽略', '导致', '35', '妈妈', '大片', '难得', '差点', '父亲', '无趣', '足够', '第一', '伯爵', '上译', '从头到尾', '更好', '设置', '基督山', '睿智', '疯狂', '报仇', '愚蠢', '记忆', '很帅', '不停', '寻找', '面瘫', '衬衫', '還是', '天空', '未知', '探索', '留下', '发生', '淡淡的', '想起', '执着', '年纪', '动作', '放弃', '很少', '结构', '科学', '可怕', '一塌糊涂', '人性', '感受', '婴儿', '一般般', '拍成', '内容', '演绎', '历史', '希望', '尸体', '没法', '影响', '区别', '英文', '迷人', '卡司', '感到', '大叔', '中年', '强大', '还要', '小孩子', '美感', '这次', '欢乐', '讽刺', '叙事', '城市', '婚姻', '价值观', '有趣', '黑色幽默', '乐观', '至今', '倔强', '热血', '摩托车', '再也', '英雄', '事情', '仅仅', '拍得', '认同', '找到', '神秘', '作者', '氛围', '始终', '模糊', '内心', '不知所云', '制作', '英语', '水平', '粗糙', '心中', '接受', '传说', '老爸', '翻译', '几年', '制片', '熟悉', '迷茫', '总会', '模仿', '终究', '痕迹', '严肃', '在于', '艺术', '本来', '中规中矩', '比起', '套路', '香川', '宽叔', '想到', '味道', '终于', '公路', '蔬菜', '励志', '自由', '霍普金斯', '所有人', '剧场', 'cctv6', '一只', '儿童', '看起来', '坏人', '全程', '越来越', '西方', '大战', '一张', '人设', '致敬', '邪恶', '调调', '好评', '拖沓', '想法', '对话', '正确', '黑人', '绝望', '第一部', '快乐', '困惑', '心情', '勇敢', '技巧', '或许', '刚刚', '正义', '塑造', '好好', '爱情片', '插叙', '努力', '一部分', '有种', '克制', '挺不错', '老爷子', '轻松', '逻辑', '江湖', '戏份', '思考', '野人', '恐怖片', '仿佛', '每次', '介绍', '重复', '来看', '英国', '法式', '身边', '影像', '外衣', '性感', '20', '结婚', '干净', '想想', '剩下', '技术', '思想', '内涵', '微妙', '体现', '张力', '刺激', '挑战', '针对', '警察', '解读', '法语', '悬念', '太过', '解决', '更是', '译名', '小女孩', '妹子', '有人', '一件', '能量', '程度', '失望', '智慧', '凶手', '同学', '片段', '飞机', '漫长', '征服', '老爷', '竹内', '结子', '牵强', '煽情', '田村正和', '加一星', '星给', '喜歡', '女朋友', '两人', '新意', '道格拉斯', '接近', '火车', '韩国', '开心', '一路', '一如既往', '剪辑版', '史诗片', '桥段', '冗长', '沉闷', '史诗', '亚历山大', '功力', '回归', '冲突', '情怀', '长镜头', '真相', '田村', '讨论', '夫妻', '特写', '情欲', '生硬', '影院', '激情', '15', '影子', '工作', '血腥', '小乔', '小品', '困境', 'jimmy', '神经', '姑娘', '那场', '婚礼', '爱情喜剧', '选择', '回家', '一贯', '凯奇', '拯救', '悬疑', '灾难片', '灾难', '李修贤', '古装', '邵氏', '刻意', '俗套', '反派', '文明', '武侠', '原因', '互动', '睡着', '力量', '幽默', '预言', '毁灭', '记住', '姐妹', '运动', '一黑', '切换', '空间', '冥王星', '章明', '聪明', '美慧孜', '巫山', '东方', '创作', '采风', '寡妇', '老罗', '探讨', '转换', '知识分子', '学兵', '美学', '神秘主义', '观感', '一剑', '橄榄球', '50', '阿凡提', '巴依', '一代', '谈恋爱', '新疆', '穆斯林', '灵性', '潮湿', '王准', '张彻', '概念', '亚当', '北野', '北野武', '大佬', '黑帮', '极恶', '非道', '黑帮片', '切腹', '情义', '艺术片', '桑德勒', '特色', '澳洲', '土著', '澳大利亚', '闹剧', '偷走', '白人', '上课', '妻子', '伯格曼', '金燕子', '谁家', '白衣', '王羽', '胡金', '大醉侠', '郑佩佩', '银鹏', '记者', '黄璐', '犹太人', '李政宰', '李美淑', '老挝', '田中', '丽奈'])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewTFVectorizer.vocabulary_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA = sklearn.decomposition.PCA\n",
    "pca = PCA(n_components = 2).fit(reviewTFVects.toarray())\n",
    "reduced_data = pca.transform(reviewTFVects.toarray()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_silhouette_avg(n_clusters, X):\n",
    "    '''\n",
    "    calculate silhouette scores.\n",
    "    '''\n",
    "    clusterer = sklearn.cluster.KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "    silhouette_avg = sklearn.metrics.silhouette_score(X, cluster_labels)\n",
    "    return silhouette_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 0.09804640367235036)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = reviewTFVects.toarray()\n",
    "current_score_tup = (0, 0)\n",
    "for i in range(4, 25, 2):\n",
    "    score = cal_silhouette_avg(i, X)\n",
    "    if current_score_tup[1] < score:\n",
    "        current_score_tup = (i, score)\n",
    "current_score_tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=24)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewKM = sklearn.cluster.KMeans(n_clusters = 24, init='k-means++')\n",
    "reviewKM.fit(reviewTFVects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = list(plt.cm.rainbow(np.linspace(0,1, 24)))\n",
    "colors_p = [colors[l] for l in reviewKM.labels_]\n",
    "fig = plt.figure(1)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_frame_on(False)\n",
    "plt.scatter(reduced_data[:, 0], reduced_data[:, 1], color = colors_p, alpha = 0.5)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title('Predicted Clusters\\n k = {}'.format(24))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a sampled 5000 reviews set from a corpus of over 4 million movie reviews. It's not surprising that we can hardly tell the differences of the 24 predicted categories from the figure. The sample size is small given the we set number of topics as 24 according the silhouette score. And the format of those reviews are short reviews, I think it makes the clustering process more difficult(or, unreliable is a more proper word). \n",
    "\n",
    "One implication could be that 24 categories might not be meaninglesss. On douban.com, movies are categorized into 22 genres. The clustering results may reveal distinct patterns of movies of different genres.\n",
    "\n",
    "Another interesting thing abouth the results is that all the clusters are distributed on one of the directions that is perpendicular to each other. I think this indicates reviews can be largely divided into 2 categories. And it's partially determined by the format, partially driven by strightforward value judgements. I think these reviews can strongly correlated with ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_time</th>\n",
       "      <th>content</th>\n",
       "      <th>douban_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>cut_words</th>\n",
       "      <th>kmeans_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-05 19:42:07</td>\n",
       "      <td>480p画质不高黑白y</td>\n",
       "      <td>5113101</td>\n",
       "      <td>2.0</td>\n",
       "      <td>480p 画质 不高 黑白 y</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-09 14:52:07</td>\n",
       "      <td>毫无看点黑白画质一个男人孤独的心理情景历程疯疯癫癫没有任何恐怖的成分这应该是剧情片吧</td>\n",
       "      <td>5113101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>毫无 看点 黑白 画质 一个 男人 孤独 的 心理 情景 历程 疯疯癫癫 没有 任何 恐怖 ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-11-05 22:15:44</td>\n",
       "      <td>上吊那裡超好笑可惜最後報告近況的旁白大扣分</td>\n",
       "      <td>3718526</td>\n",
       "      <td>3.0</td>\n",
       "      <td>上吊 那裡 超 好笑 可惜 最後報 告近況 的 旁白 大 扣分</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-06-20 02:12:50</td>\n",
       "      <td>上海国际电影节观摩片</td>\n",
       "      <td>3718526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>上海 国际 电影节 观摩 片</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-04-09 22:10:13</td>\n",
       "      <td></td>\n",
       "      <td>3718526</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>2010-09-11 13:46:02</td>\n",
       "      <td>搞笑的励志电影</td>\n",
       "      <td>1309050</td>\n",
       "      <td>5.0</td>\n",
       "      <td>搞笑 的 励志 电影</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>2010-10-23 13:19:17</td>\n",
       "      <td>美国所谓的人权</td>\n",
       "      <td>1309050</td>\n",
       "      <td>3.0</td>\n",
       "      <td>美国 所谓 的 人权</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2009-01-22 18:36:13</td>\n",
       "      <td>2009121在书房跟老公一起看的没看完但看过的部分很精彩期待</td>\n",
       "      <td>1309050</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2009121 在 书房 跟 老公 一起 看 的 没 看 完 但 看过 的 部分 很 精彩 期待</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2011-10-19 12:00:27</td>\n",
       "      <td>我喜欢亚当桑德勒说橄榄球跟乒乓球差不多就是是蛋形的跟我的头一样lol另外我的Alexmaho...</td>\n",
       "      <td>1309050</td>\n",
       "      <td>3.0</td>\n",
       "      <td>我 喜欢 亚当 桑德勒 说 橄榄球 跟 乒乓球 差不多 就是 是 蛋形 的 跟 我 的 头 ...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2009-05-23 19:02:22</td>\n",
       "      <td>好久没看这么搞笑的片了哈哈</td>\n",
       "      <td>1309050</td>\n",
       "      <td>4.0</td>\n",
       "      <td>好久没 看 这么 搞笑 的 片 了 哈哈</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             comment_time                                            content  \\\n",
       "0     2018-09-05 19:42:07                                        480p画质不高黑白y   \n",
       "1     2019-07-09 14:52:07         毫无看点黑白画质一个男人孤独的心理情景历程疯疯癫癫没有任何恐怖的成分这应该是剧情片吧   \n",
       "2     2010-11-05 22:15:44                              上吊那裡超好笑可惜最後報告近況的旁白大扣分   \n",
       "3     2010-06-20 02:12:50                                         上海国际电影节观摩片   \n",
       "4     2011-04-09 22:10:13                                                      \n",
       "...                   ...                                                ...   \n",
       "4995  2010-09-11 13:46:02                                            搞笑的励志电影   \n",
       "4996  2010-10-23 13:19:17                                            美国所谓的人权   \n",
       "4997  2009-01-22 18:36:13                    2009121在书房跟老公一起看的没看完但看过的部分很精彩期待   \n",
       "4998  2011-10-19 12:00:27  我喜欢亚当桑德勒说橄榄球跟乒乓球差不多就是是蛋形的跟我的头一样lol另外我的Alexmaho...   \n",
       "4999  2009-05-23 19:02:22                                      好久没看这么搞笑的片了哈哈   \n",
       "\n",
       "      douban_id  rating                                          cut_words  \\\n",
       "0       5113101     2.0                                    480p 画质 不高 黑白 y   \n",
       "1       5113101     1.0  毫无 看点 黑白 画质 一个 男人 孤独 的 心理 情景 历程 疯疯癫癫 没有 任何 恐怖 ...   \n",
       "2       3718526     3.0                    上吊 那裡 超 好笑 可惜 最後報 告近況 的 旁白 大 扣分   \n",
       "3       3718526     NaN                                     上海 国际 电影节 观摩 片   \n",
       "4       3718526     NaN                                                      \n",
       "...         ...     ...                                                ...   \n",
       "4995    1309050     5.0                                         搞笑 的 励志 电影   \n",
       "4996    1309050     3.0                                         美国 所谓 的 人权   \n",
       "4997    1309050     3.0   2009121 在 书房 跟 老公 一起 看 的 没 看 完 但 看过 的 部分 很 精彩 期待   \n",
       "4998    1309050     3.0  我 喜欢 亚当 桑德勒 说 橄榄球 跟 乒乓球 差不多 就是 是 蛋形 的 跟 我 的 头 ...   \n",
       "4999    1309050     4.0                               好久没 看 这么 搞笑 的 片 了 哈哈   \n",
       "\n",
       "      kmeans_predictions  \n",
       "0                      0  \n",
       "1                      9  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "...                  ...  \n",
       "4995                   4  \n",
       "4996                   0  \n",
       "4997                   6  \n",
       "4998                  15  \n",
       "4999                   0  \n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetDF['kmeans_predictions'] = reviewKM.labels_\n",
    "targetDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Clustering with Wald's Method\n",
    "\n",
    "Next we approach a hierchical clustering method, which proposes nested clusters at any resolution (at the finest resolution, every document is its own cluster).\n",
    "\n",
    "Here we must begin by calculating how similar the documents are to one another.\n",
    "\n",
    "As a first pass, we take our matrix of word counts per document\n",
    "`newsgroupsTFVects` and create a word occurrence matrix measuring how similar\n",
    "the documents are to each other based on their number of shared words. (Note one could perform the converse operation, a document occurrence matrix measuring how similar  words are to each other based on their number of collocated documents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroupsTFVects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroupsTFVects[:100].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroupsCoocMat = newsgroupsTFVects * newsgroupsTFVects.T\n",
    "#set the diagonal to 0 since we don't care how similar texts are to themselves\n",
    "newsgroupsCoocMat.setdiag(0)\n",
    "#Another way of relating the texts is with their cosine similarity\n",
    "#newsgroupsCosinMat1 = 1 - sklearn.metrics.pairwise.cosine_similarity(newsgroupsTFVects)\n",
    "#But generally word occurrence is more accurate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute a tree of nested clusters. Here we will only look at the first 50 texts of each class because drawing the dendrograms can be computationally intensive (and visually complex)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectIndices = []\n",
    "indexToCat = []\n",
    "for c in set(newsgroupsDF['category']):\n",
    "    selectIndices += list(newsgroupsDF[newsgroupsDF['category'] == c].index)[:50]\n",
    "    indexToCat += [c] * 50\n",
    "    #.groupby('category').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subCoocMat = newsgroupsCoocMat[selectIndices,:][:,selectIndices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_matrix = scipy.cluster.hierarchy.ward(subCoocMat.toarray())\n",
    "linkage_matrix[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dendDat = scipy.cluster.hierarchy.dendrogram(linkage_matrix, get_leaves=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot may seem somewhat unwieldy. To make it easier to read, we can cut the tree after a number of branchings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dendrogramDat = scipy.cluster.hierarchy.dendrogram(linkage_matrix, p=4, truncate_mode='level', get_leaves=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the tree is colored to show the clusters based on their ['distance'](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.cluster.hierarchy.dendrogram.html#scipy.cluster.hierarchy.dendrogram) from one another, but there are other ways of forming hierarchical clusters.\n",
    "\n",
    "Another approach involves cutting the tree into `n` branches. We can do this with [`fcluster()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.fcluster.html#scipy.cluster.hierarchy.fcluster). Lets break the tree into 4 clusters. When we do this with all of the data in the dataframe, as below, we can add those clusters back for detailed evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchicalClusters = scipy.cluster.hierarchy.fcluster(linkage_matrix, 4, 'maxclust')\n",
    "hierarchicalClusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this *get clusters* like we did with k-means. What if we do the full data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_matrix_full = scipy.cluster.hierarchy.ward(newsgroupsCoocMat.toarray())\n",
    "hierarchicalClusters_full = scipy.cluster.hierarchy.fcluster(linkage_matrix_full, 4, 'maxclust')\n",
    "print(\"For our complete clusters:\")\n",
    "print(\"Homogeneity: {:0.3f}\".format(sklearn.metrics.homogeneity_score(newsgroupsDF['category'], hierarchicalClusters_full)))\n",
    "print(\"Completeness: {:0.3f}\".format(sklearn.metrics.completeness_score(newsgroupsDF['category'], hierarchicalClusters_full)))\n",
    "print(\"V-measure: {:0.3f}\".format(sklearn.metrics.v_measure_score(newsgroupsDF['category'], hierarchicalClusters_full)))\n",
    "print(\"Adjusted Rand Score: {:0.3f}\".format(sklearn.metrics.adjusted_rand_score(newsgroupsDF['category'], hierarchicalClusters_full)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not quite as good as k-means. Perhaps we've got too many words for Ward or maybe we shouldn't be using TFIDF as that compresses the space. Still, the hierarchical model places constraints on the clustering not present with k-means, which come at a cost. Finally, we can bring those cluster assignments back to the data frame for deeper investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroupsDF['wald_predictions'] = hierarchicalClusters_full\n",
    "newsgroupsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's do it with Senate press release data\n",
    "\n",
    "We can also do hierarchical clustering with the Senate data. Let's start by creating the linkage matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exampleCoocMat = exampleTFVects * exampleTFVects.T\n",
    "exampleCoocMat.setdiag(0)\n",
    "examplelinkage_matrix = scipy.cluster.hierarchy.ward(exampleCoocMat[:100, :100].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And visualize the tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = scipy.cluster.hierarchy.dendrogram(examplelinkage_matrix, p=5, truncate_mode='level')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do it with the entire data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_linkage_matrix_full = scipy.cluster.hierarchy.ward(exampleCoocMat.toarray())\n",
    "example_hierarchicalClusters_full = scipy.cluster.hierarchy.fcluster(example_linkage_matrix_full, 4, 'maxclust')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">*Exercise 2*</font>\n",
    "\n",
    "<font color=\"red\">Construct cells immediately below this that hierarchically cluster your documents using two approaches, and visualize them with a tree. Interrogate the recursive cluster contents in terms of both documents and closenesses. What does this nested cluster structure reveal about the organization of documents in your sampled corpora? Moreover, if they do worse than kmeans (as above), why do you think this is the case (hint: using metrics if you have ground truth or silhouette if you do not)? \n",
    "\n",
    "<font color=\"red\">***Stretch***: Attempt using different distances into your clustering algorithms. (How) do they change the arrangement of clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mao_shiba/opt/anaconda3/lib/python3.8/site-packages/scipy/sparse/_index.py:125: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "reviewCoocMat = reviewTFVects * reviewTFVects.T\n",
    "reviewCoocMat.setdiag(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mao_shiba/opt/anaconda3/lib/python3.8/site-packages/scipy/cluster/hierarchy.py:834: ClusterWarning: scipy.cluster: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
      "  return linkage(y, method='ward', metric='euclidean')\n"
     ]
    }
   ],
   "source": [
    "review_linkage_matrix = scipy.cluster.hierarchy.ward(reviewCoocMat.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dendrogramDat = scipy.cluster.hierarchy.dendrogram(review_linkage_matrix, p=4, truncate_mode='level', get_leaves=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAENCAYAAADjW7WQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAkzUlEQVR4nO3debwdRZn/8c+ThCXsCbmQsC/GABrWKCg7yIgQCCoIIhgiElQYEEVBxEGGYVEZFEQ2kRDZQwSCgCCyODrODwmCRMAIP1QECUSZEdERwdT88VRz63bO0n2WnHtvf9+v133d23Wqq+tUdz9dXdXnXAshICIi1TCi1xUQEZFlR0FfRKRCFPRFRCpEQV9EpEIU9EVEKkRBX0SkQkY1y2BmVwBTgRdDCG+NaWOBG4CNgN8AHwgh/Hd87XPAkcA/gONCCHc128a4cePCRhtt1No7EBGpqIceeugPIYS+MutYs+f0zWwX4BXg20nQ/zLwUgjhHDM7GRgTQjjJzLYArgPeDqwD/AB4cwjhH422MWXKlDB//vwy9RYRqTwzeyiEMKXMOk2Hd0II/wG8lEueBsyOf88GDkjSrw8hvBpC+DXwFH4BEBGRQaDVMf21QwjPA8Tfa8X0dYHfJfmejWkiIjIIdHoi12qk1Rw/MrOZZjbfzOYvXry4w9UQEZFaWg36L5jZBID4+8WY/iywfpJvPeD3tQoIIVwWQpgSQpjS11dqHkJERFrUatC/FZge/54OzEvSDzGzFcxsY2Ai8NP2qigiIp1S5JHN64DdgHFm9ixwGnAOMMfMjgSeAQ4CCCE8ZmZzgMeB14Fjmj25IyIiy07ToB9C+GCdl/ask/9M4Mx2KiUiIt3RNOjL8HbtA88w75Hnel0NkY6ZtvW6HLr9Br2uxqClr2GouHmPPMfjz7/c62qIdMTjz7+sTkwT6ukLW0xYjRuOfkevqyHStoMv/a9eV2HQU09fRKRCFPRFRCpEQV9EpEIU9EVEKkRBX0SkQhT0RUQqREFfRKRCFPRFRCpEQV9EpEIU9EVEKkRBX0SkQhT0RUQqREFfRKRCFPRFRCpEQV9EpEIU9EVEKkRBX0SkQhT0RUQqREFfRKRCFPRFRCpEQV9EpEIU9EVEKkRBX0SkQhT0RUQqREFfRKRCFPRFRCpEQV9EpEIU9EVEKkRBX0SkQhT0RUQqREFfRKRC2gr6ZnaCmT1mZr8ws+vMbEUzG2tmd5vZk/H3mE5VVkRE2tNy0DezdYHjgCkhhLcCI4FDgJOBe0IIE4F74rKIiAwC7Q7vjAJGm9koYCXg98A0YHZ8fTZwQJvbEBGRDmk56IcQngPOBZ4Bngf+FEL4PrB2COH5mOd5YK1OVFRERNrXzvDOGLxXvzGwDrCymR1WYv2ZZjbfzOYvXry41WqIiEgJ7QzvvAv4dQhhcQjhNeAm4J3AC2Y2ASD+frHWyiGEy0IIU0IIU/r6+tqohoiIFNVO0H8G2MHMVjIzA/YEngBuBabHPNOBee1VUUREOmVUqyuGEB4ws7nAz4DXgYeBy4BVgDlmdiR+YTioExUVEZH2tRz0AUIIpwGn5ZJfxXv9IiIyyOgTuSIiFaKgLyJSIQr6IiIVoqAvIlIhCvoiIhWioC8iUiEK+iIiFaKgLyJSIQr6IiIVoqAvIlIhCvoiIhWioC8iUiEK+iIiFaKgLyJSIQr6IiIVoqAvIlIhCvoiIhWioC8iUiEK+iIiFaKgLyJSIQr6IiIVoqAvIlIhCvoiIhWioC8iUiEK+iIiFaKgLyJSIQr6IiIVoqAvIlIhCvoiIhWioC8iUiEK+iIiFaKgLyJSIQr6IiIVoqAvIlIhbQV9M1vDzOaa2S/N7Akze4eZjTWzu83syfh7TKcqKyIi7Wm3p38+cGcIYTNgK+AJ4GTgnhDCROCeuCwiIoNAy0HfzFYDdgG+BRBC+HsI4X+AacDsmG02cEB7VRQRkU4Z1ca6mwCLgVlmthXwEHA8sHYI4XmAEMLzZrZWrZXNbCYwE2CDDTZooxo9Nn8WLJjb61q0btE0/z3r33pbj3ZMPhCmzOh1LUSGhHaGd0YB2wIXhxC2Af5CiaGcEMJlIYQpIYQpfX19bVSjxxbMhUULel2Llt2wwTxu2GBer6vRukULhvZFV2QZa6en/yzwbAjhgbg8Fw/6L5jZhNjLnwC82G4lB73xk2HG7b2uRTXN2rfXNRAZUlru6YcQFgG/M7NJMWlP4HHgVmB6TJsODOFupIjI8NJOTx/gn4FrzGx54GlgBn4hmWNmRwLPAAe1uQ0REemQtoJ+COERYEqNl/Zsp1wREekOfSJXRKRCFPRFRCpEQV9EpEIU9EVEKkRBX0SkQhT0RUQqREFfRKRC2v1w1uDX7S9EW/So/+7m1wHoC8VEpEOGXtAvG8QXPQqvvgwrrFZ8nZX7YNUJxfKO37J4ua3IvsxNQV9EOmDoBf3sWy3HTy6Wv2xQXrTAA/5g+QI1faGYiHTQ0Av60N1vtVSQFZFhTBO5IiIVoqAvIlIhQ3N4R4YOPT0lMqiopy/d1e1/Jzl+y+4+QaV/xyjDjHr60n1D+d9JamJfhhn19EVEKkRBX0SkQhT0RUQqREFfRKRCFPRFRCpEQV9EpEIU9EVEKkRBX0SkQhT0RUQqREFfRKRCFPRFRCpEQV9EpEIU9EVEKkRBX0SkQhT0RUQqREFfRKRCFPRFRCqk7aBvZiPN7GEzuy0ujzWzu83syfh7TPvVFBGRTuhET/944Ilk+WTgnhDCROCeuCwiIoNAW0HfzNYD9gUuT5KnAbPj37OBA9rZhoiIdE67Pf2vAZ8FliRpa4cQngeIv9dqcxsiItIhLQd9M5sKvBhCeKjF9Wea2Xwzm7948eJWqyEiIiW009PfEdjfzH4DXA/sYWZXAy+Y2QSA+PvFWiuHEC4LIUwJIUzp6+troxoiIlJUy0E/hPC5EMJ6IYSNgEOAe0MIhwG3AtNjtunAvLZrKSIiHdGN5/TPAfYysyeBveKyiIgMAqM6UUgI4X7g/vj3H4E9O1GuiIh0lj6RKyJSIQr6IiIVoqAvIlIhCvoiIhWioC8iUiEK+iIiFdKRRzalQubPggVzi+df9Kj/nrVv8XUmHwhTZpSrl4gUop6+lLNgLixaUDz/+C39p6hFC8pdVESkFPX0pbzxk2HG7d0pu8wdgYiUpp6+iEiFKOiLiFSIgr6ISIVoTF9qq/eUTqOncfTUjcigp56+1FbvKZ16T+PoqRuRIUE9famvzFM6eupGZEhQT19EpEIU9EVEKkTDO9IbmigW6Qn19KU3NFEs0hPq6UvvaKJYZJlTT19EpEIU9EVEKkRBX0SkQhT0RUQqREFfRKRCFPRFRCpk8D6yqQ/viIh03ODt6evDOyIiHTd4e/qgD++IiHTY4O3pi4hIxw3unn439WrOoN5262lUn3o0t1Gf2l8qrro9/V7NGdTbbj316lOP5jYaU/tLxVW3pw+9mzMos92yNLfRnNpfKqy6PX0RkQpqOeib2fpmdp+ZPWFmj5nZ8TF9rJndbWZPxt9jOlddERFpRzs9/deBT4cQNgd2AI4xsy2Ak4F7QggTgXvisoiIDAItB/0QwvMhhJ/Fv/8MPAGsC0wDZsdss4ED2qyjiIh0SEfG9M1sI2Ab4AFg7RDC8+AXBmCtTmxDRETa13bQN7NVgO8AnwwhvFxivZlmNt/M5i9evLjdaoiISAFtBX0zWw4P+NeEEG6KyS+Y2YT4+gTgxVrrhhAuCyFMCSFM6evra6caIiJSUDtP7xjwLeCJEMJ5yUu3AtPj39OBea1XT0REOqmdD2ftCBwOLDCzR2LaKcA5wBwzOxJ4BjiorRqKiEjHtBz0Qwg/BqzOy3u2Wq6IiHSPPpErIlIhCvoiIhWioC8iUiHV/pZNEWnJjb+6kTuevqPX1VjKwpd2BWDGnZf1uCZL22eTfTjozb1/rkVBX0RKu+PpO1j40kImjZ3U66oMsM02P+x1FWpa+NJCAAV9ERm6Jo2dxKy9Z/W6GkPCjDsHz39S05i+iEiFKOiLiFSIgr6ISIUo6IuIVIgmcmV4mj8LFsxdOn3Ro/671j8wn3wgTBk8E24i3aCevgxPC+bCogVLp4/f0n/yFi2ofZEQGWbU05fha/xkmHF7sby1ev4iw5B6+iIiFaKefrdoTFlEBiH19LtFY8oiMgipp99NGlMWkUFGPX0RkQpR0BcRqRAFfRGRClHQFxGpEAV9EZEK0dM7IsNYt/6t4S9f+iXQnX8OMlj+reBwpZ6+yDCW/VvDTtts7GZsNnazjpe78KWFg/J/7w4n6umLDCFle+5Zj7yMXva0B9O/FRyu1NMXGULK9tzL9sjV0x7+1NMXGYTq9egb9dw70UNXT3v4U09fZBCq16Ov13NXD12KUk9fZJCaNHYSs/aeVSiveuhSlHr6IiIVop6+iCwTRZ48Kvr8v57lb52Cvoh0VKNJ6Fdee4VVlltlqdfWHL0mfaP7Cj1plM11KOi3RkFfRDoqm4SeNHbSgPR6AX3hSwvpG923zOcvWvm0ctnPPWQXs3Y/wdzJOxsF/aFK/46xt4Z4+zd7JDQfnMoGncE0Cd3OnUcRry15jdeWvLZU+pKwhL++/lf++L9/HLDNsuV3+s6ma0HfzPYGzgdGApeHEM7p1rYqKft3jOMnD0yv9a8Yof9fNw6SoDPkDfH2L9MbH+rDKcvizqNW+fX06s4m05Wgb2YjgW8AewHPAg+a2a0hhMe7sb3K0r9j7K0h3v5Fe+PD4XHQbt95DKY7m2a69cjm24GnQghPhxD+DlwPTOvStkREpCALIXS+ULMDgb1DCB+Ny4cD24cQjk3yzARmxsVJQOe/ClBEZHjbMIRQbHIg6taYvtVIG3B1CSFcBlzWpe2LiEgN3RreeRZYP1leD/h9l7YlIiIFdSvoPwhMNLONzWx54BDg1i5tS0RECurK8E4I4XUzOxa4C39k84oQwmPd2JaIiBTXlYlcEREZnPQtmyIiFaKgLyJSIUMy6JtZrUdCh0z5Q91Qbp+hXHeRThiSQT/EiYhmJ3CrJ3i3yh/q+TPdbv+iWim/aN1bKb9M/sG2b7uV38wmlCm3lbq0sv6yOldyZUw0sylmNjJ+VU3bWqnXkJrINbOT8AvVA8B/xKeERoQQluTy7QT8PITw58FQ/lDPn6x3Mv7Bu660f7L+psA/Qgi/6VT9i9a9lfKL5Dez44GXgFdCCDcXKHNQ5c+tux+wPfCF0CCAmNm7gY8DR4UQFhcodxvghRBCqc/0mNm2+OeCHgEWhxD+uiz3bS7/lsC6+DcMPBdCeDWmHwCcDjyFf45pITA7hPCXIuUm5e8KvA34HXBnCOFPZdaHodfTvw74C7A3cKuZrRhCWJJe7cxsC+A9wO1mtl9c7mT5mwJTi5ZvZpsD+5TIX6r+LeQvVZ+ca4FXaNw+7ZSPmW0PHAVcamYzzWz1GvVvZf9eS5N9G8ufVKb+JfI/AfwR+JyZnWVmGzSp72Ml85ctv2x+4I1A/q/A/fmAnzsO9gW+CJxfMOC/G7gYGFOkHsl6++Pf7fUhPKh+ycwmxH07Ipe37LlYNv9U4BrgaODf8GMNM1szpn0whPB+4OfADOAEM1u1xHvdD//m4rWB/fDgn71WvMcfQhj0P8BYYHz8exTeY7sM/xDYGjF9RHbnHn+/DzgNuBx4TyfKB/4pWadw+TH/QUXyl61/K++3TH1i3rOBt2Tba9T+rZRfZ5tvwT/QdwawVxvteSVwUPx7ZJNjZ/ky+7dIfmDn3DpjgG8D5wLb1ihze2Bcsl+b5Z9esvxS9cnl3Rr4LXBAsu42wIbAysnx0Qf8D3B2TFsHD4CHZu8rV+5U4NFs+7XyNKjTJcC0+Pe2+AXpBuL53O6xXzQ/sB3wOLB1XD4RuDH+vTrwI2CPJP9cPIB/sOD7XAm4EXhbXD4TOB7YDBhb6xysW1aZE7EXP7Ghrwd+iX+JW/raRcBDwPL4ifzh3OvrA9OB7wC7tVn+RcCvgO2KlA8cB3wgt6M3aZC/VP1byF+qPkmeK4E7sgMr99rFSfucDXwe+FTy+gbNyk/yHo73ftYBxsS09YBTgS/Hn/3TcprVHzgPv5X+PrBevX2btOchJAGnUf2L5MdPzGeAY3Prroaf8F+p0db3AfcAOyTpq9fJ/w3gpmR5RFL+12rkL1WfGu25HnAv8FH8AvBjYB4ewM4CVkvyvj++fkxc5yv48MtFwAq5cr8F/Cr+vQpwTkzbD1ixTl1GJvvh5Nw5cDrw78DomFbq2KSFcwV4E3B0Wr943K0blz8GXIUf52cCV+O9/ysatXlS3kqxHU8EJuDDRDfHY+YGYK0i5YQwyIM+cAXwnfj3TPyWKd+jvCgeIP8f+BtLB8I+fFzxdGD1Fst/BA981wLH514fmy8f7zl9Dw86VwGXJvnXqpF/4zL1byF/qfokr20GfDdZXheYUKN9foH3yqfjF9CNi5Sf5LkmHsAX4MHqNGDt+Nra+FDH48DngEvxIYOG5ePBYA4eqC4A3hHTV8jV/at4b/GmOnWrtb+K5j8YP7nPAj6byzcGuB/4fFw+Bbg5/n06foczAhhVJ/9c4MqkvBUZeAFaI80f0/YrWp/ca+8idnbwXv1d+PF3VEzbJZZ7MDEYx/T34sfoZ5I6/hdwTFyeGH+PiPvo/+FzLp8Bjo31ObBGffYCjoh/b4ufn9ndnAE74Mf5ePwcL3xsUv7cfRf9dygrxt+jgJXje83e41bAEcAs4KtJmbeRXCzrtP028e/t8DvUu4AzY9pG+PE4tV4ZS5VZNOOy/sGvrKcmy+cCP4g7Yv8k/U34lfPj+FX0JZYOhFvjV8TNk7RN8YmoZuVfjd8FrIAPOfwGeHu98vGT7bv09zLWxQPa7CT/tjXqc1TJ+hfK32p9knJ+Gv8+Fj8ZFgCfBd4c0/fAJ6VWiMtzgAOJJ2FMm1Kr/Pja5gy8sMzEb/XPxk/aTeJ+eRgPItOAXwMX1qs/HoTOTV7/GvCTZDkLpJsCd+IXlWx4b7e4/i5J/u2S9jwWv8gVyf9h4HY8GF6I9+w+RH/vb108EG2KX9BOi+lfiO/55rjORjXyPwbMSo6Fi/GOyT/RP2z1Rv6kroXqk7yXffBjfn/6h5w2AA7L7cfvAq/h589y6f6Nv7O7kFPw4LcX8AfgyJi+Ih4Q/yVZ91A8YI9K0t6Fz0X8FZgU0w6I7+sDufp8GLglSWt4bFLyXEnbJtcWy+EXn1vx4P+B2K5rkHQqY/1+Qhwaq3FupG2ftd9KeG//qCTft9LlprG1TCBeVj/0B5DsyrkD8ENgR7y3sog4vo7fDl4J3IKPG07GxxMfBD6XlPlJPICPqrG9RuXvGcvfDe+RnEm8jcsdjFn5a8W67Ji8Nha/BTulRv4V4wFyUcH6L1cy/9iS9RmVa5sLgBPwHslo/CS5GvhYfH1r4E/Ap4B/wXuAZ8T8VxUofzwe0KcmAeUafDhnPzzA/RYPFJ/He0xfwW+zj6pVPjXGNvHx0EPj31nwWhm/kN2FD0eciZ+E1+IB4owa5e+B9wZr5scvxJck+b8U198Vnzx9mP6hiWycdhawMz7cdD0eDDfAA/I36B9DXxnv4V8Q3+fDwNP4kNDk2D43AG9Nyp8DXJO8j3Oa1OcUYJPk3Lof2DMujwZWrdG278cv1Pfjd2RzSOY7ckHuEXx46JHYjukxmB/2OSK2TVa/feN6O+B3A8fH9FXxwLgAHw78ZHxvu+Edkj0odmyWOVeux2NG2jajc/X/ZnyP84HJudc+Ettqcr6dGrR9Nm+yJX7MHo1fwB8C3lQ4vi7LYF6oQnGstEZgWDVZ/hRxfA4PxGPxAJjdNt4E/C8wM1lnRDxozsFPjuMKlm+x/DWTA/fnyQ7IDsidY/kj8XHM3wKbxddG4T2b8+kfQ56e5Y/LOxas/6iS+UfGg6NZfbL8x+O9od1i+ofiAf7dpK774GO568Tlz8T99jD9dwB9eC9pUr4+SYBZI/79UbzHfS5+e58t3xdf/zzwHDA7buPDsY5fzL3fC/CTYOdc+ki8J/2VND05qffDA8F/4sMcFtv3apJJsqQ9d2+Q/0348NQaMf+N+GTnhXhQuhjvqWXb3x0fbunD72qOJl4o4uun5JZ3Jw4P4Hef3yNOHsa0S0mGIGP+L9E/HDGnSX22AfqSfXRb0k5z43FwCv3DZTPwO+G3AJ/Ah39uxDtKO+NPmGRt9mDM/zB+N9RH0sHKnfMz8GCZXcDWjmVmx+VR+N1Q2nN+C35+XwdsFdNOAL5OwWOT4ufK+xq0zU4x/X7gRWoE5NhONQM1fjzVa/tTY1u+Gw/8NwBbloqxyzKgN61Mg7HSXL4ngEtyadvggehqfAJlF2AJsHuS59sMHN/bKG3oRuXntnUlPvyQnSjZBNmnkzwn472S7MAaGw+CdYkTcMAqSf7tYv2vydc/7uj9c/nrvt86+U/EL1ZvztcnyXMt/eOZ1wDnxfSP4EHuRGBN/JbzN3gPc4ckQFxO/0m6Ynx9y6T8VZL2uxKfsNwb78Fujwf7A/CA9Hf8hMna+FD8RM/GbreIZWR3g7Nj3a/Aj6Pd0v2K95x/D3wwa5/cPt02q3sSZO7EJ5ZrtWe9/JvjQe8YvLd2GPBTfBJuNTy4zEjWG4Of0Nnd4/p4D3GvuDyHgb3MMbH8f84ft3H55hrl30h/B6FhfWoc6xfiF6U5+MV2R3xM+4v4Be79yT7/Av3j9w/gx+N+SfuvhXcYtk/KPzbus9WTtM1iG0xO0kax9JzTncQLebKfs3Mx7dStTJ1js86+LXKurILfbddqm3+NeXYlPvXWYjy8uF7bx9dHU2eiu2G5rVao0z/UHytNe21r4Vfhl/Gr3vtqHKB30x8INkte25Ta43sHFikfv/pmAWhqXD/rBaYTZCfn3tMz+O3gvfjYW90JOHxS8Qf0jyluhgezXxd9v03yfzq+vzfqk7y2BkuPZ94KXJTsj7Pw2/inY9rp+EmWtcsR+IdGpuLDL5em2495/oX+yfO98DmJE+m/A7gqtuXN+K35oXWOl9vovyidBNyenAjn5fZDVvan8OGYmu2T29dX4Sdd3faslT8ubxXb4b14r/Js+ocsR6fr5fJ/KGmjH+BPv1zVLH9yHN0OfLNG/QrXB/8MxOFJ2s74kzD303+cbQn8DJ9XuA/vbU7Ej7/j8QvX0/hE5ly8Bz0pV6fsmHk7fpxtmL4GrBT/3jbW4W3J61mPe3f8Aj8mqX96Lp6UrHMkuWOz0b6lxrkS67IT8M6k7l+t0Tbfp8bTbgVi4Pb4hSK7i9oOv3tNy98qlr9m2fLf2E6rK3b6Bx93u4raY6WnxzzT8FuaXfGr820MDMybJAdT+gz1iHhQ1hvfmx3z7dek/OykWwM4MUnfjYETZB+j/wTeF5/IOTEelLUm4L6HB8Atk21kB/ZnY/mF3m+j/PH1vWM90/pbfE/zWHo8cy5wQpJ2Bv0TjllwmoffFq8e3/sFwFn5dkvql47Fn4uPSR6Mzw+cjZ9Is/Fnrr+aW3/FWIdLkrQdSZ7lx4PBDSQTijF9vbj9uvsXv2jMJV4Qy+ZP0vfC7xjfn6tDzWepY/7Hs/yxrjvUWw+f0Hyc/qdYdmDggwn5/E3rE9v2VnyocFqSdhh+ATorpp2If9Btl7h8ET68txL+KOFf6J8Tm4PfWf8VuC7ZVjof9i2SyfwkfSo+LPPtWM7M3Ovr4HcUH29wLn4cH6JcGR/qeePYbLRv8+dKri434sNPht+B/igpcyreERtTMv69B3gytuMt9HcgpuFPNbVV/oBttbpip37w2890fLPWWOk1+K3/G7dy+O3VITH/wbUOphrbOo7643snNCg/ne3PxvKzCbssSKcTZL/Ee8TpgX0EHsSWY+kJuFPxccjs9nMkfqKk9Vm50fttkj99qiEfDLYHxsW/j6L2eOYF+BDP+dSfcLyI/gnH5fLbS34fjw9v7YhfiK/He1WL6H9kMRsGWh/vnR2aq/NGNcpPt/lO4O5keecm7XNQrvytsvx4h6Fp/lrtG7f76/ie9y1wLmT5j2PgM+L1LhQ7xfzHMPCJs3r5m9YnHgPXx3wfiWmj8eP6ArxX/DgDLzB9xKCND9+kTzKtjA/DzMSH465OXsvuNsbhw507Ja9tg59DW8Xlg+ifyzD6z7tsEvly6p+Lj9B/noxqsm+XOleSumyd1OWC7D3gD3ucH9vmp+nxUDAGjoxtfnhcXg3v9F4Vl9+BnzMtlb/U9tpZud0ffNxuDn4ly55nfTu1x0on48MJ6QdAVsUDzk341frrDLwNrDV2u0I8QLJPmGbje7uVKT8eqKfReILsM8mBM47+Z2uLTMCNa6E+zfJfmGufK+N7v5f+sfmT8PHM/FzEW2N7Nppw/HKd/Tw21/5fw8dxv0+cB4lp34x1NvqfUvowfoKuzMBnwAfsWwYG20nE4EJ88qJg+3yjZHu+kT8LRjXe+0S8t3kusVfe5JxoJf8nYv7prZZPvGjiPcuD8KGFJ2Pbf4X+43i9eEysFpdHxrSH6e88rMbAi/A6eCdqHH5XdHWuTivhk83jk7R3Ep8Qi8tvwgPe+gy88xtL/+R5mXOx8LnSoC4b5t7HhsSHE1qIhSeRDKvFtP8Evp4sr9dq+QPKbbeAljfst3Tfwa+25+FfgpXPk46tZhNSR9fIdyA+8XdLktZovO4TeI82Hd8rW36pCTJan4ArW5+i+fMfBjorOSk+wdJzEaUmHJPt3IY/ebNBkjYSv9hOSNLuxYcQjs6tv31MTyf1Go6z43MzP8Enimcti/YseMzX/RBOr/IT73iTtI2JwzD4sMbfgW80KGMUHtDvjcsfws/Xes+er4mfc9lFeQr+9Fx27L05yZs9RTQSvzB8l/6LzcQOnIsN922Jukyq1z5N2j8t/zB8TjM9T8bFtqr5WGerPx0rqOSb3RDvPayZpM0DtkiWa42VbkXt2/37GPgsstF8vC4b6jmrlfJz+VuasItpRSbgytanSPvU+jDQLfQH9T3w8cxP16hPwwnHJP9748n1dXzsdcNcfbMTKPtQXL36X0j8Hpe43GicfQR+d7iEOC6apHetPXtxHnXgPJyKj7Vfm6SNwYdxPoAP45yKfxjq4CZlXRmP/4doEqTwYDYLH3p5ivgVGUl9rk/3W7L/7sCD+OH43MOYJF+r52LNfdtOXUq2fVr+GbFOaeC/nuRpp47s9x4caIfht/bZB0Cy28ofsvRQzDY1Gjw/gTWCgd95cQQFxrZr1Kto+aUnyHLpZSfgytanSPs0Gpu/hDg2X6d9Ck844rfBW8S/v4w/d71hrty1GTixO6D+ubzTG+zb/Dh7zTHxLrRnoS+5Gmw/NB5rPwd4NdnHu9L4mfLl8QcjniHpgTfZ/gn4PM7kAvUZid9R3IgPzc4n6SAm+do9F0fgw5ZZXY5utS4l2z6d4D4DH149Gv98yhMkXx3RkX3fg4NtXHwz2WNW2QTLLPofVTo3PchYeigkm8A6gYFfwDWCFsa2a9Sxbvl18pedsCs7AVe2Ps3ap6Wx+Rrvt+aEI/64Z9bLSr/r5kv4hSbb91Nz5Y7I1f84YJ/csdNs317EwHH2Wp/O7Vh7Luvzp5M/LD3Wfm1ynGQPOhS6i8E7E4WeScfvJu4m96GiGvXJj/3fggfpusMpbZyL+X27brt1Kdn2aeB/Lz7v8sZnCzr5M4Jl7x/4o3kHA4QQXo/pzwIbmtmV+IcgnspWCLElkuUf498x8jdgqpkdEdOXxPK3wD+Ek+X/cwjhGvwR0Ln47eSD9SrYpPxa+X8U8/8d2D3LX6D8AOxiZtOblF+2Ps3aZ2t8SORp4jdomtlecfWt8a91aFT/7P2+BuyTlm9mV+DDOfeZ2YYhhFfNbLn4+kn4WOhdZpbVMS13Sa7+rwF7JO1ZZN+uk+7bWm3U4fYcskIIvw8hvBJC+AN+8V/BzK6O72slM9s8f+41MDuE8FjB7f43/qGtR5vUZ7SZXQ1gZhPxIHtgCGFhg7JbPRfz+/a5duvSZLv597q8mV0XX/4VcEcI4aMhhF+0Un6zjS/zH2qMp+FPQiwB/j1JK9rLWK1Z+TH9PloYi82XP9TzU3Jsvmj5xGeY49+Xk3xNQi7/y8C3W6l/p/ftsmj/ofLDwLH2J8l9HXUP6/Or+LN2C2V0ZN92oi4F3+tCknmOrrRrD3doNp6WPQv8PgZ+M2Jbt84M07HYDrZ/qQ8DFSivD39sLhuuOxMfcpmFjwlnF4aPkHyHeCv7Qfu2q8fFgLH2Xv8Mpvp0uy7L6r32uhF3xMfTPsHADxx15KRlmI7FdrD9S30YqEE5h+PzJNmY/Dtjb2Ur/LHPG+n/kM34Vrejfdv146HmWLvq0/26LMv32vN/jB7Hx/bCJxUX4Lf9HatULP9d+Hfv/CKEcGWnyh4OOtE+ZjYOn5T+WgjhT2a2Av5dIX+Kr18EPBVCOC9Zx9rdz9q3nRf/d/Dfel2PzGCqT7frsqzea8+DfsrMVgshvDxUyx/qWm0fMxuDf2fIPSGES2LaiBAnOs3sO/gXol3R0QoPrIP2rUgBgyroy9BlZlvhz8ufFEK41sxG4h+wuw5YFEI4qqcVFBGAnjyyKcNQCOHn+DcPnmpm00MI/8C/KOrBLOCbmY43kR5TT186ysx2wr9S4ct4D//mmP7GcI+I9I6CvnRctyfnRaR1CvrSVZpgFRlcFPRFRCpEE2siIhWioC8iUiEK+iIiFaKgLyJSIQr6IiIVoqAvIlIh/wfwUeMQdhap/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dendrogramDat = scipy.cluster.hierarchy.dendrogram(review_linkage_matrix, p=4, truncate_mode='level',distance_sort='descending', get_leaves=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8, 12,  8, ..., 14, 22,  8], dtype=int32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchicalClusters = scipy.cluster.hierarchy.fcluster(review_linkage_matrix, 24, 'maxclust')\n",
    "hierarchicalClusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.086283703639634"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = reviewTFVects.toarray()\n",
    "sklearn.metrics.silhouette_score(X, hierarchicalClusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical clustering also indicates that all the reviews can be largely divided into 2 categories. And one catetory has more reviews that the other's. It's silhouette score is slightly worse than k-means'. I think it's because most reviews are tring to tell you how good/bad the movie is, so hierarchical clustering is not a good choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim\n",
    "\n",
    "To do topic modeling we will also be using data from the [grimmer press releases corpus](ttps://github.com/lintool/GrimmerSenatePressReleases). To use the texts with gensim we need to create a `corpua` object, this takes a few steps. First we create a `Dictionary` that maps tokens to ids.\n",
    "\n",
    "Here again we make use of `lucem_illud` functions. The source code of both of these is in [processing.py](https://github.com/UChicago-Computational-Content-Analysis/lucem_illud/blob/main/lucem_illud/processing.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply our functions\n",
    "senReleasesTraining['tokenized_text'] = senReleasesTraining['text'].apply(lambda x: lucem_illud.word_tokenize(x))\n",
    "senReleasesTraining['normalized_tokens'] = senReleasesTraining['tokenized_text'].apply(lambda x: lucem_illud.normalizeTokens(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senReleasesTraining[::100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropMissing(wordLst, vocab):\n",
    "    return [w for w in wordLst if w in vocab]\n",
    "\n",
    "# senReleasesTraining['reduced_tokens'] = senReleasesTraining['normalized_tokens'].apply(lambda x: dropMissing(x, senTFVectorizer.vocabulary_.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(senReleasesTraining['reduced_tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then for each of the texts we create a list of tuples containing each token and its count. We will only use the first half of our dataset for now and will save the remainder for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in senReleasesTraining['reduced_tokens']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we serialize the corpus as a file and load it. This is an important step when the corpus is large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim.corpora.MmCorpus.serialize('senate.mm', corpus)\n",
    "senmm = gensim.corpora.MmCorpus('senate.mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a correctly formatted corpus that we can use for topic modeling and induction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senlda = gensim.models.ldamodel.LdaModel(corpus=senmm, id2word=dictionary, num_topics=10, alpha='auto', eta='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the degree to which distinct texts load on different topics. Here is one of the texts from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen1Bow = dictionary.doc2bow(senReleasesTraining['reduced_tokens'][0])\n",
    "sen1lda = senlda[sen1Bow]\n",
    "print(\"The topics of the text: {}\".format(senReleasesTraining['name'][0]))\n",
    "print(\"are: {}\".format(sen1lda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see which topics our model predicts press releases load on and make this into a `dataFrame` for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaDF = pandas.DataFrame({\n",
    "        'name' : senReleasesTraining['name'],\n",
    "        'topics' : [senlda[dictionary.doc2bow(l)] for l in senReleasesTraining['reduced_tokens']]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit unwieldy so lets make each topic its own column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dict to temporally hold the probabilities\n",
    "topicsProbDict = {i : [0] * len(ldaDF) for i in range(senlda.num_topics)}\n",
    "\n",
    "#Load them into the dict\n",
    "for index, topicTuples in enumerate(ldaDF['topics']):\n",
    "    for topicNum, prob in topicTuples:\n",
    "        topicsProbDict[topicNum][index] = prob\n",
    "\n",
    "#Update the DataFrame\n",
    "for topicNum in range(senlda.num_topics):\n",
    "    ldaDF['topic_{}'.format(topicNum)] = topicsProbDict[topicNum]\n",
    "\n",
    "ldaDF[1::100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize this for several (e.g., 10) documents in the corpus. First we'll subset the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaDFV = ldaDF[:10][['topic_%d' %x for x in range(10)]]\n",
    "ldaDFVisN = ldaDF[:10][['name']]\n",
    "ldaDFVis = ldaDFV.as_matrix(columns=None)\n",
    "ldaDFVisNames = ldaDFVisN.as_matrix(columns=None)\n",
    "ldaDFV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we can visualize as a stacked bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "ind = np.arange(N)\n",
    "K = senlda.num_topics  # N documents, K topics\n",
    "ind = np.arange(N)  # the x-axis locations for the novels\n",
    "width = 0.5  # the width of the bars\n",
    "plots = []\n",
    "height_cumulative = np.zeros(N)\n",
    "\n",
    "for k in range(K):\n",
    "    color = plt.cm.coolwarm(k/K, 1)\n",
    "    if k == 0:\n",
    "        p = plt.bar(ind, ldaDFVis[:, k], width, color=color)\n",
    "    else:\n",
    "        p = plt.bar(ind, ldaDFVis[:, k], width, bottom=height_cumulative, color=color)\n",
    "    height_cumulative += ldaDFVis[:, k]\n",
    "    plots.append(p)\n",
    "    \n",
    "\n",
    "plt.ylim((0, 1))  # proportions sum to 1, so the height of the stacked bars is 1\n",
    "plt.ylabel('Topics')\n",
    "\n",
    "plt.title('Topics in Press Releases')\n",
    "plt.xticks(ind+width/2, ldaDFVisNames, rotation='vertical')\n",
    "\n",
    "plt.yticks(np.arange(0, 1, 10))\n",
    "topic_labels = ['Topic #{}'.format(k) for k in range(K)]\n",
    "plt.legend([p[0] for p in plots], topic_labels, loc='center left', frameon=True,  bbox_to_anchor = (1, .5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize as a heat map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolor(ldaDFVis, norm=None, cmap='Blues')\n",
    "plt.yticks(np.arange(ldaDFVis.shape[0])+0.5, ldaDFVisNames);\n",
    "plt.xticks(np.arange(ldaDFVis.shape[1])+0.5, topic_labels);\n",
    "\n",
    "# flip the y-axis so the texts are in the order we anticipate (Austen first, then Brontë)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# rotate the ticks on the x-axis\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# add a legend\n",
    "plt.colorbar(cmap='Blues')\n",
    "plt.tight_layout()  # fixes margins\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the top words from each topic to get a sense of the semantic (or syntactic) domain they represent. To look at the terms with the highest LDA weight in topic `1` we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senlda.show_topic(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we want to make a dataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicsDict = {}\n",
    "for topicNum in range(senlda.num_topics):\n",
    "    topicWords = [w for w, p in senlda.show_topic(topicNum)]\n",
    "    topicsDict['Topic_{}'.format(topicNum)] = topicWords\n",
    "\n",
    "wordRanksDF = pandas.DataFrame(topicsDict)\n",
    "wordRanksDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that several of the topics have the same top words, but there are definitely differences. We can try and make the topics more distinct by changing the $\\alpha$ and $\\eta$ parameters of the model. $\\alpha$ controls the sparsity of document-topic loadings, and $\\eta$ controls the sparsity of topic-word loadings.\n",
    "\n",
    "We can make a visualization of the distribution of words over any single topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic1_df = pandas.DataFrame(senlda.show_topic(1, topn=50))\n",
    "plt.figure()\n",
    "topic1_df.plot.bar(legend = False)\n",
    "plt.title('Probability Distribution of Words, Topic 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how different $\\eta$ values can change the shape of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senlda1 = gensim.models.ldamodel.LdaModel(corpus=senmm, id2word=dictionary, num_topics=10, eta = 0.00001)\n",
    "senlda2 = gensim.models.ldamodel.LdaModel(corpus=senmm, id2word=dictionary, num_topics=10, eta = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic11_df = pandas.DataFrame(senlda1.show_topic(1, topn=50))\n",
    "topic21_df = pandas.DataFrame(senlda2.show_topic(1, topn=50))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.set_size_inches(18, 7)\n",
    "topic11_df.plot.bar(legend = False, ax = ax1, title = '$\\eta$  = 0.00001')\n",
    "topic21_df.plot.bar(legend = False, ax = ax2, title = '$\\eta$  = 0.9')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "syxNwikVgPH0"
   },
   "source": [
    "### Heirarchial Dirichlet Process\n",
    "\n",
    "We use LDA topic modeling above, but a similar alternative model you may run across is Hierarchical Dirichlet Processes, a nonparametric generalization of LDA. See, for example, [Teodoridis et al 2020](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3596233). One difference is how the researcher selects the number of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D7hIA4hPgcc5"
   },
   "outputs": [],
   "source": [
    "from gensim.models import HdpModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2hStv6DjFklq"
   },
   "outputs": [],
   "source": [
    "hdpmodel = HdpModel(corpus=corpus, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lErePHjxFkg_",
    "outputId": "fcd26a40-3071-49b9-a4ba-046418be3119"
   },
   "outputs": [],
   "source": [
    "hdpmodel.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "luPvBEh7Kezp"
   },
   "source": [
    "Gensim sets the default number of topics as 150. This [stack overflow link](https://stackoverflow.com/questions/31543542/hierarchical-dirichlet-process-gensim-topic-number-independent-of-corpus-size) walks you through how to truncate these topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IO0ZQsMrHaf2"
   },
   "outputs": [],
   "source": [
    "hdptexts = hdpmodel[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rZ_wUnk2Hnn2",
    "outputId": "56fffc6d-e7d6-4ca9-e4e9-1269ec2f29a1"
   },
   "outputs": [],
   "source": [
    "hdptexts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mhOZEFyMKiNh"
   },
   "source": [
    "This [HDP tutorial](https://towardsdatascience.com/dont-be-afraid-of-nonparametric-topic-models-part-2-python-e5666db347a) walks us through alternative HDP implementations outside of gensim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">*Exercise 3*</font>\n",
    "\n",
    "<font color=\"red\">Construct cells immediately below this that topic model documents related to your anticipated final project. Interrogate and visually plot (e.g., as a bar graph?) the topic-word loadings and the document-topic loadings. What does this topic structure reveal about the distribution of contents across your documents? Systematically vary the $\\alpha$, $\\eta$, and topic number of the model for your text and describe in detail whether and how these changes led to distinctive outcomes, visible to you as analyst.  \n",
    "\n",
    "<font color=\"red\">**Stretch**: Cluster your documents, but instead of using words alone, use their topic loadings as an additional set of features. Do these topic loadings increase the apparent semantic coherence of your clusters?</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_time</th>\n",
       "      <th>content</th>\n",
       "      <th>douban_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>cut_words</th>\n",
       "      <th>kmeans_predictions</th>\n",
       "      <th>reduced_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-05 19:42:07</td>\n",
       "      <td>480p画质不高黑白y</td>\n",
       "      <td>5113101</td>\n",
       "      <td>2.0</td>\n",
       "      <td>480p 画质 不高 黑白 y</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-09 14:52:07</td>\n",
       "      <td>毫无看点黑白画质一个男人孤独的心理情景历程疯疯癫癫没有任何恐怖的成分这应该是剧情片吧</td>\n",
       "      <td>5113101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>毫无 看点 黑白 画质 一个 男人 孤独 的 心理 情景 历程 疯疯癫癫 没有 任何 恐怖 ...</td>\n",
       "      <td>9</td>\n",
       "      <td>[毫无, 看点, 一个, 男人, 孤独, 心理, 恐怖]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-11-05 22:15:44</td>\n",
       "      <td>上吊那裡超好笑可惜最後報告近況的旁白大扣分</td>\n",
       "      <td>3718526</td>\n",
       "      <td>3.0</td>\n",
       "      <td>上吊 那裡 超 好笑 可惜 最後報 告近況 的 旁白 大 扣分</td>\n",
       "      <td>0</td>\n",
       "      <td>[好笑, 可惜, 旁白]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-06-20 02:12:50</td>\n",
       "      <td>上海国际电影节观摩片</td>\n",
       "      <td>3718526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>上海 国际 电影节 观摩 片</td>\n",
       "      <td>0</td>\n",
       "      <td>[上海]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-04-09 22:10:13</td>\n",
       "      <td></td>\n",
       "      <td>3718526</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>2010-09-11 13:46:02</td>\n",
       "      <td>搞笑的励志电影</td>\n",
       "      <td>1309050</td>\n",
       "      <td>5.0</td>\n",
       "      <td>搞笑 的 励志 电影</td>\n",
       "      <td>4</td>\n",
       "      <td>[搞笑, 励志, 电影]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>2010-10-23 13:19:17</td>\n",
       "      <td>美国所谓的人权</td>\n",
       "      <td>1309050</td>\n",
       "      <td>3.0</td>\n",
       "      <td>美国 所谓 的 人权</td>\n",
       "      <td>0</td>\n",
       "      <td>[美国]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2009-01-22 18:36:13</td>\n",
       "      <td>2009121在书房跟老公一起看的没看完但看过的部分很精彩期待</td>\n",
       "      <td>1309050</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2009121 在 书房 跟 老公 一起 看 的 没 看 完 但 看过 的 部分 很 精彩 期待</td>\n",
       "      <td>6</td>\n",
       "      <td>[看过, 精彩, 期待]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2011-10-19 12:00:27</td>\n",
       "      <td>我喜欢亚当桑德勒说橄榄球跟乒乓球差不多就是是蛋形的跟我的头一样lol另外我的Alexmaho...</td>\n",
       "      <td>1309050</td>\n",
       "      <td>3.0</td>\n",
       "      <td>我 喜欢 亚当 桑德勒 说 橄榄球 跟 乒乓球 差不多 就是 是 蛋形 的 跟 我 的 头 ...</td>\n",
       "      <td>15</td>\n",
       "      <td>[喜欢, 亚当, 桑德勒, 橄榄球, 差不多, 太帅, 年轻, 爱上]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2009-05-23 19:02:22</td>\n",
       "      <td>好久没看这么搞笑的片了哈哈</td>\n",
       "      <td>1309050</td>\n",
       "      <td>4.0</td>\n",
       "      <td>好久没 看 这么 搞笑 的 片 了 哈哈</td>\n",
       "      <td>0</td>\n",
       "      <td>[搞笑]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             comment_time                                            content  \\\n",
       "0     2018-09-05 19:42:07                                        480p画质不高黑白y   \n",
       "1     2019-07-09 14:52:07         毫无看点黑白画质一个男人孤独的心理情景历程疯疯癫癫没有任何恐怖的成分这应该是剧情片吧   \n",
       "2     2010-11-05 22:15:44                              上吊那裡超好笑可惜最後報告近況的旁白大扣分   \n",
       "3     2010-06-20 02:12:50                                         上海国际电影节观摩片   \n",
       "4     2011-04-09 22:10:13                                                      \n",
       "...                   ...                                                ...   \n",
       "4995  2010-09-11 13:46:02                                            搞笑的励志电影   \n",
       "4996  2010-10-23 13:19:17                                            美国所谓的人权   \n",
       "4997  2009-01-22 18:36:13                    2009121在书房跟老公一起看的没看完但看过的部分很精彩期待   \n",
       "4998  2011-10-19 12:00:27  我喜欢亚当桑德勒说橄榄球跟乒乓球差不多就是是蛋形的跟我的头一样lol另外我的Alexmaho...   \n",
       "4999  2009-05-23 19:02:22                                      好久没看这么搞笑的片了哈哈   \n",
       "\n",
       "      douban_id  rating                                          cut_words  \\\n",
       "0       5113101     2.0                                    480p 画质 不高 黑白 y   \n",
       "1       5113101     1.0  毫无 看点 黑白 画质 一个 男人 孤独 的 心理 情景 历程 疯疯癫癫 没有 任何 恐怖 ...   \n",
       "2       3718526     3.0                    上吊 那裡 超 好笑 可惜 最後報 告近況 的 旁白 大 扣分   \n",
       "3       3718526     NaN                                     上海 国际 电影节 观摩 片   \n",
       "4       3718526     NaN                                                      \n",
       "...         ...     ...                                                ...   \n",
       "4995    1309050     5.0                                         搞笑 的 励志 电影   \n",
       "4996    1309050     3.0                                         美国 所谓 的 人权   \n",
       "4997    1309050     3.0   2009121 在 书房 跟 老公 一起 看 的 没 看 完 但 看过 的 部分 很 精彩 期待   \n",
       "4998    1309050     3.0  我 喜欢 亚当 桑德勒 说 橄榄球 跟 乒乓球 差不多 就是 是 蛋形 的 跟 我 的 头 ...   \n",
       "4999    1309050     4.0                               好久没 看 这么 搞笑 的 片 了 哈哈   \n",
       "\n",
       "      kmeans_predictions                       reduced_tokens  \n",
       "0                      0                                   []  \n",
       "1                      9         [毫无, 看点, 一个, 男人, 孤独, 心理, 恐怖]  \n",
       "2                      0                         [好笑, 可惜, 旁白]  \n",
       "3                      0                                 [上海]  \n",
       "4                      0                                   []  \n",
       "...                  ...                                  ...  \n",
       "4995                   4                         [搞笑, 励志, 电影]  \n",
       "4996                   0                                 [美国]  \n",
       "4997                   6                         [看过, 精彩, 期待]  \n",
       "4998                  15  [喜欢, 亚当, 桑德勒, 橄榄球, 差不多, 太帅, 年轻, 爱上]  \n",
       "4999                   0                                 [搞笑]  \n",
       "\n",
       "[5000 rows x 7 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['reduced_tokens'] = reviews['cut_words'].apply(lambda x: x.split(' '))\\\n",
    "                                                .apply(lambda x: dropMissing(x, reviewTFVectorizer.vocabulary_.keys()))\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_lst = []\n",
    "for index, row in reviews.iterrows():\n",
    "    if row['reduced_tokens'] == []:\n",
    "        empty_lst.append(index)\n",
    "\n",
    "reviews.drop(empty_lst, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_dictionary = gensim.corpora.Dictionary(reviews['reduced_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_corpus = [review_dictionary.doc2bow(text) for text in reviews['reduced_tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim.corpora.MmCorpus.serialize('review.mm', review_corpus)\n",
    "review_mm = gensim.corpora.MmCorpus('review.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_lda = gensim.models.ldamodel.LdaModel(corpus=review_mm, \n",
    "                                             id2word=review_dictionary, \n",
    "                                             num_topics=10, \n",
    "                                             alpha=0.1, \n",
    "                                             eta=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>毫无看点黑白画质一个男人孤独的心理情景历程疯疯癫癫没有任何恐怖的成分这应该是剧情片吧</td>\n",
       "      <td>[(0, 0.012511339), (1, 0.01251113), (2, 0.0125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>上吊那裡超好笑可惜最後報告近況的旁白大扣分</td>\n",
       "      <td>[(0, 0.7748718), (1, 0.025009722), (2, 0.02501...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>上海国际电影节观摩片</td>\n",
       "      <td>[(0, 0.050006583), (1, 0.050011717), (2, 0.050...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>那些不同人们的生活状态真实且残酷描述这类人生活的片子多了有点不太敢去德国了生怕那里的人心底里...</td>\n",
       "      <td>[(2, 0.95498073)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>生活用最残酷的方式让你笑笑得哭出来</td>\n",
       "      <td>[(0, 0.025010336), (1, 0.025001336), (2, 0.774...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>搞笑的励志电影</td>\n",
       "      <td>[(0, 0.77486277), (1, 0.025003122), (2, 0.0250...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>美国所谓的人权</td>\n",
       "      <td>[(0, 0.050000317), (1, 0.050000317), (2, 0.050...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2009121在书房跟老公一起看的没看完但看过的部分很精彩期待</td>\n",
       "      <td>[(0, 0.025000677), (1, 0.02500243), (2, 0.7749...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>我喜欢亚当桑德勒说橄榄球跟乒乓球差不多就是是蛋形的跟我的头一样lol另外我的Alexmaho...</td>\n",
       "      <td>[(0, 0.016667875), (1, 0.19055559), (2, 0.0166...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>好久没看这么搞笑的片了哈哈</td>\n",
       "      <td>[(0, 0.54998964), (1, 0.050000295), (2, 0.0500...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4174 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  \\\n",
       "1            毫无看点黑白画质一个男人孤独的心理情景历程疯疯癫癫没有任何恐怖的成分这应该是剧情片吧   \n",
       "2                                 上吊那裡超好笑可惜最後報告近況的旁白大扣分   \n",
       "3                                            上海国际电影节观摩片   \n",
       "5     那些不同人们的生活状态真实且残酷描述这类人生活的片子多了有点不太敢去德国了生怕那里的人心底里...   \n",
       "6                                     生活用最残酷的方式让你笑笑得哭出来   \n",
       "...                                                 ...   \n",
       "4995                                            搞笑的励志电影   \n",
       "4996                                            美国所谓的人权   \n",
       "4997                    2009121在书房跟老公一起看的没看完但看过的部分很精彩期待   \n",
       "4998  我喜欢亚当桑德勒说橄榄球跟乒乓球差不多就是是蛋形的跟我的头一样lol另外我的Alexmaho...   \n",
       "4999                                      好久没看这么搞笑的片了哈哈   \n",
       "\n",
       "                                                 topics  \n",
       "1     [(0, 0.012511339), (1, 0.01251113), (2, 0.0125...  \n",
       "2     [(0, 0.7748718), (1, 0.025009722), (2, 0.02501...  \n",
       "3     [(0, 0.050006583), (1, 0.050011717), (2, 0.050...  \n",
       "5                                     [(2, 0.95498073)]  \n",
       "6     [(0, 0.025010336), (1, 0.025001336), (2, 0.774...  \n",
       "...                                                 ...  \n",
       "4995  [(0, 0.77486277), (1, 0.025003122), (2, 0.0250...  \n",
       "4996  [(0, 0.050000317), (1, 0.050000317), (2, 0.050...  \n",
       "4997  [(0, 0.025000677), (1, 0.02500243), (2, 0.7749...  \n",
       "4998  [(0, 0.016667875), (1, 0.19055559), (2, 0.0166...  \n",
       "4999  [(0, 0.54998964), (1, 0.050000295), (2, 0.0500...  \n",
       "\n",
       "[4174 rows x 2 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaDF = pandas.DataFrame({\n",
    "        'content' : reviews['content'],\n",
    "        'topics' : [review_lda[review_dictionary.doc2bow(l)] for l in reviews['reduced_tokens']]\n",
    "    })\n",
    "ldaDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>topics</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>topic_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>上吊那裡超好笑可惜最後報告近況的旁白大扣分</td>\n",
       "      <td>[(0, 0.7748718), (1, 0.025009722), (2, 0.02501...</td>\n",
       "      <td>0.774872</td>\n",
       "      <td>0.025010</td>\n",
       "      <td>0.025011</td>\n",
       "      <td>0.025010</td>\n",
       "      <td>0.025011</td>\n",
       "      <td>0.025012</td>\n",
       "      <td>0.025027</td>\n",
       "      <td>0.025011</td>\n",
       "      <td>0.025024</td>\n",
       "      <td>0.025012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>徐海乔的演技很好人设也很苏对女主比较崩溃又作又矫情电影立意还好就是剧情太简单</td>\n",
       "      <td>[(4, 0.72543454), (8, 0.20179272)]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.725435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.201793</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>原来主妇还有这么青葱的岁月呀哈哈哈小姐这是你掉的熊吗啊哈哈哈</td>\n",
       "      <td>[(0, 0.016673487), (1, 0.01667151), (2, 0.0166...</td>\n",
       "      <td>0.016673</td>\n",
       "      <td>0.016672</td>\n",
       "      <td>0.016671</td>\n",
       "      <td>0.016671</td>\n",
       "      <td>0.016672</td>\n",
       "      <td>0.849955</td>\n",
       "      <td>0.016671</td>\n",
       "      <td>0.016671</td>\n",
       "      <td>0.016671</td>\n",
       "      <td>0.016672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>那是一种伤在血液里流动</td>\n",
       "      <td>[(0, 0.05000922), (1, 0.05000255), (2, 0.05000...</td>\n",
       "      <td>0.050009</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050010</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.549970</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>小成本的好電影</td>\n",
       "      <td>[(0, 0.05000306), (1, 0.050003435), (2, 0.0500...</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050005</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050012</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.549961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>如果你认识一对性欲非常旺盛的夫妇他们可能只是想要个孩子虽然是近来快被国内电视剧玩烂的题材但还...</td>\n",
       "      <td>[(0, 0.13448688), (1, 0.011114266), (2, 0.0111...</td>\n",
       "      <td>0.134487</td>\n",
       "      <td>0.011114</td>\n",
       "      <td>0.011117</td>\n",
       "      <td>0.263763</td>\n",
       "      <td>0.011115</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.011116</td>\n",
       "      <td>0.243479</td>\n",
       "      <td>0.291570</td>\n",
       "      <td>0.011122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>至今看了三个版本竟然没有一个版本贴原著的</td>\n",
       "      <td>[(0, 0.012505284), (1, 0.012503927), (2, 0.012...</td>\n",
       "      <td>0.012505</td>\n",
       "      <td>0.012504</td>\n",
       "      <td>0.012505</td>\n",
       "      <td>0.012502</td>\n",
       "      <td>0.564786</td>\n",
       "      <td>0.012503</td>\n",
       "      <td>0.012503</td>\n",
       "      <td>0.012502</td>\n",
       "      <td>0.012503</td>\n",
       "      <td>0.335187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>打小就喜欢看这种片难怪现在喜欢看基情片</td>\n",
       "      <td>[(0, 0.03333409), (1, 0.0333338), (2, 0.033335...</td>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.033336</td>\n",
       "      <td>0.699991</td>\n",
       "      <td>0.033335</td>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.033334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>西班牙江姐</td>\n",
       "      <td>[(0, 0.050003838), (1, 0.050010953), (2, 0.050...</td>\n",
       "      <td>0.050004</td>\n",
       "      <td>0.050011</td>\n",
       "      <td>0.050004</td>\n",
       "      <td>0.050004</td>\n",
       "      <td>0.050004</td>\n",
       "      <td>0.050005</td>\n",
       "      <td>0.050004</td>\n",
       "      <td>0.549957</td>\n",
       "      <td>0.050004</td>\n",
       "      <td>0.050004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>笑死我了哈哈哈哈哈哈哈哈哈</td>\n",
       "      <td>[(0, 0.02500031), (1, 0.02500035), (2, 0.02500...</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.774997</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>老头把我搞的热泪盈眶</td>\n",
       "      <td>[(0, 0.050010346), (1, 0.050006215), (2, 0.050...</td>\n",
       "      <td>0.050010</td>\n",
       "      <td>0.050006</td>\n",
       "      <td>0.050011</td>\n",
       "      <td>0.050008</td>\n",
       "      <td>0.549936</td>\n",
       "      <td>0.050011</td>\n",
       "      <td>0.050006</td>\n",
       "      <td>0.050004</td>\n",
       "      <td>0.050004</td>\n",
       "      <td>0.050004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>女主真的好像HarryPotter</td>\n",
       "      <td>[(0, 0.025005896), (1, 0.025000673), (2, 0.025...</td>\n",
       "      <td>0.025006</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.025002</td>\n",
       "      <td>0.401239</td>\n",
       "      <td>0.025004</td>\n",
       "      <td>0.025010</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.025002</td>\n",
       "      <td>0.025011</td>\n",
       "      <td>0.398723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>一般般一般般</td>\n",
       "      <td>[(0, 0.03334633), (1, 0.03334633), (2, 0.03334...</td>\n",
       "      <td>0.033346</td>\n",
       "      <td>0.033346</td>\n",
       "      <td>0.033346</td>\n",
       "      <td>0.033347</td>\n",
       "      <td>0.033347</td>\n",
       "      <td>0.033347</td>\n",
       "      <td>0.033346</td>\n",
       "      <td>0.699871</td>\n",
       "      <td>0.033346</td>\n",
       "      <td>0.033358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>什么鬼不知道这个资源的翻译怎么搞的感觉都对不上号韩语也怪怪的听起来这女主角除了胸大都垂了和肤...</td>\n",
       "      <td>[(0, 0.014289671), (1, 0.014294171), (2, 0.014...</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>0.014294</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>0.182174</td>\n",
       "      <td>0.014291</td>\n",
       "      <td>0.014299</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>0.703487</td>\n",
       "      <td>0.014292</td>\n",
       "      <td>0.014293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>我叫张士豪我是游泳队吉他社长得还不错啊我有什么不好我就是要追你啊</td>\n",
       "      <td>[(0, 0.871376), (1, 0.014290944), (2, 0.014290...</td>\n",
       "      <td>0.871376</td>\n",
       "      <td>0.014291</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>0.014292</td>\n",
       "      <td>0.014291</td>\n",
       "      <td>0.014291</td>\n",
       "      <td>0.014291</td>\n",
       "      <td>0.014292</td>\n",
       "      <td>0.014295</td>\n",
       "      <td>0.014292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>让所有青春励志片见鬼去吧这才叫他妈的励志</td>\n",
       "      <td>[(0, 0.025002142), (1, 0.025006535), (2, 0.025...</td>\n",
       "      <td>0.025002</td>\n",
       "      <td>0.025007</td>\n",
       "      <td>0.025009</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.774971</td>\n",
       "      <td>0.025004</td>\n",
       "      <td>0.025001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>芳登和史都华这组合略神奇芳登在里边很漂亮但感觉她不太适合喜剧大部分时候看着都有点情绪低落史都...</td>\n",
       "      <td>[(3, 0.28670153), (6, 0.64660144)]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.646601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>这么快的车速居然没把他摔死奇迹</td>\n",
       "      <td>[(0, 0.05000321), (1, 0.0500008), (2, 0.549981...</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.549982</td>\n",
       "      <td>0.050006</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2167</th>\n",
       "      <td>高中生特有的闲得蛋疼的淳朴感情都是过来人看到影片总能想起少年自己曾傻逼</td>\n",
       "      <td>[(0, 0.020001808), (1, 0.48877764), (2, 0.0200...</td>\n",
       "      <td>0.020002</td>\n",
       "      <td>0.488778</td>\n",
       "      <td>0.020002</td>\n",
       "      <td>0.020006</td>\n",
       "      <td>0.351195</td>\n",
       "      <td>0.020002</td>\n",
       "      <td>0.020003</td>\n",
       "      <td>0.020003</td>\n",
       "      <td>0.020003</td>\n",
       "      <td>0.020007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>基本上讲述了一个完整的故事但是我不喜欢结尾人生无非就是等待和希望罢了这句最经典的话居然没有说...</td>\n",
       "      <td>[(2, 0.62067485), (7, 0.3322368)]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.332237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>你的对手是豆叔你都不敢争一下么反正他怎么都会死掉啊</td>\n",
       "      <td>[(0, 0.050001904), (1, 0.050001487), (2, 0.050...</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.549989</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2533</th>\n",
       "      <td>无厘头的体育类型励志片</td>\n",
       "      <td>[(0, 0.32362223), (1, 0.033334453), (2, 0.4096...</td>\n",
       "      <td>0.323622</td>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.409679</td>\n",
       "      <td>0.033346</td>\n",
       "      <td>0.033336</td>\n",
       "      <td>0.033336</td>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.033342</td>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.033335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2651</th>\n",
       "      <td>除了老爷其他人的表演都太漫画化了女主这么天真真是开玩笑啊</td>\n",
       "      <td>[(0, 0.02500979), (1, 0.025007304), (2, 0.7749...</td>\n",
       "      <td>0.025010</td>\n",
       "      <td>0.025007</td>\n",
       "      <td>0.774904</td>\n",
       "      <td>0.025026</td>\n",
       "      <td>0.025006</td>\n",
       "      <td>0.025009</td>\n",
       "      <td>0.025004</td>\n",
       "      <td>0.025007</td>\n",
       "      <td>0.025009</td>\n",
       "      <td>0.025018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>好雷人的电影</td>\n",
       "      <td>[(0, 0.05000316), (1, 0.050002832), (2, 0.0500...</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.549929</td>\n",
       "      <td>0.050017</td>\n",
       "      <td>0.050025</td>\n",
       "      <td>0.050010</td>\n",
       "      <td>0.050004</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>廉价感超级浓</td>\n",
       "      <td>[(0, 0.05000377), (1, 0.050003316), (2, 0.0500...</td>\n",
       "      <td>0.050004</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050004</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050004</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.549952</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>凯奇叔苦大仇深的面部让人看得相当梗阻女猪翻车时嘴角自然上扬表示欣慰黑衣怪蜀黍身份大揭秘时笑到...</td>\n",
       "      <td>[(0, 0.020001888), (1, 0.43318284), (2, 0.0200...</td>\n",
       "      <td>0.020002</td>\n",
       "      <td>0.433183</td>\n",
       "      <td>0.020009</td>\n",
       "      <td>0.020002</td>\n",
       "      <td>0.020007</td>\n",
       "      <td>0.020002</td>\n",
       "      <td>0.406784</td>\n",
       "      <td>0.020002</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>0.020006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>好似掺杂了一丝阿基的味道一段日本大佬在美利坚的黑帮往事层层堆叠的回忆片段不提供完整的故事情节...</td>\n",
       "      <td>[(1, 0.07117014), (6, 0.59980816), (7, 0.08467...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.599808</td>\n",
       "      <td>0.084677</td>\n",
       "      <td>0.056879</td>\n",
       "      <td>0.162457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>Sandler太帅了</td>\n",
       "      <td>[(0, 0.050000984), (1, 0.050000984), (2, 0.050...</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.549990</td>\n",
       "      <td>0.050001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3381</th>\n",
       "      <td>为着迷的新疆风情特意跑去看了3D特效童年阿凡提故事的异域风情并不多民俗文化的普及比不上女主角...</td>\n",
       "      <td>[(0, 0.14878064), (1, 0.22745532), (6, 0.16987...</td>\n",
       "      <td>0.148781</td>\n",
       "      <td>0.227455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169876</td>\n",
       "      <td>0.121663</td>\n",
       "      <td>0.290542</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>The2ndPYIFF一部关于电影的电影一部反射电影自身制作过程和自我认识的元电影影片加入了...</td>\n",
       "      <td>[(2, 0.058663163), (3, 0.6003503), (5, 0.09329...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058663</td>\n",
       "      <td>0.600350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093293</td>\n",
       "      <td>0.118114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3618</th>\n",
       "      <td>影片的音乐感动了我</td>\n",
       "      <td>[(0, 0.025013536), (1, 0.025007399), (2, 0.025...</td>\n",
       "      <td>0.025014</td>\n",
       "      <td>0.025007</td>\n",
       "      <td>0.025004</td>\n",
       "      <td>0.025012</td>\n",
       "      <td>0.025008</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.025005</td>\n",
       "      <td>0.774940</td>\n",
       "      <td>0.025004</td>\n",
       "      <td>0.025003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3734</th>\n",
       "      <td>一如既往的冷暴力最后一段黑人丹尼的表演很有感染力令人笑中带泪</td>\n",
       "      <td>[(0, 0.01667116), (1, 0.016676746), (2, 0.0166...</td>\n",
       "      <td>0.016671</td>\n",
       "      <td>0.016677</td>\n",
       "      <td>0.016675</td>\n",
       "      <td>0.016677</td>\n",
       "      <td>0.016671</td>\n",
       "      <td>0.322456</td>\n",
       "      <td>0.016671</td>\n",
       "      <td>0.016670</td>\n",
       "      <td>0.544160</td>\n",
       "      <td>0.016673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3851</th>\n",
       "      <td>这不是三段式的故事没有主人公的困境和人物关系复合前的多重障碍有的是两个可信的人物多情男子和她...</td>\n",
       "      <td>[(3, 0.49881306), (5, 0.18981883), (7, 0.27635...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.498813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.276353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>简单的爱情喜剧倒是拍出了新意就是男女猪实在是不合我滴审美</td>\n",
       "      <td>[(0, 0.014287275), (1, 0.014288068), (2, 0.685...</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.685652</td>\n",
       "      <td>0.014289</td>\n",
       "      <td>0.014289</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.200030</td>\n",
       "      <td>0.014294</td>\n",
       "      <td>0.014296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4088</th>\n",
       "      <td>三星半不熄的心火秘密花园情绪把控上跟情迷意乱一样出色极赞开片前后景虚实转换正反打后又影现于湖...</td>\n",
       "      <td>[(0, 0.016670624), (1, 0.016673286), (2, 0.016...</td>\n",
       "      <td>0.016671</td>\n",
       "      <td>0.016673</td>\n",
       "      <td>0.016673</td>\n",
       "      <td>0.245285</td>\n",
       "      <td>0.016675</td>\n",
       "      <td>0.016674</td>\n",
       "      <td>0.453728</td>\n",
       "      <td>0.184274</td>\n",
       "      <td>0.016678</td>\n",
       "      <td>0.016669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4206</th>\n",
       "      <td>改编小说漫漫回家路为了回家为了回到妈妈身边回到自己的土地3个孩子的漫长艰辛危险的旅程杜可风摄影极佳</td>\n",
       "      <td>[(1, 0.2785636), (6, 0.29506755), (7, 0.3725048)]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.278564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.295068</td>\n",
       "      <td>0.372505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4316</th>\n",
       "      <td>哈哈哈哈哈</td>\n",
       "      <td>[(0, 0.050000742), (1, 0.05000085), (2, 0.0500...</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.549994</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>以自杀为线索的电影</td>\n",
       "      <td>[(0, 0.033335287), (1, 0.033335205), (2, 0.033...</td>\n",
       "      <td>0.033335</td>\n",
       "      <td>0.033335</td>\n",
       "      <td>0.033342</td>\n",
       "      <td>0.033340</td>\n",
       "      <td>0.033339</td>\n",
       "      <td>0.699966</td>\n",
       "      <td>0.033337</td>\n",
       "      <td>0.033336</td>\n",
       "      <td>0.033335</td>\n",
       "      <td>0.033336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4556</th>\n",
       "      <td>黑暗的一天最终和黑暗传只有最后一部分的缘春苔看硬了想看三夫为什么我不去死</td>\n",
       "      <td>[(0, 0.02000234), (1, 0.23777263), (2, 0.39945...</td>\n",
       "      <td>0.020002</td>\n",
       "      <td>0.237773</td>\n",
       "      <td>0.399451</td>\n",
       "      <td>0.020002</td>\n",
       "      <td>0.222748</td>\n",
       "      <td>0.020006</td>\n",
       "      <td>0.020002</td>\n",
       "      <td>0.020010</td>\n",
       "      <td>0.020003</td>\n",
       "      <td>0.020002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4667</th>\n",
       "      <td>BBC拍摄的影片非常好笑英国人的幽默真乃一绝胖胖的男主角纠结于穆斯林和犹太身份间闹出笑话一箩...</td>\n",
       "      <td>[(0, 0.2785474), (1, 0.010001994), (2, 0.01000...</td>\n",
       "      <td>0.278547</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.327039</td>\n",
       "      <td>0.010006</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.324391</td>\n",
       "      <td>0.010003</td>\n",
       "      <td>0.010004</td>\n",
       "      <td>0.010005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>喜欢</td>\n",
       "      <td>[(0, 0.0500014), (1, 0.05000086), (2, 0.050004...</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050005</td>\n",
       "      <td>0.549984</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.050001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4917</th>\n",
       "      <td>表演配乐摄影都很棒</td>\n",
       "      <td>[(0, 0.26470605), (1, 0.5752795), (2, 0.020001...</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.575279</td>\n",
       "      <td>0.020002</td>\n",
       "      <td>0.020001</td>\n",
       "      <td>0.020001</td>\n",
       "      <td>0.020001</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020001</td>\n",
       "      <td>0.020002</td>\n",
       "      <td>0.020007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  \\\n",
       "2                                 上吊那裡超好笑可惜最後報告近況的旁白大扣分   \n",
       "129              徐海乔的演技很好人设也很苏对女主比较崩溃又作又矫情电影立意还好就是剧情太简单   \n",
       "248                      原来主妇还有这么青葱的岁月呀哈哈哈小姐这是你掉的熊吗啊哈哈哈   \n",
       "355                                         那是一种伤在血液里流动   \n",
       "473                                             小成本的好電影   \n",
       "592   如果你认识一对性欲非常旺盛的夫妇他们可能只是想要个孩子虽然是近来快被国内电视剧玩烂的题材但还...   \n",
       "725                                至今看了三个版本竟然没有一个版本贴原著的   \n",
       "845                                 打小就喜欢看这种片难怪现在喜欢看基情片   \n",
       "955                                               西班牙江姐   \n",
       "1073                                      笑死我了哈哈哈哈哈哈哈哈哈   \n",
       "1198                                         老头把我搞的热泪盈眶   \n",
       "1314                                  女主真的好像HarryPotter   \n",
       "1435                                             一般般一般般   \n",
       "1555  什么鬼不知道这个资源的翻译怎么搞的感觉都对不上号韩语也怪怪的听起来这女主角除了胸大都垂了和肤...   \n",
       "1673                   我叫张士豪我是游泳队吉他社长得还不错啊我有什么不好我就是要追你啊   \n",
       "1807                               让所有青春励志片见鬼去吧这才叫他妈的励志   \n",
       "1918  芳登和史都华这组合略神奇芳登在里边很漂亮但感觉她不太适合喜剧大部分时候看着都有点情绪低落史都...   \n",
       "2033                                    这么快的车速居然没把他摔死奇迹   \n",
       "2167                高中生特有的闲得蛋疼的淳朴感情都是过来人看到影片总能想起少年自己曾傻逼   \n",
       "2292  基本上讲述了一个完整的故事但是我不喜欢结尾人生无非就是等待和希望罢了这句最经典的话居然没有说...   \n",
       "2413                          你的对手是豆叔你都不敢争一下么反正他怎么都会死掉啊   \n",
       "2533                                        无厘头的体育类型励志片   \n",
       "2651                       除了老爷其他人的表演都太漫画化了女主这么天真真是开玩笑啊   \n",
       "2767                                             好雷人的电影   \n",
       "2886                                             廉价感超级浓   \n",
       "3007  凯奇叔苦大仇深的面部让人看得相当梗阻女猪翻车时嘴角自然上扬表示欣慰黑衣怪蜀黍身份大揭秘时笑到...   \n",
       "3145  好似掺杂了一丝阿基的味道一段日本大佬在美利坚的黑帮往事层层堆叠的回忆片段不提供完整的故事情节...   \n",
       "3261                                         Sandler太帅了   \n",
       "3381  为着迷的新疆风情特意跑去看了3D特效童年阿凡提故事的异域风情并不多民俗文化的普及比不上女主角...   \n",
       "3496  The2ndPYIFF一部关于电影的电影一部反射电影自身制作过程和自我认识的元电影影片加入了...   \n",
       "3618                                          影片的音乐感动了我   \n",
       "3734                     一如既往的冷暴力最后一段黑人丹尼的表演很有感染力令人笑中带泪   \n",
       "3851  这不是三段式的故事没有主人公的困境和人物关系复合前的多重障碍有的是两个可信的人物多情男子和她...   \n",
       "3973                       简单的爱情喜剧倒是拍出了新意就是男女猪实在是不合我滴审美   \n",
       "4088  三星半不熄的心火秘密花园情绪把控上跟情迷意乱一样出色极赞开片前后景虚实转换正反打后又影现于湖...   \n",
       "4206  改编小说漫漫回家路为了回家为了回到妈妈身边回到自己的土地3个孩子的漫长艰辛危险的旅程杜可风摄影极佳   \n",
       "4316                                              哈哈哈哈哈   \n",
       "4437                                          以自杀为线索的电影   \n",
       "4556               黑暗的一天最终和黑暗传只有最后一部分的缘春苔看硬了想看三夫为什么我不去死   \n",
       "4667  BBC拍摄的影片非常好笑英国人的幽默真乃一绝胖胖的男主角纠结于穆斯林和犹太身份间闹出笑话一箩...   \n",
       "4798                                                 喜欢   \n",
       "4917                                          表演配乐摄影都很棒   \n",
       "\n",
       "                                                 topics   topic_0   topic_1  \\\n",
       "2     [(0, 0.7748718), (1, 0.025009722), (2, 0.02501...  0.774872  0.025010   \n",
       "129                  [(4, 0.72543454), (8, 0.20179272)]  0.000000  0.000000   \n",
       "248   [(0, 0.016673487), (1, 0.01667151), (2, 0.0166...  0.016673  0.016672   \n",
       "355   [(0, 0.05000922), (1, 0.05000255), (2, 0.05000...  0.050009  0.050003   \n",
       "473   [(0, 0.05000306), (1, 0.050003435), (2, 0.0500...  0.050003  0.050003   \n",
       "592   [(0, 0.13448688), (1, 0.011114266), (2, 0.0111...  0.134487  0.011114   \n",
       "725   [(0, 0.012505284), (1, 0.012503927), (2, 0.012...  0.012505  0.012504   \n",
       "845   [(0, 0.03333409), (1, 0.0333338), (2, 0.033335...  0.033334  0.033334   \n",
       "955   [(0, 0.050003838), (1, 0.050010953), (2, 0.050...  0.050004  0.050011   \n",
       "1073  [(0, 0.02500031), (1, 0.02500035), (2, 0.02500...  0.025000  0.025000   \n",
       "1198  [(0, 0.050010346), (1, 0.050006215), (2, 0.050...  0.050010  0.050006   \n",
       "1314  [(0, 0.025005896), (1, 0.025000673), (2, 0.025...  0.025006  0.025001   \n",
       "1435  [(0, 0.03334633), (1, 0.03334633), (2, 0.03334...  0.033346  0.033346   \n",
       "1555  [(0, 0.014289671), (1, 0.014294171), (2, 0.014...  0.014290  0.014294   \n",
       "1673  [(0, 0.871376), (1, 0.014290944), (2, 0.014290...  0.871376  0.014291   \n",
       "1807  [(0, 0.025002142), (1, 0.025006535), (2, 0.025...  0.025002  0.025007   \n",
       "1918                 [(3, 0.28670153), (6, 0.64660144)]  0.000000  0.000000   \n",
       "2033  [(0, 0.05000321), (1, 0.0500008), (2, 0.549981...  0.050003  0.050001   \n",
       "2167  [(0, 0.020001808), (1, 0.48877764), (2, 0.0200...  0.020002  0.488778   \n",
       "2292                  [(2, 0.62067485), (7, 0.3322368)]  0.000000  0.000000   \n",
       "2413  [(0, 0.050001904), (1, 0.050001487), (2, 0.050...  0.050002  0.050001   \n",
       "2533  [(0, 0.32362223), (1, 0.033334453), (2, 0.4096...  0.323622  0.033334   \n",
       "2651  [(0, 0.02500979), (1, 0.025007304), (2, 0.7749...  0.025010  0.025007   \n",
       "2767  [(0, 0.05000316), (1, 0.050002832), (2, 0.0500...  0.050003  0.050003   \n",
       "2886  [(0, 0.05000377), (1, 0.050003316), (2, 0.0500...  0.050004  0.050003   \n",
       "3007  [(0, 0.020001888), (1, 0.43318284), (2, 0.0200...  0.020002  0.433183   \n",
       "3145  [(1, 0.07117014), (6, 0.59980816), (7, 0.08467...  0.000000  0.071170   \n",
       "3261  [(0, 0.050000984), (1, 0.050000984), (2, 0.050...  0.050001  0.050001   \n",
       "3381  [(0, 0.14878064), (1, 0.22745532), (6, 0.16987...  0.148781  0.227455   \n",
       "3496  [(2, 0.058663163), (3, 0.6003503), (5, 0.09329...  0.000000  0.000000   \n",
       "3618  [(0, 0.025013536), (1, 0.025007399), (2, 0.025...  0.025014  0.025007   \n",
       "3734  [(0, 0.01667116), (1, 0.016676746), (2, 0.0166...  0.016671  0.016677   \n",
       "3851  [(3, 0.49881306), (5, 0.18981883), (7, 0.27635...  0.000000  0.000000   \n",
       "3973  [(0, 0.014287275), (1, 0.014288068), (2, 0.685...  0.014287  0.014288   \n",
       "4088  [(0, 0.016670624), (1, 0.016673286), (2, 0.016...  0.016671  0.016673   \n",
       "4206  [(1, 0.2785636), (6, 0.29506755), (7, 0.3725048)]  0.000000  0.278564   \n",
       "4316  [(0, 0.050000742), (1, 0.05000085), (2, 0.0500...  0.050001  0.050001   \n",
       "4437  [(0, 0.033335287), (1, 0.033335205), (2, 0.033...  0.033335  0.033335   \n",
       "4556  [(0, 0.02000234), (1, 0.23777263), (2, 0.39945...  0.020002  0.237773   \n",
       "4667  [(0, 0.2785474), (1, 0.010001994), (2, 0.01000...  0.278547  0.010002   \n",
       "4798  [(0, 0.0500014), (1, 0.05000086), (2, 0.050004...  0.050001  0.050001   \n",
       "4917  [(0, 0.26470605), (1, 0.5752795), (2, 0.020001...  0.264706  0.575279   \n",
       "\n",
       "       topic_2   topic_3   topic_4   topic_5   topic_6   topic_7   topic_8  \\\n",
       "2     0.025011  0.025010  0.025011  0.025012  0.025027  0.025011  0.025024   \n",
       "129   0.000000  0.000000  0.725435  0.000000  0.000000  0.000000  0.201793   \n",
       "248   0.016671  0.016671  0.016672  0.849955  0.016671  0.016671  0.016671   \n",
       "355   0.050000  0.050010  0.050001  0.050001  0.050000  0.549970  0.050003   \n",
       "473   0.050005  0.050003  0.050003  0.050012  0.050003  0.050003  0.050003   \n",
       "592   0.011117  0.263763  0.011115  0.011118  0.011116  0.243479  0.291570   \n",
       "725   0.012505  0.012502  0.564786  0.012503  0.012503  0.012502  0.012503   \n",
       "845   0.033336  0.699991  0.033335  0.033334  0.033334  0.033334  0.033334   \n",
       "955   0.050004  0.050004  0.050004  0.050005  0.050004  0.549957  0.050004   \n",
       "1073  0.025000  0.025000  0.025000  0.774997  0.025000  0.025001  0.025000   \n",
       "1198  0.050011  0.050008  0.549936  0.050011  0.050006  0.050004  0.050004   \n",
       "1314  0.025002  0.401239  0.025004  0.025010  0.025003  0.025002  0.025011   \n",
       "1435  0.033346  0.033347  0.033347  0.033347  0.033346  0.699871  0.033346   \n",
       "1555  0.014290  0.182174  0.014291  0.014299  0.014290  0.703487  0.014292   \n",
       "1673  0.014290  0.014292  0.014291  0.014291  0.014291  0.014292  0.014295   \n",
       "1807  0.025009  0.025001  0.025003  0.025003  0.025001  0.774971  0.025004   \n",
       "1918  0.000000  0.286702  0.000000  0.000000  0.646601  0.000000  0.000000   \n",
       "2033  0.549982  0.050006  0.050001  0.050002  0.050003  0.050001  0.050001   \n",
       "2167  0.020002  0.020006  0.351195  0.020002  0.020003  0.020003  0.020003   \n",
       "2292  0.620675  0.000000  0.000000  0.000000  0.000000  0.332237  0.000000   \n",
       "2413  0.050001  0.050001  0.050001  0.050001  0.549989  0.050001  0.050001   \n",
       "2533  0.409679  0.033346  0.033336  0.033336  0.033334  0.033342  0.033334   \n",
       "2651  0.774904  0.025026  0.025006  0.025009  0.025004  0.025007  0.025009   \n",
       "2767  0.050002  0.549929  0.050017  0.050025  0.050010  0.050004  0.050003   \n",
       "2886  0.050004  0.050003  0.050003  0.050004  0.050003  0.549952  0.050003   \n",
       "3007  0.020009  0.020002  0.020007  0.020002  0.406784  0.020002  0.020004   \n",
       "3145  0.000000  0.000000  0.000000  0.000000  0.599808  0.084677  0.056879   \n",
       "3261  0.050001  0.050001  0.050001  0.050001  0.050002  0.050001  0.549990   \n",
       "3381  0.000000  0.000000  0.000000  0.000000  0.169876  0.121663  0.290542   \n",
       "3496  0.058663  0.600350  0.000000  0.093293  0.118114  0.000000  0.000000   \n",
       "3618  0.025004  0.025012  0.025008  0.025003  0.025005  0.774940  0.025004   \n",
       "3734  0.016675  0.016677  0.016671  0.322456  0.016671  0.016670  0.544160   \n",
       "3851  0.000000  0.498813  0.000000  0.189819  0.000000  0.276353  0.000000   \n",
       "3973  0.685652  0.014289  0.014289  0.014288  0.014288  0.200030  0.014294   \n",
       "4088  0.016673  0.245285  0.016675  0.016674  0.453728  0.184274  0.016678   \n",
       "4206  0.000000  0.000000  0.000000  0.000000  0.295068  0.372505  0.000000   \n",
       "4316  0.050001  0.050001  0.050001  0.549994  0.050001  0.050001  0.050001   \n",
       "4437  0.033342  0.033340  0.033339  0.699966  0.033337  0.033336  0.033335   \n",
       "4556  0.399451  0.020002  0.222748  0.020006  0.020002  0.020010  0.020003   \n",
       "4667  0.010002  0.327039  0.010006  0.010002  0.324391  0.010003  0.010004   \n",
       "4798  0.050005  0.549984  0.050003  0.050001  0.050001  0.050001  0.050001   \n",
       "4917  0.020002  0.020001  0.020001  0.020001  0.020000  0.020001  0.020002   \n",
       "\n",
       "       topic_9  \n",
       "2     0.025012  \n",
       "129   0.000000  \n",
       "248   0.016672  \n",
       "355   0.050002  \n",
       "473   0.549961  \n",
       "592   0.011122  \n",
       "725   0.335187  \n",
       "845   0.033334  \n",
       "955   0.050004  \n",
       "1073  0.025000  \n",
       "1198  0.050004  \n",
       "1314  0.398723  \n",
       "1435  0.033358  \n",
       "1555  0.014293  \n",
       "1673  0.014292  \n",
       "1807  0.025001  \n",
       "1918  0.000000  \n",
       "2033  0.050001  \n",
       "2167  0.020007  \n",
       "2292  0.000000  \n",
       "2413  0.050001  \n",
       "2533  0.033335  \n",
       "2651  0.025018  \n",
       "2767  0.050004  \n",
       "2886  0.050020  \n",
       "3007  0.020006  \n",
       "3145  0.162457  \n",
       "3261  0.050001  \n",
       "3381  0.000000  \n",
       "3496  0.116415  \n",
       "3618  0.025003  \n",
       "3734  0.016673  \n",
       "3851  0.000000  \n",
       "3973  0.014296  \n",
       "4088  0.016669  \n",
       "4206  0.000000  \n",
       "4316  0.050001  \n",
       "4437  0.033336  \n",
       "4556  0.020002  \n",
       "4667  0.010005  \n",
       "4798  0.050001  \n",
       "4917  0.020007  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dict to temporally hold the probabilities\n",
    "topicsProbDict = {i : [0] * len(ldaDF) for i in range(review_lda.num_topics)}\n",
    "\n",
    "#Load them into the dict\n",
    "for index, topicTuples in enumerate(ldaDF['topics']):\n",
    "    for topicNum, prob in topicTuples:\n",
    "        topicsProbDict[topicNum][index] = prob\n",
    "\n",
    "#Update the DataFrame\n",
    "for topicNum in range(review_lda.num_topics):\n",
    "    ldaDF['topic_{}'.format(topicNum)] = topicsProbDict[topicNum]\n",
    "\n",
    "ldaDF[1::100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaDFV = ldaDF[:10][['topic_%d' %x for x in range(10)]]\n",
    "ldaDFVisN = ldaDF[:10].index\n",
    "ldaDFVis = ldaDFV.values\n",
    "ldaDFVisNo = ldaDFVisN.values\n",
    "ldaDFVisNo = ['Review No. {}'.format(i) for i in ldaDFVisNo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cl/g60_skzn66v711f0ctx1nw_w0000gn/T/ipykernel_2391/253789795.py:14: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  plt.colorbar(cmap='Reds')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "K = review_lda.num_topics\n",
    "topic_labels = ['Topic #{}'.format(k) for k in range(K)]\n",
    "plt.pcolor(ldaDFVis, norm=None, cmap='Reds')\n",
    "plt.yticks(np.arange(ldaDFVis.shape[0])+0.5,ldaDFVisNo);\n",
    "plt.xticks(np.arange(ldaDFVis.shape[1])+0.5, topic_labels);\n",
    "\n",
    "# flip the y-axis so the texts are in the order we anticipate (Austen first, then Brontë)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# rotate the ticks on the x-axis\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# add a legend\n",
    "plt.colorbar(cmap='Reds')\n",
    "plt.tight_layout()  # fixes margins\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>Topic_3</th>\n",
       "      <th>Topic_4</th>\n",
       "      <th>Topic_5</th>\n",
       "      <th>Topic_6</th>\n",
       "      <th>Topic_7</th>\n",
       "      <th>Topic_8</th>\n",
       "      <th>Topic_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>一个</td>\n",
       "      <td>有趣</td>\n",
       "      <td>老爷</td>\n",
       "      <td>喜欢</td>\n",
       "      <td>电影</td>\n",
       "      <td>电影</td>\n",
       "      <td>电影</td>\n",
       "      <td>日本</td>\n",
       "      <td>一个</td>\n",
       "      <td>男人</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>镜头</td>\n",
       "      <td>摄影</td>\n",
       "      <td>片子</td>\n",
       "      <td>电影</td>\n",
       "      <td>一个</td>\n",
       "      <td>故事</td>\n",
       "      <td>爱情</td>\n",
       "      <td>导演</td>\n",
       "      <td>好看</td>\n",
       "      <td>剧情</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>搞笑</td>\n",
       "      <td>青春</td>\n",
       "      <td>黑暗</td>\n",
       "      <td>感觉</td>\n",
       "      <td>镜头</td>\n",
       "      <td>一部</td>\n",
       "      <td>婚姻</td>\n",
       "      <td>故事</td>\n",
       "      <td>故事</td>\n",
       "      <td>喜剧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>恋爱</td>\n",
       "      <td>刻意</td>\n",
       "      <td>精彩</td>\n",
       "      <td>表达</td>\n",
       "      <td>可爱</td>\n",
       "      <td>选择</td>\n",
       "      <td>美国</td>\n",
       "      <td>一种</td>\n",
       "      <td>发生</td>\n",
       "      <td>不到</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>算是</td>\n",
       "      <td>一部</td>\n",
       "      <td>开心</td>\n",
       "      <td>这部</td>\n",
       "      <td>年轻</td>\n",
       "      <td>制片</td>\n",
       "      <td>女人</td>\n",
       "      <td>15</td>\n",
       "      <td>角色</td>\n",
       "      <td>老版</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>导演</td>\n",
       "      <td>导演</td>\n",
       "      <td>喜欢</td>\n",
       "      <td>好像</td>\n",
       "      <td>女孩</td>\n",
       "      <td>一个</td>\n",
       "      <td>暴力</td>\n",
       "      <td>不错</td>\n",
       "      <td>导演</td>\n",
       "      <td>江湖</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>两个</td>\n",
       "      <td>片子</td>\n",
       "      <td>励志</td>\n",
       "      <td>困境</td>\n",
       "      <td>婚礼</td>\n",
       "      <td>小姐</td>\n",
       "      <td>名字</td>\n",
       "      <td>年轻</td>\n",
       "      <td>韩国</td>\n",
       "      <td>孩子</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>社会</td>\n",
       "      <td>形象</td>\n",
       "      <td>生活</td>\n",
       "      <td>影片</td>\n",
       "      <td>青春片</td>\n",
       "      <td>导演</td>\n",
       "      <td>一场</td>\n",
       "      <td>只能</td>\n",
       "      <td>演员</td>\n",
       "      <td>角色</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>竟然</td>\n",
       "      <td>调度</td>\n",
       "      <td>工作</td>\n",
       "      <td>观众</td>\n",
       "      <td>感觉</td>\n",
       "      <td>真的</td>\n",
       "      <td>期待</td>\n",
       "      <td>一个</td>\n",
       "      <td>夫妻</td>\n",
       "      <td>配乐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>兄弟</td>\n",
       "      <td>克制</td>\n",
       "      <td>剧情</td>\n",
       "      <td>风格</td>\n",
       "      <td>真实</td>\n",
       "      <td>仿佛</td>\n",
       "      <td>乏味</td>\n",
       "      <td>希望</td>\n",
       "      <td>青春</td>\n",
       "      <td>神经</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic_0 Topic_1 Topic_2 Topic_3 Topic_4 Topic_5 Topic_6 Topic_7 Topic_8  \\\n",
       "0      一个      有趣      老爷      喜欢      电影      电影      电影      日本      一个   \n",
       "1      镜头      摄影      片子      电影      一个      故事      爱情      导演      好看   \n",
       "2      搞笑      青春      黑暗      感觉      镜头      一部      婚姻      故事      故事   \n",
       "3      恋爱      刻意      精彩      表达      可爱      选择      美国      一种      发生   \n",
       "4      算是      一部      开心      这部      年轻      制片      女人      15      角色   \n",
       "5      导演      导演      喜欢      好像      女孩      一个      暴力      不错      导演   \n",
       "6      两个      片子      励志      困境      婚礼      小姐      名字      年轻      韩国   \n",
       "7      社会      形象      生活      影片     青春片      导演      一场      只能      演员   \n",
       "8      竟然      调度      工作      观众      感觉      真的      期待      一个      夫妻   \n",
       "9      兄弟      克制      剧情      风格      真实      仿佛      乏味      希望      青春   \n",
       "\n",
       "  Topic_9  \n",
       "0      男人  \n",
       "1      剧情  \n",
       "2      喜剧  \n",
       "3      不到  \n",
       "4      老版  \n",
       "5      江湖  \n",
       "6      孩子  \n",
       "7      角色  \n",
       "8      配乐  \n",
       "9      神经  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topicsDict = {}\n",
    "for topicNum in range(review_lda.num_topics):\n",
    "    topicWords = [w for w, p in review_lda.show_topic(topicNum)]\n",
    "    topicsDict['Topic_{}'.format(topicNum)] = topicWords\n",
    "\n",
    "wordRanksDF = pandas.DataFrame(topicsDict)\n",
    "wordRanksDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>topics</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>上吊那裡超好笑可惜最後報告近況的旁白大扣分</td>\n",
       "      <td>[(0, 0.027796784), (1, 0.8609968), (2, 0.02779...</td>\n",
       "      <td>0.027797</td>\n",
       "      <td>0.860997</td>\n",
       "      <td>0.027797</td>\n",
       "      <td>0.027795</td>\n",
       "      <td>0.027814</td>\n",
       "      <td>0.027801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>上海国际电影节观摩片</td>\n",
       "      <td>[(0, 0.0625147), (1, 0.0625147), (2, 0.0625147...</td>\n",
       "      <td>0.062515</td>\n",
       "      <td>0.062515</td>\n",
       "      <td>0.062515</td>\n",
       "      <td>0.062515</td>\n",
       "      <td>0.062515</td>\n",
       "      <td>0.687427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>那些不同人们的生活状态真实且残酷描述这类人生活的片子多了有点不太敢去德国了生怕那里的人心底里...</td>\n",
       "      <td>[(2, 0.117083274), (5, 0.86250025)]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.862500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>生活用最残酷的方式让你笑笑得哭出来</td>\n",
       "      <td>[(0, 0.02778144), (1, 0.027781915), (2, 0.0277...</td>\n",
       "      <td>0.027781</td>\n",
       "      <td>0.027782</td>\n",
       "      <td>0.027787</td>\n",
       "      <td>0.508974</td>\n",
       "      <td>0.027784</td>\n",
       "      <td>0.379892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>连这个竟然都看了</td>\n",
       "      <td>[(0, 0.062521815), (1, 0.6874453), (2, 0.06252...</td>\n",
       "      <td>0.062522</td>\n",
       "      <td>0.687445</td>\n",
       "      <td>0.062526</td>\n",
       "      <td>0.062502</td>\n",
       "      <td>0.062501</td>\n",
       "      <td>0.062504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>我不知道那时候为什么看了这么多香港口水片</td>\n",
       "      <td>[(0, 0.06252114), (1, 0.06252154), (2, 0.06253...</td>\n",
       "      <td>0.062521</td>\n",
       "      <td>0.062522</td>\n",
       "      <td>0.062535</td>\n",
       "      <td>0.062521</td>\n",
       "      <td>0.062521</td>\n",
       "      <td>0.687380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>小姐你的熊掉了小姐你的熊掉了小姐你的熊掉了我发现我建条目上瘾了</td>\n",
       "      <td>[(0, 0.9341956), (1, 0.0131615), (2, 0.0131592...</td>\n",
       "      <td>0.934196</td>\n",
       "      <td>0.013161</td>\n",
       "      <td>0.013159</td>\n",
       "      <td>0.013160</td>\n",
       "      <td>0.013163</td>\n",
       "      <td>0.013161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>全职主妇侦探不是强盗</td>\n",
       "      <td>[(0, 0.06253655), (1, 0.06253651), (2, 0.06255...</td>\n",
       "      <td>0.062537</td>\n",
       "      <td>0.062537</td>\n",
       "      <td>0.062551</td>\n",
       "      <td>0.687304</td>\n",
       "      <td>0.062536</td>\n",
       "      <td>0.062536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>哈哈哈哈哈哈哈师父果然威武</td>\n",
       "      <td>[(0, 0.027817165), (1, 0.3038627), (2, 0.30237...</td>\n",
       "      <td>0.027817</td>\n",
       "      <td>0.303863</td>\n",
       "      <td>0.302377</td>\n",
       "      <td>0.027813</td>\n",
       "      <td>0.027812</td>\n",
       "      <td>0.310318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  \\\n",
       "2                               上吊那裡超好笑可惜最後報告近況的旁白大扣分   \n",
       "3                                          上海国际电影节观摩片   \n",
       "5   那些不同人们的生活状态真实且残酷描述这类人生活的片子多了有点不太敢去德国了生怕那里的人心底里...   \n",
       "6                                   生活用最残酷的方式让你笑笑得哭出来   \n",
       "7                                            连这个竟然都看了   \n",
       "8                                我不知道那时候为什么看了这么多香港口水片   \n",
       "9                     小姐你的熊掉了小姐你的熊掉了小姐你的熊掉了我发现我建条目上瘾了   \n",
       "10                                         全职主妇侦探不是强盗   \n",
       "11                                      哈哈哈哈哈哈哈师父果然威武   \n",
       "\n",
       "                                               topics   topic_0   topic_1  \\\n",
       "2   [(0, 0.027796784), (1, 0.8609968), (2, 0.02779...  0.027797  0.860997   \n",
       "3   [(0, 0.0625147), (1, 0.0625147), (2, 0.0625147...  0.062515  0.062515   \n",
       "5                 [(2, 0.117083274), (5, 0.86250025)]  0.000000  0.000000   \n",
       "6   [(0, 0.02778144), (1, 0.027781915), (2, 0.0277...  0.027781  0.027782   \n",
       "7   [(0, 0.062521815), (1, 0.6874453), (2, 0.06252...  0.062522  0.687445   \n",
       "8   [(0, 0.06252114), (1, 0.06252154), (2, 0.06253...  0.062521  0.062522   \n",
       "9   [(0, 0.9341956), (1, 0.0131615), (2, 0.0131592...  0.934196  0.013161   \n",
       "10  [(0, 0.06253655), (1, 0.06253651), (2, 0.06255...  0.062537  0.062537   \n",
       "11  [(0, 0.027817165), (1, 0.3038627), (2, 0.30237...  0.027817  0.303863   \n",
       "\n",
       "     topic_2   topic_3   topic_4   topic_5  \n",
       "2   0.027797  0.027795  0.027814  0.027801  \n",
       "3   0.062515  0.062515  0.062515  0.687427  \n",
       "5   0.117083  0.000000  0.000000  0.862500  \n",
       "6   0.027787  0.508974  0.027784  0.379892  \n",
       "7   0.062526  0.062502  0.062501  0.062504  \n",
       "8   0.062535  0.062521  0.062521  0.687380  \n",
       "9   0.013159  0.013160  0.013163  0.013161  \n",
       "10  0.062551  0.687304  0.062536  0.062536  \n",
       "11  0.302377  0.027813  0.027812  0.310318  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_lda = gensim.models.ldamodel.LdaModel(corpus=review_mm, \n",
    "                                             id2word=review_dictionary, \n",
    "                                             num_topics=6, \n",
    "                                             alpha=0.1, \n",
    "                                             eta=0.01)\n",
    "ldaDF = pandas.DataFrame({\n",
    "        'content' : reviews['content'],\n",
    "        'topics' : [review_lda[review_dictionary.doc2bow(l)] for l in reviews['reduced_tokens']]\n",
    "    })\n",
    "\n",
    "#Dict to temporally hold the probabilities\n",
    "topicsProbDict = {i : [0] * len(ldaDF) for i in range(review_lda.num_topics)}\n",
    "\n",
    "#Load them into the dict\n",
    "for index, topicTuples in enumerate(ldaDF['topics']):\n",
    "    for topicNum, prob in topicTuples:\n",
    "        topicsProbDict[topicNum][index] = prob\n",
    "\n",
    "#Update the DataFrame\n",
    "for topicNum in range(review_lda.num_topics):\n",
    "    ldaDF['topic_{}'.format(topicNum)] = topicsProbDict[topicNum]\n",
    "\n",
    "ldaDF[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>Topic_3</th>\n",
       "      <th>Topic_4</th>\n",
       "      <th>Topic_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>喜欢</td>\n",
       "      <td>一部</td>\n",
       "      <td>喜剧</td>\n",
       "      <td>一个</td>\n",
       "      <td>导演</td>\n",
       "      <td>电影</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>一个</td>\n",
       "      <td>片子</td>\n",
       "      <td>婚姻</td>\n",
       "      <td>剧情</td>\n",
       "      <td>感觉</td>\n",
       "      <td>喜欢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>一部</td>\n",
       "      <td>开心</td>\n",
       "      <td>男人</td>\n",
       "      <td>电影</td>\n",
       "      <td>年轻</td>\n",
       "      <td>镜头</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>电影</td>\n",
       "      <td>真的</td>\n",
       "      <td>结局</td>\n",
       "      <td>感觉</td>\n",
       "      <td>选择</td>\n",
       "      <td>故事</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>青春</td>\n",
       "      <td>一个</td>\n",
       "      <td>爱情</td>\n",
       "      <td>喜欢</td>\n",
       "      <td>故事</td>\n",
       "      <td>日本</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>励志</td>\n",
       "      <td>电影</td>\n",
       "      <td>搞笑</td>\n",
       "      <td>睡着</td>\n",
       "      <td>一种</td>\n",
       "      <td>这部</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>角色</td>\n",
       "      <td>乏味</td>\n",
       "      <td>兄弟</td>\n",
       "      <td>恋爱</td>\n",
       "      <td>喜欢</td>\n",
       "      <td>表达</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>有趣</td>\n",
       "      <td>故事</td>\n",
       "      <td>生活</td>\n",
       "      <td>婚礼</td>\n",
       "      <td>老爷</td>\n",
       "      <td>一个</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>影片</td>\n",
       "      <td>期待</td>\n",
       "      <td>悲剧</td>\n",
       "      <td>浪费</td>\n",
       "      <td>一个</td>\n",
       "      <td>感觉</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>一段</td>\n",
       "      <td>发生</td>\n",
       "      <td>记得</td>\n",
       "      <td>方式</td>\n",
       "      <td>有趣</td>\n",
       "      <td>黑暗</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic_0 Topic_1 Topic_2 Topic_3 Topic_4 Topic_5\n",
       "0      喜欢      一部      喜剧      一个      导演      电影\n",
       "1      一个      片子      婚姻      剧情      感觉      喜欢\n",
       "2      一部      开心      男人      电影      年轻      镜头\n",
       "3      电影      真的      结局      感觉      选择      故事\n",
       "4      青春      一个      爱情      喜欢      故事      日本\n",
       "5      励志      电影      搞笑      睡着      一种      这部\n",
       "6      角色      乏味      兄弟      恋爱      喜欢      表达\n",
       "7      有趣      故事      生活      婚礼      老爷      一个\n",
       "8      影片      期待      悲剧      浪费      一个      感觉\n",
       "9      一段      发生      记得      方式      有趣      黑暗"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topicsDict = {}\n",
    "for topicNum in range(review_lda.num_topics):\n",
    "    topicWords = [w for w, p in review_lda.show_topic(topicNum)]\n",
    "    topicsDict['Topic_{}'.format(topicNum)] = topicWords\n",
    "\n",
    "wordRanksDF = pandas.DataFrame(topicsDict)\n",
    "wordRanksDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>topics</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>上吊那裡超好笑可惜最後報告近況的旁白大扣分</td>\n",
       "      <td>[(0, 0.027781315), (1, 0.027781803), (2, 0.027...</td>\n",
       "      <td>0.027781</td>\n",
       "      <td>0.027782</td>\n",
       "      <td>0.027782</td>\n",
       "      <td>0.027783</td>\n",
       "      <td>0.027782</td>\n",
       "      <td>0.861090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>上海国际电影节观摩片</td>\n",
       "      <td>[(0, 0.062524945), (1, 0.062524945), (2, 0.687...</td>\n",
       "      <td>0.062525</td>\n",
       "      <td>0.062525</td>\n",
       "      <td>0.687351</td>\n",
       "      <td>0.062532</td>\n",
       "      <td>0.062525</td>\n",
       "      <td>0.062542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>那些不同人们的生活状态真实且残酷描述这类人生活的片子多了有点不太敢去德国了生怕那里的人心底里...</td>\n",
       "      <td>[(3, 0.2029519), (4, 0.7766278)]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202952</td>\n",
       "      <td>0.776628</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>生活用最残酷的方式让你笑笑得哭出来</td>\n",
       "      <td>[(0, 0.027789395), (1, 0.027787425), (2, 0.440...</td>\n",
       "      <td>0.027789</td>\n",
       "      <td>0.027787</td>\n",
       "      <td>0.440833</td>\n",
       "      <td>0.448016</td>\n",
       "      <td>0.027785</td>\n",
       "      <td>0.027788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>连这个竟然都看了</td>\n",
       "      <td>[(0, 0.06250188), (1, 0.06250266), (2, 0.68747...</td>\n",
       "      <td>0.062502</td>\n",
       "      <td>0.062503</td>\n",
       "      <td>0.687475</td>\n",
       "      <td>0.062501</td>\n",
       "      <td>0.062502</td>\n",
       "      <td>0.062518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>我不知道那时候为什么看了这么多香港口水片</td>\n",
       "      <td>[(0, 0.06253779), (1, 0.06252434), (2, 0.06251...</td>\n",
       "      <td>0.062538</td>\n",
       "      <td>0.062524</td>\n",
       "      <td>0.062519</td>\n",
       "      <td>0.062519</td>\n",
       "      <td>0.062519</td>\n",
       "      <td>0.687380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>小姐你的熊掉了小姐你的熊掉了小姐你的熊掉了我发现我建条目上瘾了</td>\n",
       "      <td>[(0, 0.9342012), (1, 0.013159618), (2, 0.01315...</td>\n",
       "      <td>0.934201</td>\n",
       "      <td>0.013160</td>\n",
       "      <td>0.013160</td>\n",
       "      <td>0.013160</td>\n",
       "      <td>0.013160</td>\n",
       "      <td>0.013159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>全职主妇侦探不是强盗</td>\n",
       "      <td>[(0, 0.06254208), (1, 0.06255752), (2, 0.06254...</td>\n",
       "      <td>0.062542</td>\n",
       "      <td>0.062558</td>\n",
       "      <td>0.062542</td>\n",
       "      <td>0.062542</td>\n",
       "      <td>0.687259</td>\n",
       "      <td>0.062558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>哈哈哈哈哈哈哈师父果然威武</td>\n",
       "      <td>[(0, 0.0278009), (1, 0.86099255), (2, 0.027802...</td>\n",
       "      <td>0.027801</td>\n",
       "      <td>0.860993</td>\n",
       "      <td>0.027802</td>\n",
       "      <td>0.027802</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.027803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  \\\n",
       "2                               上吊那裡超好笑可惜最後報告近況的旁白大扣分   \n",
       "3                                          上海国际电影节观摩片   \n",
       "5   那些不同人们的生活状态真实且残酷描述这类人生活的片子多了有点不太敢去德国了生怕那里的人心底里...   \n",
       "6                                   生活用最残酷的方式让你笑笑得哭出来   \n",
       "7                                            连这个竟然都看了   \n",
       "8                                我不知道那时候为什么看了这么多香港口水片   \n",
       "9                     小姐你的熊掉了小姐你的熊掉了小姐你的熊掉了我发现我建条目上瘾了   \n",
       "10                                         全职主妇侦探不是强盗   \n",
       "11                                      哈哈哈哈哈哈哈师父果然威武   \n",
       "\n",
       "                                               topics   topic_0   topic_1  \\\n",
       "2   [(0, 0.027781315), (1, 0.027781803), (2, 0.027...  0.027781  0.027782   \n",
       "3   [(0, 0.062524945), (1, 0.062524945), (2, 0.687...  0.062525  0.062525   \n",
       "5                    [(3, 0.2029519), (4, 0.7766278)]  0.000000  0.000000   \n",
       "6   [(0, 0.027789395), (1, 0.027787425), (2, 0.440...  0.027789  0.027787   \n",
       "7   [(0, 0.06250188), (1, 0.06250266), (2, 0.68747...  0.062502  0.062503   \n",
       "8   [(0, 0.06253779), (1, 0.06252434), (2, 0.06251...  0.062538  0.062524   \n",
       "9   [(0, 0.9342012), (1, 0.013159618), (2, 0.01315...  0.934201  0.013160   \n",
       "10  [(0, 0.06254208), (1, 0.06255752), (2, 0.06254...  0.062542  0.062558   \n",
       "11  [(0, 0.0278009), (1, 0.86099255), (2, 0.027802...  0.027801  0.860993   \n",
       "\n",
       "     topic_2   topic_3   topic_4   topic_5  \n",
       "2   0.027782  0.027783  0.027782  0.861090  \n",
       "3   0.687351  0.062532  0.062525  0.062542  \n",
       "5   0.000000  0.202952  0.776628  0.000000  \n",
       "6   0.440833  0.448016  0.027785  0.027788  \n",
       "7   0.687475  0.062501  0.062502  0.062518  \n",
       "8   0.062519  0.062519  0.062519  0.687380  \n",
       "9   0.013160  0.013160  0.013160  0.013159  \n",
       "10  0.062542  0.062542  0.687259  0.062558  \n",
       "11  0.027802  0.027802  0.027800  0.027803  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_lda = gensim.models.ldamodel.LdaModel(corpus=review_mm, \n",
    "                                             id2word=review_dictionary, \n",
    "                                             num_topics=6, \n",
    "                                             alpha=0.1, \n",
    "                                             eta=0.1)\n",
    "ldaDF = pandas.DataFrame({\n",
    "        'content' : reviews['content'],\n",
    "        'topics' : [review_lda[review_dictionary.doc2bow(l)] for l in reviews['reduced_tokens']]\n",
    "    })\n",
    "\n",
    "#Dict to temporally hold the probabilities\n",
    "topicsProbDict = {i : [0] * len(ldaDF) for i in range(review_lda.num_topics)}\n",
    "\n",
    "#Load them into the dict\n",
    "for index, topicTuples in enumerate(ldaDF['topics']):\n",
    "    for topicNum, prob in topicTuples:\n",
    "        topicsProbDict[topicNum][index] = prob\n",
    "\n",
    "#Update the DataFrame\n",
    "for topicNum in range(review_lda.num_topics):\n",
    "    ldaDF['topic_{}'.format(topicNum)] = topicsProbDict[topicNum]\n",
    "\n",
    "ldaDF[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>Topic_3</th>\n",
       "      <th>Topic_4</th>\n",
       "      <th>Topic_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>日本</td>\n",
       "      <td>一个</td>\n",
       "      <td>电影</td>\n",
       "      <td>电影</td>\n",
       "      <td>喜欢</td>\n",
       "      <td>电影</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>田中</td>\n",
       "      <td>喜欢</td>\n",
       "      <td>导演</td>\n",
       "      <td>感觉</td>\n",
       "      <td>电影</td>\n",
       "      <td>导演</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>老爷</td>\n",
       "      <td>镜头</td>\n",
       "      <td>一部</td>\n",
       "      <td>一个</td>\n",
       "      <td>困境</td>\n",
       "      <td>故事</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>一个</td>\n",
       "      <td>婚姻</td>\n",
       "      <td>不错</td>\n",
       "      <td>故事</td>\n",
       "      <td>男人</td>\n",
       "      <td>喜剧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>北野武</td>\n",
       "      <td>爱情</td>\n",
       "      <td>一个</td>\n",
       "      <td>生活</td>\n",
       "      <td>励志</td>\n",
       "      <td>表达</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>发生</td>\n",
       "      <td>开心</td>\n",
       "      <td>这部</td>\n",
       "      <td>镜头</td>\n",
       "      <td>搞笑</td>\n",
       "      <td>很多</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>妈妈</td>\n",
       "      <td>美国</td>\n",
       "      <td>青春</td>\n",
       "      <td>一种</td>\n",
       "      <td>喜剧</td>\n",
       "      <td>印象</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>阿凡提</td>\n",
       "      <td>阿凡提</td>\n",
       "      <td>影片</td>\n",
       "      <td>人物</td>\n",
       "      <td>亚当</td>\n",
       "      <td>时刻</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>工作</td>\n",
       "      <td>选择</td>\n",
       "      <td>喜欢</td>\n",
       "      <td>剧情</td>\n",
       "      <td>一场</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>期待</td>\n",
       "      <td>恋爱</td>\n",
       "      <td>片子</td>\n",
       "      <td>郑佩佩</td>\n",
       "      <td>镜头</td>\n",
       "      <td>一个</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic_0 Topic_1 Topic_2 Topic_3 Topic_4 Topic_5\n",
       "0      日本      一个      电影      电影      喜欢      电影\n",
       "1      田中      喜欢      导演      感觉      电影      导演\n",
       "2      老爷      镜头      一部      一个      困境      故事\n",
       "3      一个      婚姻      不错      故事      男人      喜剧\n",
       "4     北野武      爱情      一个      生活      励志      表达\n",
       "5      发生      开心      这部      镜头      搞笑      很多\n",
       "6      妈妈      美国      青春      一种      喜剧      印象\n",
       "7     阿凡提     阿凡提      影片      人物      亚当      时刻\n",
       "8      工作      选择      喜欢      剧情      一场      15\n",
       "9      期待      恋爱      片子     郑佩佩      镜头      一个"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topicsDict = {}\n",
    "for topicNum in range(review_lda.num_topics):\n",
    "    topicWords = [w for w, p in review_lda.show_topic(topicNum)]\n",
    "    topicsDict['Topic_{}'.format(topicNum)] = topicWords\n",
    "\n",
    "wordRanksDF = pandas.DataFrame(topicsDict)\n",
    "wordRanksDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic modeling tells us more details about those reviews. At first I used 10 topics to fit the model, many top weighted words overlap. Then I ruduced the number to 6. We can find different feelings and genres in different topics. Changing $\\eta$ from 0.01 to 0.1 makes the topics more confusing. Many names occur in topics. I think it's beacuse all reviews are short so they have their unique words. Hence a higher $\\eta$ maybe a misplace.\n",
    "Combining with clustering results, topic modelling did tell us more details about those reviews. However, this a rudimentary exploration. Some improvements can be made. For example, 一个（a/one）,电影（movie) appeared in many topics. We could add these words to stop words list first. This is a randomed sample. Most reviews are from less popular movies. Maybe sampling reviews from a few popular movies is a better choice. We can find more interesting patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending Topic Models within broader research pipelines\n",
    "\n",
    "Topic models can be the base of more complex analysis. One good example is the paper - Individuals, institutions, and innovation in the debates of the French Revolution (https://www.pnas.org/content/115/18/4607), where they use topic models to find similarities and differences between the topics of different individuals. Let us revisit this idea using the Soap opera database. Who innovates and influences the most within the Soap?\n",
    "\n",
    "The next few lines of code follows the same process as last weeks notebook. Please visit the old notebook to read descriptions of the code if you have forgotten what it does. `lucem_illud.loadDavies` can be found in [loaders.py](https://github.com/UChicago-Computational-Content-Analysis/lucem_illud/blob/main/lucem_illud/loaders.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora_address = \"/Users/bhargavvader/Downloads/Academics_Tech/corpora/SOAP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soap_texts = lucem_illud.loadDavies(corpora_address, num_files=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zfile = zipfile.ZipFile(corpora_address + \"/soap_sources.zip\")\n",
    "source = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in zfile.namelist():\n",
    "    with zfile.open(file) as f:\n",
    "        for line in f:\n",
    "            source.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soap_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for soap in source[3:]:\n",
    "    try:\n",
    "        textID, year, show, url = soap.decode(\"utf-8\").split(\"\\t\")\n",
    "    except UnicodeDecodeError:\n",
    "        continue\n",
    "    if show.strip() not in soap_dict:\n",
    "        soap_dict[show.strip()] = []\n",
    "    if show.strip() in soap_dict:\n",
    "        try:\n",
    "            soap_dict[show.strip()].append(soap_texts[textID.strip()])\n",
    "        except KeyError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soap_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soap_df = pd.DataFrame(columns=[\"Soap Name\", \"Tokenized Texts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for soap in soap_dict:\n",
    "    # since there were multiple lists\n",
    "    print(soap)\n",
    "    full_script = []\n",
    "    for part in soap_dict[soap]:\n",
    "        full_script = full_script + part\n",
    "    soap_df.loc[i] = [soap, full_script]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soap_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking to see which index I should use. In my example it is the last one, so I choose my index as 9. It might be different for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dool = soap_df['Tokenized Texts'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(dool[0:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = {}\n",
    "for token in dool:\n",
    "    if token[0] == '@':\n",
    "        # all characters or actions start with @, so we add that to character\n",
    "        if token[2:] not in characters:\n",
    "            characters[token[2:]] = 0\n",
    "        if token[2:] in characters:\n",
    "            characters[token[2:]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_network = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for character in characters:\n",
    "    if characters[character] > 2000:\n",
    "        actor_network.add_node(character, lines_spoken= characters[character], words=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in dool:\n",
    "    i += 1\n",
    "    if i > len(dool):\n",
    "        break\n",
    "    if token[0] == \"@\":\n",
    "        if token[2:] in actor_network.nodes():\n",
    "            j = i\n",
    "            for token_ in dool[i:]:\n",
    "                if token_[0] == \"@\":\n",
    "                    # if both the characters exist in the graph, add a weight\n",
    "                    if token_[2:] != token[2:] and token_[2:] in actor_network.nodes():\n",
    "                        if (token[2:], token_[2:]) not in actor_network.edges():\n",
    "                            actor_network.add_edge(token[2:], token_[2:], weight=0)\n",
    "                        if (token[2:], token_[2:]) in actor_network.edges():\n",
    "                            actor_network.edges[(token[2:], token_[2:])]['weight'] += 1\n",
    "                    break\n",
    "                j += 1\n",
    "            # adding characters sentences\n",
    "            actor_network.nodes[token[2:]]['words'].append(dool[i:j])\n",
    "            all_texts.append(lucem_illud.normalizeTokens(dool[i:j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(actor_network, with_labels=True, font_weight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok - so we have our graph now. Let us create a topic model with all the texts spoken by the characters, see what's being spoken about, and construct topic distributions for each character. What does our all_texts corpus look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in all_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim.corpora.MmCorpus.serialize('dool.mm', corpus)\n",
    "doolcorpus = gensim.corpora.MmCorpus('dool.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doollda = gensim.models.ldamodel.LdaModel(corpus=doolcorpus, id2word=dictionary, num_topics=10, alpha='auto', eta='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doollda.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are your topics interpretable/interesting? Sometimes they require a good deal of fine tuning and parameter choosing to get it to work in a nice way. Check out the gensim ldamodel documentation page and see what parameters you can play around with and try the model again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for actor in actor_network.nodes():\n",
    "    actor_all_words = []\n",
    "    for sent in actor_network.nodes[actor]['words']:\n",
    "        for word in sent:\n",
    "            actor_all_words += word\n",
    "    actor_network.nodes[actor]['topic_distribution'] = doollda[dictionary.doc2bow(lucem_illud.normalizeTokens(actor_all_words))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have topic distributions for each character. Let us have a brief look at what the characters are talking about. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for actor in actor_network.nodes():\n",
    "    print(actor, actor_network.nodes[actor]['topic_distribution'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quickly eye-balling these distributions suggest that the model itself could be tuned better - all the topics are loaded more or less equally. \n",
    "\n",
    "In the paper I linked to earlier, they found similarities or differences using the KL divergence - this is a topic we've dealt with before. Let us plot a heatmap with these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.matutils import kullback_leibler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_prob(bow):\n",
    "    ps = []\n",
    "    for topic_no, topic_prob in bow:\n",
    "        ps.append(topic_prob)\n",
    "    return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = []\n",
    "for actor_1 in actor_network.nodes():\n",
    "    p = actor_network.nodes[actor_1]['topic_distribution'] \n",
    "    p = convert_to_prob(p)\n",
    "    l = []\n",
    "    for actor_2 in actor_network.nodes():\n",
    "        q = actor_network.nodes[actor_2]['topic_distribution'] \n",
    "        q = convert_to_prob(q)\n",
    "        l.append(kullback_leibler(p, q))\n",
    "    L.append(l)\n",
    "M = np.array(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "div = pandas.DataFrame(M, columns = list(actor_network.nodes()), index = list(actor_network.nodes()))\n",
    "ax = sns.heatmap(div)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one example of how we can use topic models to analyse a network - what other data exploration can you come up with?  Maybe see what are the themes surrounding the top topics for each of the actors? You now have the infrastructure to explore the network and the topics. Gensim has a great set of Jupyter Notebooks which illustrate their methods and functions - https://github.com/RaRe-Technologies/gensim/tree/develop/docs/notebooks. The Auto Examples page also has a good variety of examples - https://radimrehurek.com/gensim/auto_examples/. \n",
    "\n",
    "\n",
    "### Dynamic Topic Modelling\n",
    "\n",
    "Dynamic Topic Modelling is a time based topic model method introduced by David Blei and John Lafferty. It allows one to see topics evolve over a time annotated corpus. I would recommend first viewing the Dynamic Topic Model tutorial on Gensim (https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/ldaseqmodel.ipynb) to understand what exactly it's about. \n",
    "\n",
    "(An acknowledgement - Bhargav (the author of most of this class's code) wrote the code for Gensim's Dynamic Topic Models back in 2016 as a Google Summer of Code student, and they're still using it as are thousands of others!)\n",
    "\n",
    "To demonstrate it on a time based corpus, we will create a corpus from COHA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora_address = \"/Users/bhargavvader/Downloads/Academics_Tech/corpora/COHA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coha_texts = lucem_illud.loadDavies(corpora_address, return_raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(coha_texts.keys())[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd have to approach this differently: note that while extracting the corpus we returned the raw texts, and the dictionary keys already contain some useful information: the year published, and the genre. neat! We can now create some corpora, organised by year and by genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coha_genres = {}\n",
    "coha_years = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in coha_texts:\n",
    "    genre, year, id_ = article.split(\"_\")\n",
    "    if genre not in coha_genres:\n",
    "        coha_genres[genre] = []\n",
    "    if genre in coha_genres:\n",
    "        coha_genres[genre].append(coha_texts[article])\n",
    "    \n",
    "    if year not in coha_years:\n",
    "        coha_years[year] = []\n",
    "    if year in coha_years:\n",
    "        coha_years[year].append(coha_texts[article])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coha_genres.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coha_years.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's neat: we have 4 genres and 200 years. We have to now decide how many time slices we want. Let us see how the corpus is distributed.\n",
    "\n",
    "If you went through the tutorial, you would notice how we would need to arrange the corpora year wise.\n",
    "We also have to arrange the number of topics per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "year_lens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year_info in collections.OrderedDict(sorted(coha_years.items())):\n",
    "    years.append(year_info)\n",
    "    year_lens.append(len((coha_years[year_info])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years[0], years[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(years, year_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The X axis isn't legible, but you can get the point: there are far less articles in the beginning, and then it grows. Maybe in our 5 time slices, we do: 1810-1880, 1881-1913, 1914-1950, 1950-1990, 1990-2009?\n",
    "I use some historical intuition to use these time periods, you are encouraged to try your different time slices (for e.g, 20 10 year periods, 10 20 year periods, by total number of papers, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts_coha = []\n",
    "docs_per_timeslice = [0, 0, 0, 0, 0]\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year_info in collections.OrderedDict(sorted(coha_years.items())):\n",
    "    large_files = 0\n",
    "    for article in coha_years[year_info]:\n",
    "        try:\n",
    "            if len(article[2]) < 1500000:\n",
    "                all_texts_coha.append(lucem_illud.normalizeTokens(article[2].decode(\"utf-8\")))\n",
    "            if len(article[2]) >= 1500000:\n",
    "                large_files += 1\n",
    "        except IndexError:\n",
    "            continue\n",
    "    # these numbers are the number of years in the \n",
    "    if i < 70:\n",
    "        docs_per_year[0] += len(coha_years[year_info]) - large_files\n",
    "    if i >= 70 and i < 103:\n",
    "        docs_per_year[1] += len(coha_years[year_info]) - large_files\n",
    "    if i >= 103 and i < 140:\n",
    "        docs_per_year[2] += len(coha_years[year_info]) - large_files\n",
    "    if i >= 140 and i < 180:\n",
    "        docs_per_year[3] += len(coha_years[year_info]) - large_files\n",
    "    if i >= 180:\n",
    "        docs_per_year[4] += len(coha_years[year_info]) - large_files\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smaller Corpora\n",
    "\n",
    "The original size of the corpus is wayyy too big for our laptops. Let us demo this with a smaller size. You are welcome to try different sizes until you get the size you would like.\n",
    "I am using a 100 documents per time slice for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_n(corpus, time_slices, nums=100):\n",
    "    new_corpus = corpus[0:nums]\n",
    "    for time_slice in time_slices[:-1]:\n",
    "        new_corpus = new_corpus + corpus[time_slice:time_slice+nums]\n",
    "    return new_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, COHA also has some really large files, full books and the like: we're going to now split up really large files such that each of the documents are only 1000 tokens long. This function will return a split up document and the number of files it has been split into, so we can accordingly adjust the documents per time slice, which is important for Dynamic Topic Modelling to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_up(document, doc_size=1000):\n",
    "    new_docs = [document[i:i + doc_size] for i in range(0, len(document), doc_size)]\n",
    "    return(new_docs, len(new_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_corpus = choose_n(all_texts_coha, docs_per_year, nums=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_corpus= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_per_time_slice = [0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now use the split method to create my final corpus. Note that I hardcode values for the time slice to figure out the number of documets per time slice. Now I have a representative number of documents in each time slice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, article in enumerate(small_corpus):\n",
    "    # identify time slice based on article number \n",
    "    if i < 100:\n",
    "        time = 0\n",
    "    if i > 100 and i <= 200:\n",
    "        time = 1\n",
    "    if i > 200 and i <= 300:\n",
    "        time = 2\n",
    "    if i > 300 and i <= 400:\n",
    "        time = 3\n",
    "    if i > 400 and i <= 500:\n",
    "        time = 4\n",
    "        \n",
    "    if len(article) > 1000:\n",
    "        split_docs, no_docs = split_up(article)\n",
    "        for doc in split_docs:\n",
    "            final_corpus.append(doc)\n",
    "        docs_per_time_slice[time] += no_docs\n",
    "    else:\n",
    "        final_corpus.append(article)\n",
    "        docs_per_time_slice[time] += 1\n",
    "    # just a check if the counts are correctly added\n",
    "    if np.sum(docs_per_time_slice) != len(final_corpus):\n",
    "        print(np.sum(docs_per_time_slice), len(final_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(final_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in final_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim.corpora.MmCorpus.serialize('coha.mm', corpus)\n",
    "cohacorpus = gensim.corpora.MmCorpus('coha.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import ldaseqmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaseq = ldaseqmodel.LdaSeqModel(corpus=corpus, id2word=dictionary, time_slice=docs_per_time_slice, num_topics=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaseq.print_topics(time=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaseq.print_topics(time=4)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you see from the analysis? I encourage you to explore the tutorial and see what else you can do with this dataset. In the above model I can see how the topic related to state evolves slowly, with the word president not previously there coming into the topic. I will now save this model and also upload it on GitHub so that you can see how it works. Note that the Dynamic Topic Model is a very time consuming algorithm: you might want to start a run overnight if you intend on using it in your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaseq.save(\"ldaseqmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = ldaseqmodel.LdaSeqModel.load(\"ldaseqmodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For future research, you can also consider the Structural Topic Model (STM), which can integrate any covariates (e.g., time, author, document length) into your topic model. Unfortunately there is not yet an implementation of this in Python, but there is a wonderful [R package](https://www.structuraltopicmodel.com/) authored by Molly Roberts, Brandon Stewart, and Dustin Tingley.\n",
    "\n",
    "Here are plate diagrams of LDA and STM, which may help you visualize the way STM adds covariates to the \"left\" and \"right\" of the standard LDA model.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/UChicago-Computational-Content-Analysis/Homework-Notebooks/main/week-3/img/lda_stm_plate_diagrams.jpg\" alt=\"https://raw.githubusercontent.com/UChicago-Computational-Content-Analysis/Homework-Notebooks/main/week-3/img/lda_stm_plate_diagrams.jpg\" style=\"width:500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## <font color=\"red\">*Exercise 4*</font>\n",
    "\n",
    "<font color=\"red\">Construct cells immediately below this that use dynamic topic models on datasets relevant to your final project. You can also extend the analysis of the COHA or Soap datasets, if relevant to the comparison of data for your projects. (You could possibly use coha_genres dictionary to conduct analysis on topic evolution for a particular genre? What themes do you see evolving throughout these corpora?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, I selected around 500 reviews per year to build a dynamic topic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_all = pandas.read_csv('/Users/mao_shiba/Downloads/moviedata-10m/moviedata-10m/comments.csv')\n",
    "reviews_all = reviews_all.loc[:, ['COMMENT_TIME','CONTENT', 'MOVIE_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_TIME</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>MOVIE_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4427687</th>\n",
       "      <td>2019-09-07 15:57:07</td>\n",
       "      <td>就很尬，很无聊，笑点好无语，朱亚文为什么要接这样的片子啊………</td>\n",
       "      <td>27063867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4427686</th>\n",
       "      <td>2019-09-07 15:58:03</td>\n",
       "      <td>吃了感冒药去看的，困上加困。朱亚文是想通过这部作品来拓宽戏路吗？</td>\n",
       "      <td>27063867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4427685</th>\n",
       "      <td>2019-09-07 15:58:51</td>\n",
       "      <td>有些地方还是很好笑的，奔着两位主演去看，他们也确实有范儿，倒数第二场戏，两人穿礼服去办公室真...</td>\n",
       "      <td>27063867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4418159</th>\n",
       "      <td>2019-09-07 15:59:42</td>\n",
       "      <td>OMG</td>\n",
       "      <td>1292226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4424115</th>\n",
       "      <td>2019-09-07 16:00:15</td>\n",
       "      <td>舒缓的节奏与童书相称</td>\n",
       "      <td>1900121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               COMMENT_TIME  \\\n",
       "4427687 2019-09-07 15:57:07   \n",
       "4427686 2019-09-07 15:58:03   \n",
       "4427685 2019-09-07 15:58:51   \n",
       "4418159 2019-09-07 15:59:42   \n",
       "4424115 2019-09-07 16:00:15   \n",
       "\n",
       "                                                   CONTENT  MOVIE_ID  \n",
       "4427687                    就很尬，很无聊，笑点好无语，朱亚文为什么要接这样的片子啊………  27063867  \n",
       "4427686                   吃了感冒药去看的，困上加困。朱亚文是想通过这部作品来拓宽戏路吗？  27063867  \n",
       "4427685  有些地方还是很好笑的，奔着两位主演去看，他们也确实有范儿，倒数第二场戏，两人穿礼服去办公室真...  27063867  \n",
       "4418159                                                OMG   1292226  \n",
       "4424115                                         舒缓的节奏与童书相称   1900121  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_all['COMMENT_TIME'] = pandas.to_datetime(reviews_all['COMMENT_TIME'])\n",
    "reviews_all = reviews_all.sort_values(by = 'COMMENT_TIME')\n",
    "reviews_all.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_all = reviews_all.set_index('COMMENT_TIME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews in Time Slice 0: 13596\n",
      "Reviews in Time Slice 1: 34985\n",
      "Reviews in Time Slice 2: 92790\n",
      "Reviews in Time Slice 3: 142998\n",
      "Reviews in Time Slice 4: 261817\n",
      "Reviews in Time Slice 5: 355514\n",
      "Reviews in Time Slice 6: 377019\n",
      "Reviews in Time Slice 7: 312148\n",
      "Reviews in Time Slice 8: 270202\n",
      "Reviews in Time Slice 9: 268842\n",
      "Reviews in Time Slice 10: 344790\n",
      "Reviews in Time Slice 11: 453416\n",
      "Reviews in Time Slice 12: 563923\n",
      "Reviews in Time Slice 13: 934830\n"
     ]
    }
   ],
   "source": [
    "reviews_2006_2019 = reviews_all['1/1/2006':'12/31/2019']\n",
    "time_slice = reviews_2006_2019.groupby(reviews_2006_2019.index.year).count()\n",
    "time_slice = time_slice['CONTENT'].to_list()\n",
    "for i in range(len(time_slice)):\n",
    "    print(\"Reviews in Time Slice {}:\".format(i), time_slice[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_n_from_df(corpus, time_slices, nums=500):\n",
    "    new_corpus = corpus.iloc[0:nums]\n",
    "    start = time_slices[0]\n",
    "    for time_slice in time_slices[1:]:\n",
    "        new_corpus = pandas.concat([new_corpus, corpus.iloc[start:start+nums]], axis=0)\n",
    "        start += time_slice\n",
    "    return new_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_TIME</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>MOVIE_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-01 00:08:26</td>\n",
       "      <td>没有一个女性角色出现，一样喘不过气。</td>\n",
       "      <td>1293770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01-01 00:23:17</td>\n",
       "      <td>罗拉把我跑晕掉了，那是我辈梦想了许许多多年的存盘/取出大法。原来电影可以这么拍哦。蒙太奇可以...</td>\n",
       "      <td>1292275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-01 01:59:42</td>\n",
       "      <td>这样子的心计，到底是环境的逼迫，还是本性的爆发？</td>\n",
       "      <td>1307679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-01-01 02:04:01</td>\n",
       "      <td>我从没想到过这个梦会有如此多的缺憾，但也没想到他又会有如此完满的结局，I LOVE THIS...</td>\n",
       "      <td>1293179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-01 06:29:26</td>\n",
       "      <td>讲故事都讲不来，情节太荒谬了；10年12月，在CCTV6又看了一些，觉得表演也太做作，故事还...</td>\n",
       "      <td>1419969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426867</th>\n",
       "      <td>2019-09-07 15:57:07</td>\n",
       "      <td>就很尬，很无聊，笑点好无语，朱亚文为什么要接这样的片子啊………</td>\n",
       "      <td>27063867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426868</th>\n",
       "      <td>2019-09-07 15:58:03</td>\n",
       "      <td>吃了感冒药去看的，困上加困。朱亚文是想通过这部作品来拓宽戏路吗？</td>\n",
       "      <td>27063867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426869</th>\n",
       "      <td>2019-09-07 15:58:51</td>\n",
       "      <td>有些地方还是很好笑的，奔着两位主演去看，他们也确实有范儿，倒数第二场戏，两人穿礼服去办公室真...</td>\n",
       "      <td>27063867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426870</th>\n",
       "      <td>2019-09-07 15:59:42</td>\n",
       "      <td>OMG</td>\n",
       "      <td>1292226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426871</th>\n",
       "      <td>2019-09-07 16:00:15</td>\n",
       "      <td>舒缓的节奏与童书相称</td>\n",
       "      <td>1900121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4426872 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               COMMENT_TIME  \\\n",
       "0       2006-01-01 00:08:26   \n",
       "1       2006-01-01 00:23:17   \n",
       "2       2006-01-01 01:59:42   \n",
       "3       2006-01-01 02:04:01   \n",
       "4       2006-01-01 06:29:26   \n",
       "...                     ...   \n",
       "4426867 2019-09-07 15:57:07   \n",
       "4426868 2019-09-07 15:58:03   \n",
       "4426869 2019-09-07 15:58:51   \n",
       "4426870 2019-09-07 15:59:42   \n",
       "4426871 2019-09-07 16:00:15   \n",
       "\n",
       "                                                   CONTENT  MOVIE_ID  \n",
       "0                                       没有一个女性角色出现，一样喘不过气。   1293770  \n",
       "1        罗拉把我跑晕掉了，那是我辈梦想了许许多多年的存盘/取出大法。原来电影可以这么拍哦。蒙太奇可以...   1292275  \n",
       "2                                 这样子的心计，到底是环境的逼迫，还是本性的爆发？   1307679  \n",
       "3        我从没想到过这个梦会有如此多的缺憾，但也没想到他又会有如此完满的结局，I LOVE THIS...   1293179  \n",
       "4        讲故事都讲不来，情节太荒谬了；10年12月，在CCTV6又看了一些，觉得表演也太做作，故事还...   1419969  \n",
       "...                                                    ...       ...  \n",
       "4426867                    就很尬，很无聊，笑点好无语，朱亚文为什么要接这样的片子啊………  27063867  \n",
       "4426868                   吃了感冒药去看的，困上加困。朱亚文是想通过这部作品来拓宽戏路吗？  27063867  \n",
       "4426869  有些地方还是很好笑的，奔着两位主演去看，他们也确实有范儿，倒数第二场戏，两人穿礼服去办公室真...  27063867  \n",
       "4426870                                                OMG   1292226  \n",
       "4426871                                         舒缓的节奏与童书相称   1900121  \n",
       "\n",
       "[4426872 rows x 3 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_2006_2019.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>MOVIE_ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMMENT_TIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-01 00:08:26</th>\n",
       "      <td>没有一个女性角色出现，一样喘不过气。</td>\n",
       "      <td>1293770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 00:23:17</th>\n",
       "      <td>罗拉把我跑晕掉了，那是我辈梦想了许许多多年的存盘/取出大法。原来电影可以这么拍哦。蒙太奇可以...</td>\n",
       "      <td>1292275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 01:59:42</th>\n",
       "      <td>这样子的心计，到底是环境的逼迫，还是本性的爆发？</td>\n",
       "      <td>1307679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 02:04:01</th>\n",
       "      <td>我从没想到过这个梦会有如此多的缺憾，但也没想到他又会有如此完满的结局，I LOVE THIS...</td>\n",
       "      <td>1293179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 06:29:26</th>\n",
       "      <td>讲故事都讲不来，情节太荒谬了；10年12月，在CCTV6又看了一些，觉得表演也太做作，故事还...</td>\n",
       "      <td>1419969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 09:39:22</th>\n",
       "      <td>1111</td>\n",
       "      <td>26990112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 09:40:00</th>\n",
       "      <td>1111</td>\n",
       "      <td>27185049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 09:40:42</th>\n",
       "      <td>111</td>\n",
       "      <td>30406175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 09:40:59</th>\n",
       "      <td>在诗歌里你可以爱任何一个人，但在生活里你只能爱陪伴你的那一个</td>\n",
       "      <td>26976371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 09:42:09</th>\n",
       "      <td>满满的青春气息，两个男孩子都好可爱呀，还有言寺君有没有神似车银优哈哈</td>\n",
       "      <td>26761228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               CONTENT  \\\n",
       "COMMENT_TIME                                                             \n",
       "2006-01-01 00:08:26                                 没有一个女性角色出现，一样喘不过气。   \n",
       "2006-01-01 00:23:17  罗拉把我跑晕掉了，那是我辈梦想了许许多多年的存盘/取出大法。原来电影可以这么拍哦。蒙太奇可以...   \n",
       "2006-01-01 01:59:42                           这样子的心计，到底是环境的逼迫，还是本性的爆发？   \n",
       "2006-01-01 02:04:01  我从没想到过这个梦会有如此多的缺憾，但也没想到他又会有如此完满的结局，I LOVE THIS...   \n",
       "2006-01-01 06:29:26  讲故事都讲不来，情节太荒谬了；10年12月，在CCTV6又看了一些，觉得表演也太做作，故事还...   \n",
       "...                                                                ...   \n",
       "2019-01-01 09:39:22                                               1111   \n",
       "2019-01-01 09:40:00                                               1111   \n",
       "2019-01-01 09:40:42                                                111   \n",
       "2019-01-01 09:40:59                     在诗歌里你可以爱任何一个人，但在生活里你只能爱陪伴你的那一个   \n",
       "2019-01-01 09:42:09                 满满的青春气息，两个男孩子都好可爱呀，还有言寺君有没有神似车银优哈哈   \n",
       "\n",
       "                     MOVIE_ID  \n",
       "COMMENT_TIME                   \n",
       "2006-01-01 00:08:26   1293770  \n",
       "2006-01-01 00:23:17   1292275  \n",
       "2006-01-01 01:59:42   1307679  \n",
       "2006-01-01 02:04:01   1293179  \n",
       "2006-01-01 06:29:26   1419969  \n",
       "...                       ...  \n",
       "2019-01-01 09:39:22  26990112  \n",
       "2019-01-01 09:40:00  27185049  \n",
       "2019-01-01 09:40:42  30406175  \n",
       "2019-01-01 09:40:59  26976371  \n",
       "2019-01-01 09:42:09  26761228  \n",
       "\n",
       "[7000 rows x 2 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_reviews = choose_n_from_df(reviews_2006_2019, time_slice, nums=500)\n",
    "small_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://github.com/goto456/stopwords/blob/master/baidu_stopwords.txt\n",
    "stop_words = open(\"/Users/mao_shiba/Downloads/stopwords-master/baidu_stopwords.txt\", 'r', encoding='utf-8').read()\n",
    "stop_words_lst = stop_words.split('\\n') + ['电影', '一部', '一个', '很' ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>MOVIE_ID</th>\n",
       "      <th>regex_content</th>\n",
       "      <th>cut_words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMMENT_TIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-01 00:08:26</th>\n",
       "      <td>没有一个女性角色出现，一样喘不过气。</td>\n",
       "      <td>1293770</td>\n",
       "      <td>没有一个女性角色出现 一样喘不过气</td>\n",
       "      <td>[女性, 角色, 喘, 气]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 00:23:17</th>\n",
       "      <td>罗拉把我跑晕掉了，那是我辈梦想了许许多多年的存盘/取出大法。原来电影可以这么拍哦。蒙太奇可以...</td>\n",
       "      <td>1292275</td>\n",
       "      <td>罗拉把我跑晕掉了 那是我辈梦想了许许多多年的存盘 取出大法 原来电影可以这么拍哦 蒙太奇可以...</td>\n",
       "      <td>[罗拉, 跑, 晕, 掉, 我辈, 梦想, 许许多多, 年, 存盘, 取出, 大法, 拍, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 01:59:42</th>\n",
       "      <td>这样子的心计，到底是环境的逼迫，还是本性的爆发？</td>\n",
       "      <td>1307679</td>\n",
       "      <td>这样子的心计 到底是环境的逼迫 还是本性的爆发</td>\n",
       "      <td>[样子, 心计, 到底, 环境, 逼迫, 本性, 爆发]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 02:04:01</th>\n",
       "      <td>我从没想到过这个梦会有如此多的缺憾，但也没想到他又会有如此完满的结局，I LOVE THIS...</td>\n",
       "      <td>1293179</td>\n",
       "      <td>我从没想到过这个梦会有如此多的缺憾 但也没想到他又会有如此完满的结局</td>\n",
       "      <td>[没想到, 梦会, 缺憾, 没想到, 又会有, 完满, 结局]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 06:29:26</th>\n",
       "      <td>讲故事都讲不来，情节太荒谬了；10年12月，在CCTV6又看了一些，觉得表演也太做作，故事还...</td>\n",
       "      <td>1419969</td>\n",
       "      <td>讲故事都讲不来 情节太荒谬了 10年12月 在 6又看了一些 觉得表演也太做作 故事还是莫名其妙</td>\n",
       "      <td>[讲故事, 都, 讲, 不来, 情节, 太, 荒谬, 10, 年, 12, 月, 6, 看,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 09:39:22</th>\n",
       "      <td>1111</td>\n",
       "      <td>26990112</td>\n",
       "      <td>1111</td>\n",
       "      <td>[1111]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 09:40:00</th>\n",
       "      <td>1111</td>\n",
       "      <td>27185049</td>\n",
       "      <td>1111</td>\n",
       "      <td>[1111]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 09:40:42</th>\n",
       "      <td>111</td>\n",
       "      <td>30406175</td>\n",
       "      <td>111</td>\n",
       "      <td>[111]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 09:40:59</th>\n",
       "      <td>在诗歌里你可以爱任何一个人，但在生活里你只能爱陪伴你的那一个</td>\n",
       "      <td>26976371</td>\n",
       "      <td>在诗歌里你可以爱任何一个人 但在生活里你只能爱陪伴你的那一个</td>\n",
       "      <td>[诗歌, 里, 爱, 人, 生活, 里, 只能, 爱, 陪伴]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 09:42:09</th>\n",
       "      <td>满满的青春气息，两个男孩子都好可爱呀，还有言寺君有没有神似车银优哈哈</td>\n",
       "      <td>26761228</td>\n",
       "      <td>满满的青春气息 两个男孩子都好可爱呀 还有言寺君有没有神似车银优哈哈</td>\n",
       "      <td>[满满的, 青春, 气息, 两个, 男孩子, 都, 好, 可爱, 言寺君, 有没有, 神似,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               CONTENT  \\\n",
       "COMMENT_TIME                                                             \n",
       "2006-01-01 00:08:26                                 没有一个女性角色出现，一样喘不过气。   \n",
       "2006-01-01 00:23:17  罗拉把我跑晕掉了，那是我辈梦想了许许多多年的存盘/取出大法。原来电影可以这么拍哦。蒙太奇可以...   \n",
       "2006-01-01 01:59:42                           这样子的心计，到底是环境的逼迫，还是本性的爆发？   \n",
       "2006-01-01 02:04:01  我从没想到过这个梦会有如此多的缺憾，但也没想到他又会有如此完满的结局，I LOVE THIS...   \n",
       "2006-01-01 06:29:26  讲故事都讲不来，情节太荒谬了；10年12月，在CCTV6又看了一些，觉得表演也太做作，故事还...   \n",
       "...                                                                ...   \n",
       "2019-01-01 09:39:22                                               1111   \n",
       "2019-01-01 09:40:00                                               1111   \n",
       "2019-01-01 09:40:42                                                111   \n",
       "2019-01-01 09:40:59                     在诗歌里你可以爱任何一个人，但在生活里你只能爱陪伴你的那一个   \n",
       "2019-01-01 09:42:09                 满满的青春气息，两个男孩子都好可爱呀，还有言寺君有没有神似车银优哈哈   \n",
       "\n",
       "                     MOVIE_ID  \\\n",
       "COMMENT_TIME                    \n",
       "2006-01-01 00:08:26   1293770   \n",
       "2006-01-01 00:23:17   1292275   \n",
       "2006-01-01 01:59:42   1307679   \n",
       "2006-01-01 02:04:01   1293179   \n",
       "2006-01-01 06:29:26   1419969   \n",
       "...                       ...   \n",
       "2019-01-01 09:39:22  26990112   \n",
       "2019-01-01 09:40:00  27185049   \n",
       "2019-01-01 09:40:42  30406175   \n",
       "2019-01-01 09:40:59  26976371   \n",
       "2019-01-01 09:42:09  26761228   \n",
       "\n",
       "                                                         regex_content  \\\n",
       "COMMENT_TIME                                                             \n",
       "2006-01-01 00:08:26                                 没有一个女性角色出现 一样喘不过气    \n",
       "2006-01-01 00:23:17  罗拉把我跑晕掉了 那是我辈梦想了许许多多年的存盘 取出大法 原来电影可以这么拍哦 蒙太奇可以...   \n",
       "2006-01-01 01:59:42                           这样子的心计 到底是环境的逼迫 还是本性的爆发    \n",
       "2006-01-01 02:04:01                我从没想到过这个梦会有如此多的缺憾 但也没想到他又会有如此完满的结局    \n",
       "2006-01-01 06:29:26  讲故事都讲不来 情节太荒谬了 10年12月 在 6又看了一些 觉得表演也太做作 故事还是莫名其妙    \n",
       "...                                                                ...   \n",
       "2019-01-01 09:39:22                                               1111   \n",
       "2019-01-01 09:40:00                                               1111   \n",
       "2019-01-01 09:40:42                                                111   \n",
       "2019-01-01 09:40:59                     在诗歌里你可以爱任何一个人 但在生活里你只能爱陪伴你的那一个   \n",
       "2019-01-01 09:42:09                 满满的青春气息 两个男孩子都好可爱呀 还有言寺君有没有神似车银优哈哈   \n",
       "\n",
       "                                                             cut_words  \n",
       "COMMENT_TIME                                                            \n",
       "2006-01-01 00:08:26                                     [女性, 角色, 喘, 气]  \n",
       "2006-01-01 00:23:17  [罗拉, 跑, 晕, 掉, 我辈, 梦想, 许许多多, 年, 存盘, 取出, 大法, 拍, ...  \n",
       "2006-01-01 01:59:42                       [样子, 心计, 到底, 环境, 逼迫, 本性, 爆发]  \n",
       "2006-01-01 02:04:01                    [没想到, 梦会, 缺憾, 没想到, 又会有, 完满, 结局]  \n",
       "2006-01-01 06:29:26  [讲故事, 都, 讲, 不来, 情节, 太, 荒谬, 10, 年, 12, 月, 6, 看,...  \n",
       "...                                                                ...  \n",
       "2019-01-01 09:39:22                                             [1111]  \n",
       "2019-01-01 09:40:00                                             [1111]  \n",
       "2019-01-01 09:40:42                                              [111]  \n",
       "2019-01-01 09:40:59                    [诗歌, 里, 爱, 人, 生活, 里, 只能, 爱, 陪伴]  \n",
       "2019-01-01 09:42:09  [满满的, 青春, 气息, 两个, 男孩子, 都, 好, 可爱, 言寺君, 有没有, 神似,...  \n",
       "\n",
       "[7000 rows x 4 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_reviews['regex_content'] = small_reviews['CONTENT'].replace('[^\\u4e00-\\u9fa50-9]+', ' ', regex=True)\n",
    "cut_words = lambda x: [word for word in jieba.lcut(x) if word not in stop_words_lst]\n",
    "small_reviews['cut_words'] = small_reviews['regex_content'].apply(cut_words)\n",
    "small_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_lst = []\n",
    "for index, row in small_reviews.iterrows():\n",
    "    if row['cut_words'] == []:\n",
    "        empty_lst.append(index)\n",
    "\n",
    "small_reviews.drop(empty_lst, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>MOVIE_ID</th>\n",
       "      <th>regex_content</th>\n",
       "      <th>cut_words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMMENT_TIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-01 00:08:26</th>\n",
       "      <td>没有一个女性角色出现，一样喘不过气。</td>\n",
       "      <td>1293770</td>\n",
       "      <td>没有一个女性角色出现 一样喘不过气</td>\n",
       "      <td>[女性, 角色, 喘, 气]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 00:23:17</th>\n",
       "      <td>罗拉把我跑晕掉了，那是我辈梦想了许许多多年的存盘/取出大法。原来电影可以这么拍哦。蒙太奇可以...</td>\n",
       "      <td>1292275</td>\n",
       "      <td>罗拉把我跑晕掉了 那是我辈梦想了许许多多年的存盘 取出大法 原来电影可以这么拍哦 蒙太奇可以...</td>\n",
       "      <td>[罗拉, 跑, 晕, 掉, 我辈, 梦想, 许许多多, 年, 存盘, 取出, 大法, 拍, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 01:59:42</th>\n",
       "      <td>这样子的心计，到底是环境的逼迫，还是本性的爆发？</td>\n",
       "      <td>1307679</td>\n",
       "      <td>这样子的心计 到底是环境的逼迫 还是本性的爆发</td>\n",
       "      <td>[样子, 心计, 到底, 环境, 逼迫, 本性, 爆发]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 02:04:01</th>\n",
       "      <td>我从没想到过这个梦会有如此多的缺憾，但也没想到他又会有如此完满的结局，I LOVE THIS...</td>\n",
       "      <td>1293179</td>\n",
       "      <td>我从没想到过这个梦会有如此多的缺憾 但也没想到他又会有如此完满的结局</td>\n",
       "      <td>[没想到, 梦会, 缺憾, 没想到, 又会有, 完满, 结局]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 06:29:26</th>\n",
       "      <td>讲故事都讲不来，情节太荒谬了；10年12月，在CCTV6又看了一些，觉得表演也太做作，故事还...</td>\n",
       "      <td>1419969</td>\n",
       "      <td>讲故事都讲不来 情节太荒谬了 10年12月 在 6又看了一些 觉得表演也太做作 故事还是莫名其妙</td>\n",
       "      <td>[讲故事, 都, 讲, 不来, 情节, 太, 荒谬, 10, 年, 12, 月, 6, 看,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 09:39:22</th>\n",
       "      <td>1111</td>\n",
       "      <td>26990112</td>\n",
       "      <td>1111</td>\n",
       "      <td>[1111]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 09:40:00</th>\n",
       "      <td>1111</td>\n",
       "      <td>27185049</td>\n",
       "      <td>1111</td>\n",
       "      <td>[1111]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 09:40:42</th>\n",
       "      <td>111</td>\n",
       "      <td>30406175</td>\n",
       "      <td>111</td>\n",
       "      <td>[111]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 09:40:59</th>\n",
       "      <td>在诗歌里你可以爱任何一个人，但在生活里你只能爱陪伴你的那一个</td>\n",
       "      <td>26976371</td>\n",
       "      <td>在诗歌里你可以爱任何一个人 但在生活里你只能爱陪伴你的那一个</td>\n",
       "      <td>[诗歌, 里, 爱, 人, 生活, 里, 只能, 爱, 陪伴]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 09:42:09</th>\n",
       "      <td>满满的青春气息，两个男孩子都好可爱呀，还有言寺君有没有神似车银优哈哈</td>\n",
       "      <td>26761228</td>\n",
       "      <td>满满的青春气息 两个男孩子都好可爱呀 还有言寺君有没有神似车银优哈哈</td>\n",
       "      <td>[满满的, 青春, 气息, 两个, 男孩子, 都, 好, 可爱, 言寺君, 有没有, 神似,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6772 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               CONTENT  \\\n",
       "COMMENT_TIME                                                             \n",
       "2006-01-01 00:08:26                                 没有一个女性角色出现，一样喘不过气。   \n",
       "2006-01-01 00:23:17  罗拉把我跑晕掉了，那是我辈梦想了许许多多年的存盘/取出大法。原来电影可以这么拍哦。蒙太奇可以...   \n",
       "2006-01-01 01:59:42                           这样子的心计，到底是环境的逼迫，还是本性的爆发？   \n",
       "2006-01-01 02:04:01  我从没想到过这个梦会有如此多的缺憾，但也没想到他又会有如此完满的结局，I LOVE THIS...   \n",
       "2006-01-01 06:29:26  讲故事都讲不来，情节太荒谬了；10年12月，在CCTV6又看了一些，觉得表演也太做作，故事还...   \n",
       "...                                                                ...   \n",
       "2019-01-01 09:39:22                                               1111   \n",
       "2019-01-01 09:40:00                                               1111   \n",
       "2019-01-01 09:40:42                                                111   \n",
       "2019-01-01 09:40:59                     在诗歌里你可以爱任何一个人，但在生活里你只能爱陪伴你的那一个   \n",
       "2019-01-01 09:42:09                 满满的青春气息，两个男孩子都好可爱呀，还有言寺君有没有神似车银优哈哈   \n",
       "\n",
       "                     MOVIE_ID  \\\n",
       "COMMENT_TIME                    \n",
       "2006-01-01 00:08:26   1293770   \n",
       "2006-01-01 00:23:17   1292275   \n",
       "2006-01-01 01:59:42   1307679   \n",
       "2006-01-01 02:04:01   1293179   \n",
       "2006-01-01 06:29:26   1419969   \n",
       "...                       ...   \n",
       "2019-01-01 09:39:22  26990112   \n",
       "2019-01-01 09:40:00  27185049   \n",
       "2019-01-01 09:40:42  30406175   \n",
       "2019-01-01 09:40:59  26976371   \n",
       "2019-01-01 09:42:09  26761228   \n",
       "\n",
       "                                                         regex_content  \\\n",
       "COMMENT_TIME                                                             \n",
       "2006-01-01 00:08:26                                 没有一个女性角色出现 一样喘不过气    \n",
       "2006-01-01 00:23:17  罗拉把我跑晕掉了 那是我辈梦想了许许多多年的存盘 取出大法 原来电影可以这么拍哦 蒙太奇可以...   \n",
       "2006-01-01 01:59:42                           这样子的心计 到底是环境的逼迫 还是本性的爆发    \n",
       "2006-01-01 02:04:01                我从没想到过这个梦会有如此多的缺憾 但也没想到他又会有如此完满的结局    \n",
       "2006-01-01 06:29:26  讲故事都讲不来 情节太荒谬了 10年12月 在 6又看了一些 觉得表演也太做作 故事还是莫名其妙    \n",
       "...                                                                ...   \n",
       "2019-01-01 09:39:22                                               1111   \n",
       "2019-01-01 09:40:00                                               1111   \n",
       "2019-01-01 09:40:42                                                111   \n",
       "2019-01-01 09:40:59                     在诗歌里你可以爱任何一个人 但在生活里你只能爱陪伴你的那一个   \n",
       "2019-01-01 09:42:09                 满满的青春气息 两个男孩子都好可爱呀 还有言寺君有没有神似车银优哈哈   \n",
       "\n",
       "                                                             cut_words  \n",
       "COMMENT_TIME                                                            \n",
       "2006-01-01 00:08:26                                     [女性, 角色, 喘, 气]  \n",
       "2006-01-01 00:23:17  [罗拉, 跑, 晕, 掉, 我辈, 梦想, 许许多多, 年, 存盘, 取出, 大法, 拍, ...  \n",
       "2006-01-01 01:59:42                       [样子, 心计, 到底, 环境, 逼迫, 本性, 爆发]  \n",
       "2006-01-01 02:04:01                    [没想到, 梦会, 缺憾, 没想到, 又会有, 完满, 结局]  \n",
       "2006-01-01 06:29:26  [讲故事, 都, 讲, 不来, 情节, 太, 荒谬, 10, 年, 12, 月, 6, 看,...  \n",
       "...                                                                ...  \n",
       "2019-01-01 09:39:22                                             [1111]  \n",
       "2019-01-01 09:40:00                                             [1111]  \n",
       "2019-01-01 09:40:42                                              [111]  \n",
       "2019-01-01 09:40:59                    [诗歌, 里, 爱, 人, 生活, 里, 只能, 爱, 陪伴]  \n",
       "2019-01-01 09:42:09  [满满的, 青春, 气息, 两个, 男孩子, 都, 好, 可爱, 言寺君, 有没有, 神似,...  \n",
       "\n",
       "[6772 rows x 4 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_time_slice = small_reviews.groupby(small_reviews.index.year).count()\n",
    "small_time_slice = small_time_slice['CONTENT'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[486, 470, 474, 476, 482, 483, 489, 477, 492, 487, 489, 494, 485, 488]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_time_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_corpus = list(small_reviews['cut_words'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(small_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in small_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim.corpora.MmCorpus.serialize('reviews.mm', corpus)\n",
    "review_corpus = gensim.corpora.MmCorpus('reviews.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mao_shiba/opt/anaconda3/lib/python3.8/site-packages/gensim/models/ldaseqmodel.py:297: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  convergence = np.fabs((bound - old_bound) / old_bound)\n"
     ]
    }
   ],
   "source": [
    "ldaseq = ldaseqmodel.LdaSeqModel(corpus=corpus, id2word=dictionary, time_slice=small_time_slice, num_topics=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('人', 0.013869027549829478),\n",
       " ('不', 0.013395924357062376),\n",
       " ('都', 0.012834753871380016),\n",
       " ('剧情', 0.008039117891873688),\n",
       " ('说', 0.0071078622616712875),\n",
       " ('还', 0.005891852284769024),\n",
       " ('喜欢', 0.005157016349257597),\n",
       " ('看', 0.005028359293901975),\n",
       " ('却', 0.004700396107453443),\n",
       " ('中', 0.0046708905777647905),\n",
       " ('会', 0.004403557772127651),\n",
       " ('这部', 0.004178600840734471),\n",
       " ('太', 0.004158164956450024),\n",
       " ('一点', 0.004043065787318693),\n",
       " ('故事', 0.004034805020981709),\n",
       " ('做', 0.004009675821675383),\n",
       " ('影片', 0.0039579246626461825),\n",
       " ('好', 0.0038324677260792093),\n",
       " ('上', 0.003711930442388923),\n",
       " ('想', 0.0033897567504783243)]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('都', 0.015347558627681921),\n",
       " ('不', 0.01521192673585167),\n",
       " ('人', 0.013029999572287882),\n",
       " ('剧情', 0.009763332787124681),\n",
       " ('说', 0.006655628181303324),\n",
       " ('还', 0.006089880257621396),\n",
       " ('看', 0.005581880035938559),\n",
       " ('中', 0.004950217601408053),\n",
       " ('好', 0.0046696422300322145),\n",
       " ('一点', 0.004481226148115719),\n",
       " ('故事', 0.004365253108903081),\n",
       " ('会', 0.00436290224357248),\n",
       " ('却', 0.003905253394579585),\n",
       " ('上', 0.0039014552519361033),\n",
       " ('做', 0.0038082095835294447),\n",
       " ('太', 0.003792498908652628),\n",
       " ('喜欢', 0.0037598558542079152),\n",
       " ('想', 0.0037222331123269174),\n",
       " ('没', 0.0034143820674373097),\n",
       " ('导演', 0.0034075002965170092)]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=13)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('片', 0.007280218173445015),\n",
       " ('不', 0.005984588051981002),\n",
       " ('真', 0.005611762285183265),\n",
       " ('还', 0.005123692152930248),\n",
       " ('上', 0.004895789623103878),\n",
       " ('喜剧', 0.00467409352648683),\n",
       " ('都', 0.004606741707353641),\n",
       " ('故事', 0.00459420522971433),\n",
       " ('烂', 0.004412536551105898),\n",
       " ('中', 0.0043166247421084596),\n",
       " ('拍', 0.004128910858500325),\n",
       " ('导演', 0.004017945108674388),\n",
       " ('垃圾', 0.00381447241657174),\n",
       " ('哈哈哈', 0.0037399636972846933),\n",
       " ('男', 0.003591535990324543),\n",
       " ('血腥', 0.003385159402334285),\n",
       " ('太', 0.003278733472644457),\n",
       " ('好', 0.0031815053076093202),\n",
       " ('人', 0.0031720346694673242),\n",
       " ('爱情', 0.0031660584306316456)]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=0)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('片', 0.006372128291090471),\n",
       " ('不', 0.005487051996592614),\n",
       " ('都', 0.004913324730028293),\n",
       " ('中', 0.004847398203911993),\n",
       " ('真', 0.004792637053593104),\n",
       " ('故事', 0.004682584792614175),\n",
       " ('上', 0.004531180129425113),\n",
       " ('喜剧', 0.0043752246299962275),\n",
       " ('烂', 0.00429420957649512),\n",
       " ('哈哈哈', 0.004287646189938744),\n",
       " ('还', 0.004084151783506735),\n",
       " ('拍', 0.003971981827265729),\n",
       " ('导演', 0.0037674461159121135),\n",
       " ('垃圾', 0.0037211840157106604),\n",
       " ('男', 0.003571205540009882),\n",
       " ('剧', 0.0033252914055239367),\n",
       " ('太', 0.003191856353183727),\n",
       " ('血腥', 0.0031732022321455176),\n",
       " ('好', 0.0031441712922129503),\n",
       " ('却', 0.003123984210109283)]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=13)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaseq.save(\"ldaseqmodel\")\n",
    "loaded_model = ldaseqmodel.LdaSeqModel.load(\"ldaseqmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
